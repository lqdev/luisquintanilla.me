---
title: "The Foundation Model Transparency Index"
targeturl: https://crfm.stanford.edu/fmti/ 
response_type: bookmark
dt_published: "2023-12-11 19:37"
dt_updated: "2023-12-11 19:37 -05:00"
tags: ["ai","opensource","transparency"]
---

> A comprehensive assessment of the transparency of foundation model developers

> **Context**. Foundation models like GPT-4 and Llama 2 are used by millions of people. While the societal impact of these models is rising, transparency is on the decline. If this trend continues, foundation models could become just as opaque as social media platforms and other previous technologies, replicating their failure modes. 

> **Design**. We introduce the Foundation Model Transparency Index to assess the transparency of foundation model developers. We design the Index around 100 transparency indicators, which codify transparency for foundation models, the resources required to build them, and their use in the AI supply chain.

> **Execution**. For the 2023 Index, we score 10 leading developers against our 100 indicators. This provides a snapshot of transparency across the AI ecosystem. All developers have significant room for improvement that we will aim to track in the future versions of the Index. 