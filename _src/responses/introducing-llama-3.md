---
title: "Introducing Llama 3"
targeturl: https://llama.meta.com/llama3/ 
response_type: reshare
dt_published: "2024-04-18 21:01 -05:00"
dt_updated: "2024-04-18 21:01 -05:00"
tags: ["meta","ai","llama3","llama","llm"]
---

> Build the future of AI with Meta Llama 3

> Now available with both 8B and 70B pretrained and instruction-tuned versions to support a wide range of applications

> Llama 3 models take data and scale to new heights. It’s been trained on our two recently announced custom-built 24K GPU clusters on over 15T token of data – a training dataset 7x larger than that used for Llama 2, including 4x more code. This results in the most capable Llama model yet, which supports a 8K context length that doubles the capacity of Llama 2.
