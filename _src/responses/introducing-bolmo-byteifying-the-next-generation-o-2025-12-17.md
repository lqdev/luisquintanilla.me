---
title: "Introducing Bolmo: Byteifying the next generation of language models"
targeturl: https://allenai.org/blog/bolmo
response_type: reshare
dt_published: "2025-12-17 22:20 -05:00"
dt_updated: "2025-12-17 22:20 -05:00"
tags: ["ai","llm"]
---

> Today, we're introducing Bolmo, a new family of byte-level language models that takes a different path. Instead of starting from scratch, Bolmo byteifies our open Olmo 3 models—reusing the backbone and capabilities we've already invested in, and retrofitting them into a fast, flexible byte-level architecture with a relatively short additional training run. The result is, to our knowledge, the first fully open byte-level language models – Bolmo 7B and Bolmo 1B – that are on par with, and in some cases surpass, state-of-the-art subword models across a wide range of tasks, while remaining practical to train and deploy.