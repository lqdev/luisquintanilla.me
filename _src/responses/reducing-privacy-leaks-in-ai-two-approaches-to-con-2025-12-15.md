---
title: "Reducing Privacy leaks in AI: Two approaches to contextual integrity"
targeturl: https://www.microsoft.com/en-us/research/blog/reducing-privacy-leaks-in-ai-two-approaches-to-contextual-integrity/
response_type: reshare
dt_published: "2025-12-15 22:02 -05:00"
dt_updated: "2025-12-15 22:02 -05:00"
tags: ["ai","privacy","research","microsoft","msr","microsoftresearch"]
---

> [Privacy in Action: Towards Realistic Privacy Mitigation and Evaluation for LLM-Powered Agents](https://www.microsoft.com/en-us/research/publication/privacy-in-action-towards-realistic-privacy-mitigation-and-evaluation-for-llm-powered-agents/), accepted at the EMNLP 2025, introduces [PrivacyChecker(opens in new tab)](https://github.com/microsoft/ACV/tree/main/misc/PrivacyInAction), a lightweight module that can be integrated into agents, helping make them more sensitive to contextual integrity. It enables a new evaluation approach, transforming static privacy benchmarks into dynamic environments that reveal substantially higher privacy risks in real-world agent interactions. [Contextual Integrity in LLMs via Reasoning and Reinforcement Learning](https://www.microsoft.com/en-us/research/publication/contextual-integrity-in-llms-via-reasoning-and-reinforcement-learning/), accepted at [NeurIPS 2025](https://www.microsoft.com/en-us/research/event/neurips-2025/),  takes a different approach to applying contextual integrity. It treats it as a problem that requires careful reasoning about the context, the information, and who is involved to enforce privacy norms.