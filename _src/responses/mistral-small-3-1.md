---
title: "Mistral Small 3.1"
targeturl: https://mistral.ai/fr/news/mistral-small-3-1
response_type: reshare
dt_published: "2025-03-18 20:31 -05:00"
dt_updated: "2025-03-18 20:31 -05:00"
tags: ["mistral","ai","opensource"]
---

> Building on Mistral Small 3, this new model comes with improved text performance, multimodal understanding, and an expanded context window of up to 128k tokens. The model outperforms comparable models like Gemma 3 and GPT-4o Mini, while delivering inference speeds of 150 tokens per second.

> Lightweight: Mistral Small 3.1 can run on a single RTX 4090 or a Mac with 32GB RAM. This makes it a great fit for on-device use cases.