---
title: "The assistant axis: situating and stabilizing the character of large language models"
targeturl: https://www.anthropic.com/research/assistant-axis
response_type: reshare
dt_published: "2026-01-20 10:19 -05:00"
dt_updated: "2026-01-20 10:19 -05:00"
tags: ["ai","anthropic","agents","llm"]
---

> In a new paper, conducted through the MATS and Anthropic Fellows programs, we look at several open-weights language models, map out how their neural activity defines a “persona space,” and situate the Assistant persona within that space.  
> <br>
> We find that Assistant-like behavior is linked to a pattern of neural activity that corresponds to one particular direction in this space—the “Assistant Axis”—that is closely associated with helpful, professional human archetypes. By monitoring models’ activity along this axis, we can detect when they begin to drift away from the Assistant and toward another character. And by constraining their neural activity (“activation capping”) to prevent this drift, we can stabilize model behavior in situations that would otherwise lead to harmful outputs.