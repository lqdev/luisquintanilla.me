---
title: "Cosmopedia v0.1"
targeturl: https://huggingface.co/datasets/HuggingFaceTB/cosmopedia
response_type: reshare
dt_published: "2024-02-20 16:50"
dt_updated: "2024-02-20 16:50 -05:00"
tags: ["cosmopedia","dataset","huggingface","mixtral","ai","genai","llm"]
---

> Cosmopedia is a dataset of synthetic textbooks, blogposts, stories, posts and WikiHow articles generated by Mixtral-8x7B-Instruct-v0.1.The dataset contains over 30 million files and 25 billion tokens, making it the largest open synthetic dataset to date.  
> <br>
> It covers a variety of topics; we tried to map world knowledge present in Web datasets like RefinedWeb and RedPajama, and generate synthetic content that covers them. This is the v0.1 of Cosmopedia, with ample room for improvement and topics to be more comprehensively covered. We hope this dataset will help the community's research efforts in the increasingly intriguing domain of synthetic data.  
> <br>
> This work is inspired by the great work of Phi1.5. 
