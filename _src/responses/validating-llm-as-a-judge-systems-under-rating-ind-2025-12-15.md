---
title: "Validating LLM-as-a-Judge Systems under Rating Indeterminacy"
targeturl: https://blog.ml.cmu.edu/2025/12/09/validating-llm-as-a-judge-systems-under-rating-indeterminacy/
response_type: reshare
dt_published: "2025-12-15 23:20 -05:00"
dt_updated: "2025-12-15 23:20 -05:00"
tags: ["ai","cmu","research","llm"]
---

> we developed a framework for judge-system meta-evaluation under rating indeterminacy (Figure 1). Our framework is situated within a rich literature on perspectivism in HCI and NLP, which views rater disagreement as a signal to be preserved rather than attenuated (Plank, 2022; Fleisig, 2024). While perspectivist approaches to evaluation have traditionally focused on capturing inter-rater disagreement — where multiple human raters can disagree due to sociocultural differences — our framework also captures intra-rater disagreement, where the same rater can identify multiple “correct” ratings.