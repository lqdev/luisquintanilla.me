---
title: "Titans + MIRAS: Helping AI have long-term memory"
targeturl: https://research.google/blog/titans-miras-helping-ai-have-long-term-memory/
response_type: reshare
dt_published: "2025-12-07 15:37 -05:00"
dt_updated: "2025-12-07 15:37 -05:00"
tags: ["google","ai","research","deeplearning","neuralnetworks","transformers","rnn"]
---

> In two new papers, [Titans](https://arxiv.org/abs/2501.00663) and [MIRAS](https://arxiv.org/pdf/2504.13173), we introduce an architecture and theoretical blueprint that combine the speed of RNNs with the accuracy of transformers. Titans is the specific architecture (the tool), and MIRAS is the theoretical framework (the blueprint) for generalizing these approaches. Together, they advance the concept of test-time memorization, the ability of an AI model to maintain long-term memory by incorporating more powerful “surprise” metrics (i.e., unexpected pieces of information) while the model is running and without dedicated offline retraining.  
> <br>
> The MIRAS framework, as demonstrated by Titans, introduces a meaningful shift toward real-time adaptation. Instead of compressing information into a static state, this architecture actively learns and updates its own parameters as data streams in. This crucial mechanism enables the model to incorporate new, specific details into its core knowledge instantly.