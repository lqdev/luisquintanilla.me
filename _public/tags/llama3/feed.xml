<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>Luis Quintanilla - llama3</title>
    <link>https://www.lqdev.me/tags/llama3</link>
    <description>All content tagged with 'llama3' by Luis Quintanilla</description>
    <lastBuildDate>2024-08-22 16:21 -05:00</lastBuildDate>
    <language>en</language>
    <item>
      <title>Bringing Llama 3 to life</title>
      <description>&lt;![CDATA[[reshare] &lt;p&gt;At AI Infra @ Scale 2024, Meta engineers discussed every step of how we built and brought Llama 3 to life, from data and training to inference.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=ELIcy6flgQI" title="Bringing Llama 3 to life talk video thumbnail"&gt;&lt;img src="http://img.youtube.com/vi/ELIcy6flgQI/0.jpg" class="img-fluid" alt="Bringing Llama 3 to life talk video thumbnail" /&gt;&lt;/a&gt;&lt;/p&gt;
]]&gt;</description>
      <link>https://www.lqdev.me/responses/meta-bringing-llama-3-to-life</link>
      <guid>https://www.lqdev.me/responses/meta-bringing-llama-3-to-life</guid>
      <pubDate>2024-08-22 16:21 -05:00</pubDate>
      <category>ai</category>
      <category>meta</category>
      <category>llama3</category>
      <category>opensource</category>
      <category>llm</category>
    </item>
    <item>
      <title>Introducing Llama 3</title>
      <description>&lt;![CDATA[[reshare] &lt;blockquote class="blockquote"&gt;
&lt;p&gt;Build the future of AI with Meta Llama 3&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;Now available with both 8B and 70B pretrained and instruction-tuned versions to support a wide range of applications&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;Llama 3 models take data and scale to new heights. It’s been trained on our two recently announced custom-built 24K GPU clusters on over 15T token of data – a training dataset 7x larger than that used for Llama 2, including 4x more code. This results in the most capable Llama model yet, which supports a 8K context length that doubles the capacity of Llama 2.&lt;/p&gt;
&lt;/blockquote&gt;
]]&gt;</description>
      <link>https://www.lqdev.me/responses/introducing-llama-3</link>
      <guid>https://www.lqdev.me/responses/introducing-llama-3</guid>
      <pubDate>2024-04-18 21:01 -05:00</pubDate>
      <category>meta</category>
      <category>ai</category>
      <category>llama3</category>
      <category>llama</category>
      <category>llm</category>
    </item>
  </channel>
</rss>