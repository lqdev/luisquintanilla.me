<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>Luis Quintanilla - mlnet</title>
    <link>https://www.lqdev.me/tags/mlnet</link>
    <description>All content tagged with 'mlnet' by Luis Quintanilla</description>
    <lastBuildDate>2021-09-16 18:00:00 -05:00</lastBuildDate>
    <language>en</language>
    <item>
      <title>Make predictions with ML.NET models without defining schema classes</title>
      <description>&lt;![CDATA[
## Introduction

To make predictions with ML.NET models you often have to define schema classes for your model inputs and outputs. In previous posts I wrote how you can [use Netron to inspect an ML.NET model](/posts/inspect-mlnet-models-netron/) to determine the name and types of your model inputs and outputs. If you have data samples of what your data input and output look like in JSON format, you can [automate the generation of model input and output classes by using Visual Studio's "Paste JSON as Classes" feature](/posts/vs-automate-mlnet-schema-generation/). However, what if you want to make predictions without defining these classes? In this post I'll show how you can use the .NET DataFrame API to make predictions with ML.NET models without having to create model input and output classes. Code snippets are in F# but notebooks with complete [C#](https://github.com/lqdev/mlnet-noschema-predictions/blob/main/CSharp-NB.ipynb) &amp; [F#](https://github.com/lqdev/mlnet-noschema-predictions/blob/main/FSharp-NB.ipynb) code can be found in the [mlnet-noschema-predictions repo](https://github.com/lqdev/mlnet-noschema-predictions) on GitHub.

## Install and reference packages

In addition to the [Microsoft.ML](https://www.nuget.org/packages/Microsoft.ML/) ML.NET NuGet package, you'll also need the [Microsoft.Data.Analysis](https://www.nuget.org/packages/Microsoft.Data.Analysis/) NuGet package to use the .NET DataFrame API. For more information on the .NET DataFrame API, see [an introduction to DataFrame](https://devblogs.microsoft.com/dotnet/an-introduction-to-dataframe/).

Once your packages are installed, reference them in your application.

```fsharp
open Microsoft.ML
open Microsoft.Data.Analysis
```

## Initialize MLContext and load the model

The `MLContext` is the entrypoint of ML.NET applications. Use it to load your model. The model used in this case categorizes sentiment as positive or negative. See the [use Netron to inspect an ML.NET model](/posts/inspect-mlnet-models-netron/) blog post to learn more about the model.

```fsharp
let ctx = MLContext()
let model,schema = ctx.Model.Load("sentiment_model.zip")
```

Both the model and the input schema are returned when you load the model. The input schema is a [DataViewSchema](https://docs.microsoft.com/dotnet/api/microsoft.ml.dataviewschema?view=ml-dotnet) object containing a collection of [Columns](https://docs.microsoft.com/dotnet/api/microsoft.ml.dataviewschema.column?view=ml-dotnet).

## Define input and output column names

The input and output column names are for the DataFrames containing your input data and predictions. They help the model map the input and output values.

Use the `schema` which was loaded with the model to get the name of your input columns.

```fsharp
let inputColumnNames = 
    schema 
    |&gt; Seq.map(fun column -&gt; column.Name) 
    |&gt; Array.ofSeq
```

Since this is a binary classification model by default only two columns are returned as part of the prediction:

- Score
- PredictedLabel

You can create an array containing the names of these columns. For more information on default output columns, see the [ML.NET Tasks documentation](https://docs.microsoft.com/dotnet/machine-learning/resources/tasks#binary-classification-inputs-and-outputs).

```fsharp
let outputColumnNames = [| "PredictedLabel" ; "Score" |]
```

## Create input data for predictions

Use the [`LoadCsvFromString`](https://docs.microsoft.com/dotnet/api/microsoft.data.analysis.dataframe.loadcsvfromstring?view=ml-dotnet-preview#Microsoft_Data_Analysis_DataFrame_LoadCsvFromString_System_String_System_Char_System_Boolean_System_String___System_Type___System_Int64_System_Int32_System_Boolean_) method to load your input data into a DataFrame. In this case, there's only one column and data instance so I represent it as a string literal. Additionally, I provide the name of the input columns.

```fsharp
let sampleInput = "This was a very bad steak"

let inputDataFrame = 
    DataFrame.LoadCsvFromString(
        sampleInput, 
        header=false, 
        columnNames=inputColumnNames)
```

## Make predictions

Now that you've loaded your input data, it's time to use the model to make predictions.

```fsharp
let predictionDV = 
    inputDataFrame 
    |&gt; model.Transform 
```

Calling the [`Transform`](https://docs.microsoft.com/dotnet/api/microsoft.ml.itransformer.transform?view=ml-dotnet#Microsoft_ML_ITransformer_Transform_Microsoft_ML_IDataView_) method  returns an [`IDataView`](https://docs.microsoft.com/dotnet/api/microsoft.ml.idataview?view=ml-dotnet) with your predictions. You can then convert the `IDataView` into a DataFrame for further processing with the [`ToDataFrame`](https://docs.microsoft.com/dotnet/api/microsoft.ml.idataviewextensions.todataframe?view=ml-dotnet-preview) method.

```fsharp
let prediction = predictionDV.ToDataFrame(1L, outputColumnNames)
```

The resulting DataFrame should look something like the following:

| index | PredictedLabel | Score | 
|---|---|---|
|0 |False | -2.1337974 |

## Conclusion

If you want to load a model and make predictions without defining  classes for your input and output schema's you can load your data into a DataFrame using the .NET DataFrame API. While this solution works, because DataFrames and IDataViews process data differently, I haven't tested whether this solution would scale for larger data sets.
]]&gt;</description>
      <link>https://www.lqdev.me/posts/mlnet-predictions-no-schema</link>
      <guid>https://www.lqdev.me/posts/mlnet-predictions-no-schema</guid>
      <pubDate>2021-09-16 18:00:00 -05:00</pubDate>
      <category>dotnet</category>
      <category>machine learning</category>
      <category>mlnet</category>
      <category>artificial intelligence</category>
    </item>
    <item>
      <title>Automate ML.NET model schema generation from sample JSON data with Visual Studio</title>
      <description>&lt;![CDATA[
## Introduction

When using ML.NET models to make predictions, you often have to define classes for the model's input and output schema. In a previous post, I showed how you can [use Netron to inspect ML.NET models](/posts/inspect-mlnet-models-netron/) and manually define classes to represent the input and output schema for your model. That works for models that don't have a lot of features / columns. However, as the number of columns grows, it can become cumbersome to define these classes. Visual Studio has a feature that can help automate that process. Assuming you have a sample of your input and output data in JSON format, you can leverage a built-in feature "Paste JSON As Classes" to take the sample and convert it to a class. In this post, I'll show how to do that.

## Prerequisites

- Visual Studio 2019. Though I haven't tested with VS2022, I assume "Paste JSON As Classes" is also available there.

## Convert sample JSON data to C# classes

In this post, I'll work with the *sentiment_model.zip* model to classify sentiment, which you can find in the [dotnet/samples](https://github.com/dotnet/samples/blob/main/machine-learning/models/sentimentanalysis/sentiment_model.zip) repo.

The model input has 3 columns:

- SentimentText (string)
- Label (boolean)
- SamplingKeyColumn (float32)

The model output has at least 2 columns since it uses a binary classification algorithm. For information on expected output columns based on the machine learning algorithm/task, see the [ML.NET tasks article](https://docs.microsoft.com/dotnet/machine-learning/resources/tasks#binary-classification-inputs-and-outputs).

- Score (Single). Single is a single-precision floating-point number.
- PredictedLabel (boolean)

With that in mind, let's then assume that we have sample input data in JSON format that looks as follows.

```json
{
    "SentimentText": "This was a very bad steak",
    "Label": false,
    "SamplingKeyColumn": 1.0
}
```

Inside a C# project in Visual Studio:

1. Create a C# class
   1. Right-click your project.
   2. Select **Add &gt; Class**.
   3. Provide a name for your class in the New Item dialog.
2. Copy the input JSON data sample to your clipboard.
3. Place your cursor inside the namespace block of your newly created class.
4. In the Visual Studio toolbar, select **Edit &gt; Paste Special &gt; Paste JSON as Classes**.
5. The result should look similar to the following:

    ```csharp
    public class Rootobject
    {
        public string SentimentText { get; set; }
        public bool Label { get; set; }
        public float SamplingKeyColumn { get; set; }
    }
    ```

6. Rename the class to something more descriptive like `ModelInput`. The class should look similar to the following:

    ```csharp
    public class ModelInput
    {
        public string SentimentText { get; set; }
        public bool Label { get; set; }
        public float SamplingKeyColumn { get; set; }
    }
    ```

7. Create a JSON data sample for your output. In this case it'd look something like:

    ```json
    {
        "Score": 1.0,
        "PredictedLabel": false
    }
    ```

8. Repeat steps 1-6 for your output JSON data sample. The resulting class should look similar to the following:

    ```csharp
    public class ModelOutput
    {
        public float Score { get; set; }
        public bool PredictedLabel { get; set; }
    }
    ```

It's important to note that the name of the class does not matter as long as the column names and types are the same the ones the model expects.

At this point, you can go through the process of [using the model to make predictions on new data](https://docs.microsoft.com/dotnet/machine-learning/how-to-guides/machine-learning-model-predictions-ml-net).

## Conclusion

Although the model used in this post does not have many columns, when you have many columns "Paste JSON As Classes" can significantly simplify the process of creating your input and output schema classes for ML.NET models. Happy coding!
]]&gt;</description>
      <link>https://www.lqdev.me/posts/vs-automate-mlnet-schema-generation</link>
      <guid>https://www.lqdev.me/posts/vs-automate-mlnet-schema-generation</guid>
      <pubDate>2021-08-26 18:00:00 -05:00</pubDate>
      <category>dotnet</category>
      <category>machine learning</category>
      <category>mlnet</category>
      <category>artificial intelligence</category>
      <category>tooling</category>
      <category>visual studio</category>
    </item>
    <item>
      <title>Inspect ML.NET models with Netron</title>
      <description>&lt;![CDATA[
## Introduction

Once you've trained a machine learning model, you typically serialize it and save it to a file. This serialized file contains information such as the model inputs and output schema (names, data types), the transformations and algorithms used by the model,  weights / coefficients, hyperparameters, and all other sorts of information about the model. The model file is then embedded in an end-user application such as a web API which deserializes the contents of the file and uses the model to make predictions on new data.

How the model is serialized depends on the framework you use to train your model. To standardize model serialization and interoperability, you can use something like Open Neural Network Exchange (ONNX) to represent your models if supported by the framework you're using. That's beyond the scope of this post though.

Regardless of which framework or serialization format is used, if you were to open up the model file, the contents of the model file are often not human readable or difficult to interpret. When the person who trains the model is also putting it into production, they know the format input data needs to be in to make predictions. That's not often the case though. As a result, the people putting models into production need the ability to inspect a model to get a sense of how they need to collect and preprocess input data before making predictions. That's where Netron comes in. [Netron](https://github.com/lutzroeder/Netron) is a "visualizer for neural network, deep learning, and machine learning models". In this post, I'll show how you can use Netron to inspect ML.NET models and use that information to define the model input and output schemas.

## Inspecting an ML.NET model

ML.NET models are typically serialized and saved to files with the *.zip* file extension. Using the *.zip* file extension is standard convention. However, the extension can be whatever makes the most sense to you.

A common question is, what's in the *zip* file? The easy but vague answer to that question is, a serialized version of the model. Using Netron, you can go deeper and see exactly what is inside the *zip* file. 

In this post, I'm using a pretrained ML.NET model that classifies sentiment. The model can be found in the [dotnet/samples](https://github.com/dotnet/samples/blob/main/machine-learning/models/sentimentanalysis/sentiment_model.zip) repo. The same concept applies to any other ML.NET model.

To inspect the ML.NET model using Netron:

1. [Download the model](https://github.com/dotnet/samples/raw/main/machine-learning/models/sentimentanalysis/sentiment_model.zip)
2. Navigate to [https://netron.app](https://netron.app/). Alternatively, if you'd prefer to use Netron offline, you can also [download the latest version of Netron](https://github.com/lutzroeder/netron/releases) for your operating system (Windows, Mac, or Linux). In this post, I use the web app.
3. Select **Open Model...** and use the file browser to select your ML.NET model. In this case, our model is *sentiment_model.zip*.
4. After a few seconds, a graph describing you model appears. How long it takes for your model depends on its size. The larger your model, the longer it takes to load. The nodes in the graph represent the model inputs, transformations, algorithm, and outputs.
5. Usually the top nodes represent the model inputs and the last node represents the algorithm or trainer. Click on any of the top nodes to display more information about the inputs.

    ![Sentiment Classification ML.NET model in netron](https://user-images.githubusercontent.com/11130940/130704589-61ebb612-d65f-4364-b275-bd0d4991d3cf.png)

    For this model, we see that there are 3 input properties or columns:

    - SentimentText (string)
    - Label (boolean)
    - SamplingKeyColumn (float32)

    Using this information, we can represent the model inputs as a Plain-Old-CLR-Object (POCO) in our end-user application.

    ```csharp
    public class ModelInput
    {
        public string SentimentText {get;set;}
        public bool Label {get;set;}
        public float SamplingKeyColumn {get;set;} 
    }
    ```

    ![ML.NET Netron Binary Predictor](https://user-images.githubusercontent.com/11130940/130705880-0baea2f7-7b45-408a-b60c-16acceb54079.png)

    Looking at the last node `BinaryPredXfer`, we see that the algorithm used is for binary classification or predictions. Looking at the [ML.NET tasks documentation](https://docs.microsoft.com/dotnet/machine-learning/resources/tasks#binary-classification-inputs-and-outputs), we expect to get at least two columns in the prediction output:

    - Score (Single)
    - PredictedLabel (boolean)

    Like the input, we can also represent model outputs or predictions as follows:

    ```csharp
    public class ModelOutput
    {
        public float Score {get;set;}
        public bool PredictedLabel {get;set;}
    }
    ```

    Keep in mind that the name of the class can be anything so long as the properties or column names and types match with those expected by the model.

Once you have your model inputs and outputs defined in your end-user application, you can follow the standard process of [loading your model and using it to make predictions](https://docs.microsoft.com/dotnet/machine-learning/how-to-guides/machine-learning-model-predictions-ml-net).

## Conclusion

Inspecting ML.NET models can be difficult since their serialized version is not human readable. When making predictions with ML.NET models but you're not familiar with what the input and output data should look like, use Netron to inspect the model. Then, use the information about the input data names and types, machine learning task, and algorithm to define model input and output schema classes in your end-user application. Once you've defined your model input and output, you can use the model to make predictions on new data.
]]&gt;</description>
      <link>https://www.lqdev.me/posts/inspect-mlnet-models-netron</link>
      <guid>https://www.lqdev.me/posts/inspect-mlnet-models-netron</guid>
      <pubDate>2021-08-25 18:00:00 -05:00</pubDate>
      <category>dotnet</category>
      <category>machine learning</category>
      <category>mlnet</category>
      <category>netron</category>
      <category>artificial intelligence</category>
      <category>tooling</category>
    </item>
    <item>
      <title>Train an image classifier using F# and ML .NET</title>
      <description>&lt;![CDATA[
# Introduction

This post is part of F# Advent 2020. Thank you to [Sergey Tihon](https://twitter.com/sergey_tihon) for organizing this and the rest of the contributors for producing high-quality content. Make sure to check out the rest of the [F# Advent 2020 content](https://sergeytihon.com/2020/10/22/f-advent-calendar-in-english-2020/).

When picking who's on the naughty or nice list, I often wonder how Santa decides. I took a shot at answering this question by training an image classifier using the ML.NET image classification API and images of Disney heroes and villains to tell whether they're naughty or nice. You shouldn't judge someone by the way they look (even if they are the Evil Queen), so it's safe to say, don't try this at home or with your neighbors 😉. This sample is just for demo purposes. You can find the full code on [GitHub](https://gist.github.com/lqdev/0c4dc9eea93b7b8541f31ddd429afb53).

## Prerequisites

This sample was built on a Windows 10 PC, but should work on Mac / Linux PCs

- [.NET 5 SDK](https://dotnet.microsoft.com/download)

## The data

The dataset contains images of Disney characters, both real and animated. They were obtained from the [Disney Fandom Wiki](https://disney.fandom.com/wiki/The_Disney_Wiki). The characters are split into two categories, [villains](https://disney.fandom.com/wiki/Category:Villains) and [heroes](https://disney.fandom.com/wiki/Category:Protagonists). For the purpose of this sample, we'll label heroes as nice and villains as naughty. The dataset used to train this model contains 2400 villain (naughty) and 675 hero (nice) images stored in top-level directories with the naughty/nice names. This means that the dataset is unbalanced and may skew predictions as it can be seen when making predictions.

## Install  NuGet packages

Use the `#r` convention to install the necessary NuGet packages used in this sample.

```fsharp
#r "nuget:Microsoft.ML"
#r "nuget:Microsoft.ML.Vision"
#r "nuget:Microsoft.ML.ImageAnalytics"
#r "nuget:SciSharp.TensorFlow.Redist" 
```

Then, import the packages.

```fsharp
open System
open System.IO
open Microsoft.ML
open Microsoft.ML.Data
open Microsoft.ML.Vision
```

## Define data types

Start off by defining the data types containing your input and output schema. You can do this by creating two records, `ImageData` and `ImagePrediction`. `ImageData` is the input which contains the path to image file and the category it belongs to and the `ImagePrediction` contains the prediction generated by the model.

```fsharp
[&lt;CLIMutable&gt;]
type ImageData = {
    ImagePath: string
    Label: string
}

[&lt;CLIMutable&gt;]
type ImagePrediction = {
    PredictedLabel: string
}
```

## Training

The training process loads a set of training images, preprocesses them, and uses the ML.NET image classification API to train an image classification model. 

### Initialize MLContext

Once you've defined the data type, initialize the `MLContext`. `MLContext` is the entrypoint for ML.NET applications.

```fsharp
let ctx = new MLContext()
```

### Load training data

Then, load the data using the helper function `loadImagesFromDirectory` and point it to the top-level directory containing the subdirectories of images in the nice and naughty categories.

```fsharp
let imageData = loadImagesFromDirectory "C:/Datasets/fsadvent2020/Train" true
```

The `loadImagesFromDirectory` function looks like the following:

```fsharp
let loadImagesFromDirectory (path:string) (useDirectoryAsLabel:bool) = 

    let files = Directory.GetFiles(path, "*",searchOption=SearchOption.AllDirectories)

    files
    |&gt; Array.filter(fun file -&gt; 
        (Path.GetExtension(file) = ".jpg") ||
        (Path.GetExtension(file) = ".png"))
    |&gt; Array.map(fun file -&gt; 
        let mutable label = Path.GetFileName(file)
        if useDirectoryAsLabel then
            label &lt;-  Directory.GetParent(file).Name
        else
            let mutable brk = false
            for index in 0..label.Length do
                while not brk do
                    if not (label.[index] |&gt; Char.IsLetter) then
                        label &lt;- label.Substring(0,index)
                        brk &lt;- true

        {ImagePath=file; Label=label}
    )
```

Then, create an `IDataView` for the training images. An `IDataView` is the way data is represented in ML.NET.

```fsharp
let imageIdv = ctx.Data.LoadFromEnumerable&lt;ImageData&gt;(imageData)
```

### Define training pipeline

Once your data is is loaded into an `IDataView`, set the classifier options by using `ImageClassificationTrainer.Options`. Use it to define the name of the network architecture, input and output columns, and some additional parameters. The network architecture used in this case is [`ResNet V2`](https://www.paperswithcode.com/method/inception-resnet-v2).

```fsharp
let classifierOptions = ImageClassificationTrainer.Options()
classifierOptions.FeatureColumnName &lt;- "Image" 
classifierOptions.LabelColumnName &lt;- "LabelKey" 
classifierOptions.TestOnTrainSet &lt;- true  
classifierOptions.Arch &lt;- ImageClassificationTrainer.Architecture.ResnetV2101
classifierOptions.MetricsCallback &lt;- Action&lt;ImageClassificationTrainer.ImageClassificationMetrics&gt;(fun x -&gt; printfn "%s" (x.ToString()))
```

Define the preprocessing steps, image classification trainer (along with the previously defined options) and postprocessing steps.

```fsharp
let pipeline = 
    EstimatorChain()
        .Append(ctx.Transforms.LoadRawImageBytes("Image",null,"ImagePath"))
        .Append(ctx.Transforms.Conversion.MapValueToKey("LabelKey","Label"))
        .Append(ctx.MulticlassClassification.Trainers.ImageClassification(classifierOptions))
        .Append(ctx.Transforms.Conversion.MapKeyToValue("PredictedLabel"))
```

The ML.NET image classification API leverages a technique known as transfer learning. Transfer learning uses pretrained models (usually neural networks) and retrains the last few layers using new data. This significantly cuts down the amount of time, resources, and data you need to train deep learning models. ML .NET is able to do this with the help of [TensorFlow .NET](https://github.com/SciSharp/TensorFlow.NET), a set of .NET bindings for the TensorFlow deep learning framework. Although transfer learning usually makes the process of training a deep learning models less resource intensive, the TensorFlow API is usually low level and still requires a significant amount of code. See this [transfer learning example](https://github.com/SciSharp/SciSharp-Stack-Examples/blob/master/src/TensorFlowNET.Examples/ImageProcessing/TransferLearningWithInceptionV3.cs) from TensorFlow.NET to see how you'd do it in TensorFlow.NET. Although the low-level nature of the TensorFlow API gives you control over what you're building, many times you don't need that level of control. ML.NET through the image classification trainer greatly simplifies this process by providing a high-level API for achieving the same task.

To train the model, use the `Fit` method on the training image `IDataView`.

```fsharp
let model = pipeline.Fit(imageIdv)
```

Throughout the training process, you should see output similar to the following:

```console
Phase: Bottleneck Computation, Dataset used:      Train, Image Index: 279
Phase: Bottleneck Computation, Dataset used:      Train, Image Index: 280
Phase: Bottleneck Computation, Dataset used: Validation, Image Index:   1
```

With the model trained, it's time to use it to make predictions. Optionally, you can save it for use in other applications.

```fsharp
ctx.Model.Save(model,imageIdv.Schema,"fsadvent2020-model.zip")
```

## Make predictions

Load the test images and create an `IDataView` for them. The test images used are of Jack Skellington and The Grinch.

```fsharp
let testImages = 
    Directory.GetFiles("C:/Datasets/fsadvent2020/Test")
    |&gt; Array.map(fun file -&gt; {ImagePath=file; Label=""})

let testImageIdv = ctx.Data.LoadFromEnumerable&lt;ImageData&gt;(testImages)
```

![The grinch](https://www.khwiki.com/images/thumb/f/ff/Jack_Skellington_KHII.png/180px-Jack_Skellington_KHII.png)

Then, use the model to make predictions.

```fsharp
let predictionIdv = model.Transform(testImageIdv)
```

One of the easiest ways to access the predictions is to create an `IEnumerable`. To do so, use the `CreateEnumerable` method.

```fsharp
let predictions = ctx.Data.CreateEnumerable&lt;ImagePrediction&gt;(predictionIdv,false)
```

Then, use the built-in F# sequence operations to display the predictions 

```fsharp
predictions |&gt; Seq.iter(fun pred -&gt; 
    printfn "%s is %s" (Path.GetFileNameWithoutExtension(pred.ImagePath)) pred.PredictedLabel)
```

The output should look like the following:

```console
grinch is Naughty
jack is Naughty
```

## Conclusion

In this post, I showed how you can use the ML.NET and TensorFlow.NET to train an image classification model to classify Disney characters as naughty or nice. Depending on the level of control you need, you might choose to use TensorFlow.NET or if you want a high-level API for training an image classifier, you can use the ML.NET. Most importantly, we figured out that Jack Skellington and The Grinch are naughty, so I guess no gifts for them this year? Happy coding!

### Call to Action

Originally, I had planned on writing this article using [TensorFlow.Keras](https://github.com/SciSharp/TensorFlow.NET), which is part of the SciSharp TensorFlow.NET project. TensorFlow.Keras provides .NET bindings for Keras. Keras provides a high-level API for TensorFlow which makes the process of building custom neural networks much simpler than working with the TensorFlow API. Unfortunately, while trying to adapt my scenario to an [existing sample](https://github.com/SciSharp/SciSharp-Stack-Examples/blob/master/src/TensorFlowNET.Examples/ImageProcessing/ImageClassificationKeras.cs), I ran into an [issue](https://github.com/SciSharp/SciSharp-Stack-Examples/issues/23).  This is not something I would have been able to resolve in time to publish this post, so I defaulted to using ML.NET.

I'm a big fan of the work being done by the SciSharp community and the machine learning and data science capabilities it brings to the .NET ecosystem. The work and efforts are all community driven, and as such, there's plenty of opportunities to contribute. Here are just some examples of ways to contribute, especially from an F# perspective. From my end, I plan on eventually converting this sample to use TensorFlow.Keras. See you in the SciSharp repos! 🙂

![FsLab SciSharp contribute](https://user-images.githubusercontent.com/11130940/102030239-f4ac3700-3d7f-11eb-9898-f18990a56326.png)
]]&gt;</description>
      <link>https://www.lqdev.me/posts/image-classification-mlnet-fsadvent2020</link>
      <guid>https://www.lqdev.me/posts/image-classification-mlnet-fsadvent2020</guid>
      <pubDate>2020-12-14 20:03:18 -05:00</pubDate>
      <category>image classification</category>
      <category>mlnet</category>
      <category>fsharp</category>
      <category>dotnet</category>
      <category>deep learning</category>
      <category>fsadvent2020</category>
      <category>tensorflow</category>
    </item>
    <item>
      <title>Deploy ML.NET Machine Learning Model in Blazor WebAssembly Static Website</title>
      <description>&lt;![CDATA[
## Introduction

There are many ways of deploying machine learning models. The most common way to do so is by exposing models as a web service through APIs or serverless functions. One of the considerations when deploying a model as a web service is latency and performance. The process of making predictions over HTTP using a model involves accepting the user input, loading the serialized version of the model from a file, using the model to make a prediction, and returning the prediction back to the user. Since models are typically just static files, another way of deploying a model is as a static asset over the web, just like any other HTML, CSS, or JavaScript file. This deployment method is similar to that of TensorFlow.js. Deploying in this way has several advantages. One advantage is that there is no longer a web service just to serve the model, making it more cost-efficient. Another advantage is that once the model has been downloaded onto the user's PC, the resources used at that point are those of the user's PC rather than the server the model would otherwise be hosted in. Finally, because the model is a static file, it can be distributed via CDNs. 

One of the challenges with this is that machine learning models are usually built using languages other than JavaScript. This makes using the same code / library the model was built difficult or nearly impossible. WebAssembly is changing that by allowing Rust, C++, C# and other languages to run natively inside the browser. Having that ability, the code / logic to load the model and make predictions is much easier and almost comparable to that of a native platform. Blazor WebAssembly provides users the ability to create modern component-based web applications completely in C#. Additionally, Blazor WebAssembly allows users to publish and deploy their applications as static websites in an easy and cost-efficient way. ML.NET is an open-source, cross-platform framework that allows developers to create machine learning models using .NET. In this post, I'll show how to train a multiclass classification machine learning model that predicts iris flower species. Then, I'll take that model and deploy it alongside a Blazor WebAssembly static website to Azure Storage. The full code for this application may be found at the [MLNETBlazorWASMSample repository on GitHub](https://github.com/lqdev/MLNETBlazorWASMSample).

## Prerequisites

This project was built on a Windows PC but should work cross platform on Mac and Linux.

- [.NET Core SDK 3.1](https://dotnet.microsoft.com/download/dotnet-core/3.1)
- [Blazor WebAssembly Template](https://www.nuget.org/packages/Microsoft.AspNetCore.Blazor.Templates/3.2.0-preview1.20073.1)
- [Azure Subscription](http://aka.ms/amlFree)
- [Azure Storage Explorer](https://azure.microsoft.com/en-us/features/storage-explorer/)

## Set up the solution

The solution built in this post contains three projects:

- SchemaLibrary: C# .NET Standard 2.0 class library that contains the schema definition classes of the data used to train the model as well as the prediction output generated by the model.
- TrainingConsole: C# .NET Core 3.1 console application used to train the machine learning model.
- BlazorWebApp: Blazor WebAssembly web application to make predictions using machine learning model trained by TrainingConsole application.

### Install Blazor WebAssembly Template

Use the .NET CLI to run the following command in the command prompt:

```powershell
dotnet new -i Microsoft.AspNetCore.Blazor.Templates::3.2.0-preview1.20073.1
```

### Create the solution

Create a new directory for the solution called *MLNETBlazorWASMSample*.

```powershell
mkdir MLNETBlazorWASMSample
```

Navigate to the newly created solution directory and create a solution:

```powershell
cd MLNETBlazorWASMSample
dotnet new sln
```

### Create schema class library

The data schema for the model input and output are shared during training as well as when making predictions. To share resources, create a class library that's shared by the `ConsoleTraining` and `BlazorWebApp` projects. In the solution directory, enter the following command:

```powershell
dotnet new classlib -o SchemaLibrary
```

Install the *Microsoft.ML* NuGet package (This solution is built with version 1.4.0). The *Microsoft.ML* package is used throughout the entire solution.

```powershell
dotnet add SchemaLibrary package Microsoft.ML
```

Add the library project to the solution.

```powershell
dotnet sln add SchemaLibrary
```

### Create the training console application

The console application contains the series of data transformations and algorithms used to train the model. In the solution directory, create a new console application.

```powershell
dotnet new console -o TrainingConsole
```

Add the console application to the solution.

```powershell
dotnet sln add TrainingConsole
```

Reference the *SchemaLibrary* project.

```powershell
dotnet add TrainingConsole reference SchemaLibrary
```

### Create the Blazor WebAssembly web application

The web application contains a few input elements so users can provide new data that the model then uses to make predictions. In the solution directory, create a new Blazor WebAssembly application.

```powershell
dotnet new blazorwasm -o BlazorWebApp
```

Add the web application project to the solution.

```powershell
dotnet sln add BlazorWebApp
```

Reference the *SchemaLibrary* project.

```powershell
dotnet add BlazorWebApp reference SchemaLibrary
```

## Define the schema

### Understand the data

The data used to train the model comes from the [iris dataset](https://archive.ics.uci.edu/ml/datasets/Iris). It contains four numerical columns which are sepal and petal measurements and one numerical column for the species of iris flower. This is a sample of the data.

|Sepal length (cm)  |Sepal width (cm)  |Petal length (cm)  |Petal width (cm)  |Class (iris species)  |
|---------|---------|---------|---------|---------|
|5.1|3.5|1.4|0.2|Iris-setosa|
|7.0|3.2|4.7|1.4|Iris-versicolor|
|6.3|3.3|6.0|2.5|Iris-virginica|

### Define model input schema

In the *SchemaLibrary* project, create a class called `ModelInput` to model the data used for training and as model input.

```powershell
ni ModelInput.cs
```

The `ModelInput` class should look like the following:

```csharp
using Microsoft.ML.Data;

namespace SchemaLibrary
{
    public class ModelInput
    {
        [LoadColumn(0)]
        public float SepalLength { get; set; }

        [LoadColumn(1)]
        public float SepalWidth { get; set; }

        [LoadColumn(2)]
        public float PetalLength { get; set; }

        [LoadColumn(3)]
        public float PetalWidth { get; set; }

        [LoadColumn(4)]
        public string Label { get; set; }
    }
}
```

Notice that the `Class` column is now a property called `Label`. This is for two reasons:

1. Avoid using the `class` keyword.
2. In ML.NET, the default column name of the column to predict expected by algorithms is `Label`.

Also notice the `LoadColumn` attributes at the top of each property. This is used to tell the loader the index of the column where the data for the respective property is.

### Define model output schema

Similar to the input schema, there's a schema for the output of the model. The type of model used in this solution is a multiclass classification model since there are more than two categories to choose from for iris flower species. Multiclass classification models output a column called `PredictedLabel` which contains the name of the predicted category. In the *SchemaLibrary* project, create a class called `ModelOutput` to model the predictions made by the model.

```powershell
ni ModelOutput.cs
```

The `ModelOutput` class should look like the following:

```csharp
namespace SchemaLibrary
{
    public class ModelOutput
    {
        public string PredictedLabel { get; set; }
    }
}
```

## Train the model

Now it's time to create the application that trains the model.

### Get the data

Download the data and save it inside the *TrainingConsole* project directory.

```powershell
curl https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data -o iris.data
```

### Define the data preparation and training steps

In the *TrainingConsole* project, open the *Program.cs* file and add the following using statements at the top:

```csharp
using System;
using System.Linq;
using Microsoft.ML;
using SchemaLibrary;
```

Then, delete the contents inside the `Main` method and replace it with the following.

```csharp
// 1. Initialize MLContext
MLContext mlContext = new MLContext();

// 2. Load the data
IDataView data = mlContext.Data.LoadFromTextFile&lt;ModelInput&gt;("iris.data", separatorChar:',');

// 3. Shuffle the data
IDataView shuffledData = mlContext.Data.ShuffleRows(data);

// 3. Define the data preparation and training pipeline.
IEstimator&lt;ITransformer&gt; pipeline = 
    mlContext.Transforms.Concatenate("Features","SepalLength","SepalWidth","PetalLength","PetalWidth")
        .Append(mlContext.Transforms.NormalizeMinMax("Features"))
        .Append(mlContext.Transforms.Conversion.MapValueToKey("Label"))
        .Append(mlContext.MulticlassClassification.Trainers.NaiveBayes())
        .Append(mlContext.Transforms.Conversion.MapKeyToValue("PredictedLabel"));

// 4. Train with cross-validation
var cvResults = mlContext.MulticlassClassification.CrossValidate(shuffledData, pipeline);

// 5. Get the highest performing model and its accuracy
(ITransformer, double) model = 
    cvResults
        .OrderByDescending(fold =&gt; fold.Metrics.MacroAccuracy)
        .Select(fold =&gt; (fold.Model, fold.Metrics.MacroAccuracy))
        .First();

Console.WriteLine($"Top performing model's macro-accuracy: {model.Item2}");

// 6. Save the model
mlContext.Model.Save(model.Item1, data.Schema, "model.zip");

Console.WriteLine("Model trained");
```

The training application loads the data from the `iris.data` file and applies a series of transformations. First, all of the individual numerical columns are combined into a single vector and stored in a new column called `Features`. The `Features` column is then normalized and the `MapValueToKey` transform is used to convert the text in the `Label` column to a number. Then, the transformed data is used to train a model using the `NaiveBayes` algorithm. **Note that at the time of this writing, for multiclass classification problems, only Naive Bayes has been confirmed to work with Blazor WebAssembly**. Finally, the `PredictedLabel` is stored as a number so it has to be converted back into text.

Using the `Fit` method, the data is applied to the pipeline. Because the dataset is small, a technique called cross-validation is used to build a more robust model. Once the model is trained, the model with the top performance is then serialized and saved to a file called *model.zip* for later use in the web application.

The final *Program.cs* file should look like the content below:

```csharp
using System;
using System.Linq;
using Microsoft.ML;
using SchemaLibrary;

namespace TrainingConsole
{
    class Program
    {
        static void Main(string[] args)
        {
            // 1. Initialize MLContext
            MLContext mlContext = new MLContext();

            // 2. Load the data
            IDataView data = mlContext.Data.LoadFromTextFile&lt;ModelInput&gt;("iris.data", separatorChar:',');

            // 3. Shuffle the data
            IDataView shuffledData = mlContext.Data.ShuffleRows(data);

            // 3. Define the data preparation and training pipeline.
            IEstimator&lt;ITransformer&gt; pipeline = 
                mlContext.Transforms.Concatenate("Features","SepalLength","SepalWidth","PetalLength","PetalWidth")
                    .Append(mlContext.Transforms.NormalizeMinMax("Features"))
                    .Append(mlContext.Transforms.Conversion.MapValueToKey("Label"))
                    .Append(mlContext.MulticlassClassification.Trainers.NaiveBayes())
                    .Append(mlContext.Transforms.Conversion.MapKeyToValue("PredictedLabel"));

            // 4. Train with cross-validation
            var cvResults = mlContext.MulticlassClassification.CrossValidate(shuffledData, pipeline);

            // 5. Get the highest performing model and its accuracy
            (ITransformer, double) model = 
                cvResults
                    .OrderByDescending(fold =&gt; fold.Metrics.MacroAccuracy)
                    .Select(fold =&gt; (fold.Model, fold.Metrics.MacroAccuracy))
                    .First();

            Console.WriteLine($"Top performing model's macro-accuracy: {model.Item2}");

            // 6. Save the model
            mlContext.Model.Save(model.Item1, data.Schema, "model.zip");

            Console.WriteLine("Model trained");
        }
    }
}
```

### Run the application

In the *TrainConsole* project directory, use the following command to run the application and train the model:

```powershell
dotnet run
```

## Host the model

Once you have the model saved, use the Azure Portal to create an Azure Storage account.

![Create Azure Storage Account](http://cdn.lqdev.tech/files/images/deploy-machine-learning-mlnet-model-blazor-webassembly1.png)

Then, navigate to your newly created storage account resource and create a blob container called `models`.

![Create Blob Container](http://cdn.lqdev.tech/files/images/deploy-machine-learning-mlnet-model-blazor-webassembly2.png)

Once your container is created, navigate to it and upload the *model.zip* file.

![Upload Model](http://cdn.lqdev.tech/files/images/deploy-machine-learning-mlnet-model-blazor-webassembly3.png)

## Create prediction web page

To make predictions, create a web page to take in user input. Then, provide the user input to the model and display the prediction to the user.

### Set up imports

In the *BlazorWebApp* project directory, open the *_Imports.razor* file. This contains the using statements for the pages and components in your application. Add the following using statements:

```razor
@using System.IO
@using Microsoft.ML
@using SchemaLibrary
```

### Create user input page

In the *BlazorWebApp* project, create a new razor page called *Prediction.razor* inside the *Pages* directory.

```powershell
ni Prediction.razor
```

Add the following content to it:

```razor
@page "/prediction"
@inject HttpClient _client

&lt;label&gt;Sepal Length: &lt;/label&gt;
&lt;input type="text" @bind="_sepalLength"&gt;&lt;br&gt;
&lt;label&gt;Sepal Width: &lt;/label&gt;
&lt;input type="text" @bind="_sepalWidth"&gt;&lt;br&gt;
&lt;label&gt;Petal Length: &lt;/label&gt;
&lt;input type="text" @bind="_petalLength"&gt;&lt;br&gt;
&lt;label&gt;Petal Width: &lt;/label&gt;
&lt;input type="text" @bind="_petalWidth"&gt;&lt;br&gt;
&lt;button @onclick="GetPrediction"&gt;Make prediction&lt;/button&gt;
@if(@ModelPrediction == null)
{
    &lt;p&gt;Enter data to get a prediction&lt;/p&gt;
} else
{
    &lt;p&gt;@ModelPrediction&lt;/p&gt;
}


@code {
    private PredictionEngine&lt;ModelInput,ModelOutput&gt; _predictionEngine;
    private string _sepalLength, _sepalWidth, _petalLength, _petalWidth, ModelPrediction;

    protected override async Task OnInitializedAsync()
    {
        Stream savedModel = await _client.GetStreamAsync("&lt;YOUR-MODEL-ENDPOINT&gt;");
        MLContext mlContext = new MLContext();
        ITransformer _model = mlContext.Model.Load(savedModel,out DataViewSchema schema);
        _predictionEngine = mlContext.Model.CreatePredictionEngine&lt;ModelInput,ModelOutput&gt;(_model);
    }

    private void GetPrediction()
    {
        ModelInput input = new ModelInput
        {
            SepalLength=float.Parse(_sepalLength),
            SepalWidth=float.Parse(_sepalWidth),
            PetalLength=float.Parse(_petalLength),
            PetalWidth=float.Parse(_petalWidth)
        };

        ModelOutput prediction = _predictionEngine.Predict(input);

        ModelPrediction = prediction.PredictedLabel;
    }
}
```

The *Predict.razor* page contains a text input element for each of the columns the model was original trained on. When the page is initialized, the model is loaded from Azure Storage and a `PredictionEngine` is created. **Make sure to replace `&lt;YOUR-MODEL-ENDPOINT&gt;` with the URL of the blob that contains your `model.zip`**. A `PredictionEngine` is a convenience API to make a single prediction. Traditionally when models are served as a web service, it is recommended to use the `PredictionEnginePool` service because it's thread-safe and more performant in multi-threaded application. However, in this case since the model is downloaded onto the individual user's browser, it's okay to use `PredictionEngine`. After a user enters input values and clicks the "Make Prediction" button, the `GetPrediction` method executes by taking the user input and making a prediction using the `PredictionEngine`. The prediction is then displayed in the browser.

### Add to navigation menu

In the *BlazorWebApp* project, open the *NavMenu.razor* file in the *Shared* directory.

Add the following list item to the `&lt;ul&gt;` element.

```html
&lt;li class="nav-item px-3"&gt;
    &lt;NavLink class="nav-link" href="prediction"&gt;
        &lt;span class="oi oi-list-rich" aria-hidden="true"&gt;&lt;/span&gt; Prediction
    &lt;/NavLink&gt;
&lt;/li&gt;
```

The final *NavMenu.razor* page should look like the following:

```razor
&lt;div class="top-row pl-4 navbar navbar-dark"&gt;
    &lt;a class="navbar-brand" href=""&gt;BlazorWebApp&lt;/a&gt;
    &lt;button class="navbar-toggler" @onclick="ToggleNavMenu"&gt;
        &lt;span class="navbar-toggler-icon"&gt;&lt;/span&gt;
    &lt;/button&gt;
&lt;/div&gt;

&lt;div class="@NavMenuCssClass" @onclick="ToggleNavMenu"&gt;
    &lt;ul class="nav flex-column"&gt;
        &lt;li class="nav-item px-3"&gt;
            &lt;NavLink class="nav-link" href="" Match="NavLinkMatch.All"&gt;
                &lt;span class="oi oi-home" aria-hidden="true"&gt;&lt;/span&gt; Home
            &lt;/NavLink&gt;
        &lt;/li&gt;
        &lt;li class="nav-item px-3"&gt;
            &lt;NavLink class="nav-link" href="counter"&gt;
                &lt;span class="oi oi-plus" aria-hidden="true"&gt;&lt;/span&gt; Counter
            &lt;/NavLink&gt;
        &lt;/li&gt;
        &lt;li class="nav-item px-3"&gt;
            &lt;NavLink class="nav-link" href="fetchdata"&gt;
                &lt;span class="oi oi-list-rich" aria-hidden="true"&gt;&lt;/span&gt; Fetch data
            &lt;/NavLink&gt;
        &lt;/li&gt;
        &lt;li class="nav-item px-3"&gt;
            &lt;NavLink class="nav-link" href="prediction"&gt;
                &lt;span class="oi oi-list-rich" aria-hidden="true"&gt;&lt;/span&gt; Prediction
            &lt;/NavLink&gt;
        &lt;/li&gt;
    &lt;/ul&gt;
&lt;/div&gt;

@code {
    private bool collapseNavMenu = true;

    private string NavMenuCssClass =&gt; collapseNavMenu ? "collapse" : null;

    private void ToggleNavMenu()
    {
        collapseNavMenu = !collapseNavMenu;
    }
}
```

## Configure the web application

The web application will he hosted as a static site on Azure Storage.

In the Azure Portal, navigate to the storage account resource where you are hosting your model.

### Enable static website

Enable a static website for the storage account and set the index document name and error document path to *index.html*.

![Enable Static Website](http://cdn.lqdev.tech/files/images/deploy-machine-learning-mlnet-model-blazor-webassembly4.png)

At this point, a new container called *$web* is created in your storage account. This is where all your site's static files will reside. Additionally, a primary endpoint is created. This is the URL you will use to access your application

### Configure CORS

The storage account has some default CORS settings. In order to download and use your model from your application, you'll have to configure them.

![Configure CORS](http://cdn.lqdev.tech/files/images/deploy-machine-learning-mlnet-model-blazor-webassembly5.png)

For "Allowed origins", enter your primary endpoint.

## Publish and deploy the web application

To publish your application, run the following command:

```powershell
dotnet publish -c Release
```

This generates all the files you'll need to host your web application as a static site in the *bin/Release/netstandard2.1/publish/BlazorWebApp/dist* directory of your *BlazorWebApp* project.

To deploy your application, use Azure Storage Explorer to copy all of the files in the *dist* directory into the *$web* container of your Azure Storage Account.

![Copy files into web container](http://cdn.lqdev.tech/files/images/deploy-machine-learning-mlnet-model-blazor-webassembly6.png)

## Test the application

In your browser, navigate to your static website's primary endpoint and select the Prediction page. Input data and click "Make prediction". The page should look as follows. 

![Test the application](http://cdn.lqdev.tech/files/images/deploy-machine-learning-mlnet-model-blazor-webassembly7.png)

**You may note that performance of Naive Bayes on this dataset is not the best so some of the predictions may not be as accurate. I am okay with this at the moment because this is a proof-of-concept to show how these technologies might work together. Perhaps using a better dataset may yield better results.**

## Conclusion

In this post, I went over how to deploy an ML.NET multiclass classification model alongside a Blazor WebAssembly static website to Azure Storage. While more limited than other methods of deployment due to the early stages of WebAssembly and Blazor WebAssembly, this shows the possibilities for the technologies. Deploying in this manner reduces the amount of resources required to deploy these models and shifts processing from a server or web service to the client's browser making deployment and distribution of machine learning models more efficient, scalable and cost-efficient.
]]&gt;</description>
      <link>https://www.lqdev.me/posts/deploy-machine-learning-mlnet-models-blazor-webassembly</link>
      <guid>https://www.lqdev.me/posts/deploy-machine-learning-mlnet-models-blazor-webassembly</guid>
      <pubDate>2020-03-01 19:21:04 -05:00</pubDate>
      <category>azure</category>
      <category>staticwebsites</category>
      <category>machinelearning</category>
      <category>ai</category>
      <category>artifificalintelligence</category>
      <category>ml</category>
      <category>dotnet</category>
      <category>dotnetcore</category>
      <category>webassembly</category>
      <category>webdevelopment</category>
      <category>mldotnet</category>
      <category>mlnet</category>
      <category>blazor</category>
    </item>
    <item>
      <title>Restaurant Inspections ETL &amp; Data Enrichment with Spark.NET and ML.NET Automated (Auto) ML</title>
      <description>&lt;![CDATA[
## Introduction

Apache Spark is an open-source, distributed, general-purpose analytics engine. For years, it has been a staple in the Big Data ecosystem for batch and real-time processing on large datasets. Although native support for the platform is limited to the JVM set of languages, other languages typically used for data processing and analytics like Python and R have plugged into Spark's Interop layer to make use of its functionality. Around the Build 2019 conference, Microsoft announced Spark.NET. Spark.NET provides bindings written for the Spark Interop layer that allow you to work with components like Spark SQL and Spark Streaming inside your .NET applications. Because Spark.NET is .NET Standard 2.0 compliant, it can run operating systems like Windows, Mac and Linux. Spark.NET is an evolution of the Mobius project which provided .NET bindings for Spark.

This sample takes a restaurant violation dataset from the NYC Open Data portal and processes it using Spark.NET. Then, the processed data is used to train a machine learning model that attempts to predict the grade an establishment will receive after an inspection. The model will be trained using ML.NET, an open-source, cross-platform machine learning framework. Finally, data for which no grade currently exists will be enriched using the trained model to assign an expected grade.

The source code for this sample can be found in the [lqdev/RestaurantInspectionsSparkMLNET
GitHub repo](https://github.com/lqdev/RestaurantInspectionsSparkMLNET).

## Pre-requisites

This project was built using Ubuntu 18.04 but should work on Windows and Mac devices.

- [.NET Core 2.1 SDK](https://dotnet.microsoft.com/download/dotnet-core/2.1)
- [Java 8](https://www.java.com/en/download/)
- [Apache Spark 2.4.1 with Hadoop 2.7](https://archive.apache.org/dist/spark/spark-2.4.1/)
- [.NET Spark Worker 0.4.0](https://github.com/dotnet/spark/releases)

### Install Java

Since Spark runs on the JVM, you'll need Java on your PC. The minimum version required is version 8. To install and Java, enter the following command into the terminal:

```bash
sudo apt install openjdk-8-jdk openjdk-8-jre
```

Then, make sure that the recently installed version is the default

```bash
sudo update-alternatives --config java
```

### Download and configure Spark

Download Spark 2.4.1 with Hadoop 2.7 onto your computer. In this case, I'm placing it into my *Downloads* folder.

```bash
wget https://archive.apache.org/dist/spark/spark-2.4.1/spark-2.4.1-bin-hadoop2.7.tgz -O ~/Downloads/spark-2.4.1-bin-hadoop2.7.tgz
```

Extract the contents of the recently downloaded file into the */usr/bin/local* directory.

```bash
sudo tar -xvf ~/Downloads/spark-2.4.1-bin-hadoop2.7.tgz --directory /usr/local/bin
```

### Download and configure .NET Spark Worker

Download the .NET Spark worker onto your computer. In this case, I'm placing it into the *Downloads* folder.

```bash
wget https://github.com/dotnet/spark/releases/download/v0.4.0/Microsoft.Spark.Worker.netcoreapp2.1.linux-x64-0.4.0.tar.gz -O ~/Downloads/Microsoft.Spark.Worker.netcoreapp2.1.linux-x64-0.4.0.tar.gz
```

Extract the contents of the recently downloaded file into the */usr/bin/local* directory.

```bash
sudo tar -xvf ~/Downloads/Microsoft.Spark.Worker.netcoreapp2.1.linux-x64-0.4.0.tar.gz --directory /usr/local/bin
```

Finally, raise the permissions on the `Microsoft.Spark.Worker` program. This is required to execute User-Defined Functions (UDF).

```bash
sudo chmod +x /usr/local/bin/Microsoft.Spark.Worker-0.4.0/Microsoft.Spark.Worker
```

### Configure environment variables

Once you download and configure the pre-requisites, configure their locations in the system as environment variables. Open the *~/.bashrc* file and add the following content at the end of the file.

```bash
export SPARK_PATH=/usr/local/bin/spark-2.4.1-bin-hadoop2.7
export PATH=$SPARK_PATH/bin:$PATH
export HADOOP_HOME=$SPARK_PATH
export SPARK_HOME=$SPARK_PATH
export DOTNET_WORKER_DIR=/usr/local/bin/Microsoft.Spark.Worker-0.4.0
```

## Solution description

### Understand the data

The dataset used in this solution is the [*DOHMH New York City Restaurant Inspection Results*](https://data.cityofnewyork.us/Health/DOHMH-New-York-City-Restaurant-Inspection-Results/43nn-pn8j) and comes from the NYC Open Data portal. It is updated daily and contains assigned and pending inspection results and violation citations for restaurants and college cafeterias. The dataset excludes establishments that have gone out of business. Although the dataset contains several columns, only a subset of them are used in this solution. For a detailed description of the dataset, visit the dataset website.

### Understand the solution

This solution is made up of four different .NET Core applications:

- *RestaurantInspectionsETL*: .NET Core Console application that takes raw data and uses Spark.NET to clean and transform the data into a format that is easier to use as input for training and making predictions with a machine learning model built with ML.NET.
- *RestaurantInspectionsML*: .NET Core Class Library that defines the input and output schema of the ML.NET machine learning model. Additionally, this is where the trained model is saved to.
- *RestaurantInspectionsTraining*: .NET Core Console application that uses the graded data generated by the *RestaurantInspectionsETL* application to train a multiclass classification machine learning model using ML.NET's Auto ML.
- *RestaurantInspectionsEnrichment*: .NET Core Console application that uses the ungraded data generated by the *RestaurantInspectionsETL* application as input for the trained ML.NET machine learning model which predicts what grade an establishment is most likely to receive based on the violations found during inspection.

## Set up the solution

### Create solution directory

Create a new directory for your projects called *RestaurantInspectionsSparkMLNET* and navigate to it with the following command.

```bash
mkdir RestaurantInspectionsSparkMLNET &amp;&amp; cd RestaurantInspectionsSparkMLNET
```

Then, create a solution using the `dotnet cli`.

```bash
dotnet new sln
```

To ensure that the 2.1 version of the .NET Core SDK is used as the target framework, especially if you have multiple versions of the .NET SDK installed, create a file called *globals.json* in the *RestaurantInspectionsSparkMLNET* solution directory.

```bash
touch global.json
```

In the *global.json* file, add the following content. Make sure to use the specific version of the SDK installed on your computer. In this case, I have version `2.1.801` installed on my computer. You can use the `dotnet --list-sdks` command to list the installed SDK versions.

```json
{
  "sdk": {
    "version": "2.1.801"
  }
}
```

### Create and configure the ETL project

The ETL project is responsible for taking the raw source data and using Spark to apply a series of transformations to prepare the data to train the machine learning model as well as to enrich data with missing grades.

Inside the *RestaurantInspectionsSparkMLNET* solution directory, create a new console application called *RestaurantInspectionsETL* using the `dotnet cli`.

```bash
dotnet new console -o RestaurantInspectionsETL
```

Add the newly created project to the solution with the `dotnet cli`.

```bash
dotnet sln add ./RestaurantInspectionsETL/
```

Since this project uses the `Microsoft.Spark` NuGet package, use the `dotnet cli` to install it.

```bash
dotnet add ./RestaurantInspectionsETL/ package Microsoft.Spark --version 0.4.0
```

### Create and configure the ML model project

The ML model class library will contain the domain model that defines the schema of model inputs and outputs as well as the trained model itself.

Inside the *RestaurantInspectionsSparkMLNET* solution directory, create a new class library called *RestaurantInspectionsML* using the `dotnet cli`.

```bash
dotnet new classlib -o RestaurantInspectionsML
```

Add the newly created project to the solution with the `dotnet cli`.

```bash
dotnet sln add ./RestaurantInspectionsML/
```

Since this project uses the `Microsoft.ML` NuGet package, use the `dotnet cli` to install it.

```bash
dotnet add ./RestaurantInspectionsML/ package Microsoft.ML --version 1.3.1
```

### Create and configure the ML training project

The purpose of the training project is to use the pre-processed graded data output by the *RestaurantInspectionsETL* project as input to train a multiclass classification model with ML.NET's Auto ML API. The trained model will then be saved in the *RestaurantInspectionsML* directory.

Inside the *RestaurantInspectionsSparkMLNET* solution directory, create a new console application called *RestaurantInspectionsTraining* using the `dotnet cli`.

```bash
dotnet new console -o RestaurantInspectionsTraining
```

Add the newly created project to the solution with the `dotnet cli`.

```bash
dotnet sln add ./RestaurantInspectionsTraining/
```

This project depends on the domain model created in the *RestaurantInspectionsML* project, so you need to add a reference to it.  

```bash
dotnet add ./RestaurantInspectionsTraining/ reference ./RestaurantInspectionsML/
```

Since this project uses the `Microsoft.Auto.ML` NuGet package, use the `dotnet cli` to install it.

```bash
dotnet add ./RestaurantInspectionsTraining/ package Microsoft.ML.AutoML --version 0.15.1
```

### Create and configure the data enrichment project

The data enrichment application uses the trained machine learning model created by the *RestaurantInspectionsTraining* application and use it on the pre-processed ungraded data created by the *RestaurantInspectionsETL* application to predict what grade that establishment is most likely to receive based on the violations found during inspection.

Inside the *RestaurantInspectionsSparkMLNET* solution directory, create a new console application called *RestaurantInspectionsEnrichment* using the `dotnet cli`.

```bash
dotnet new console -o RestaurantInspectionsEnrichment
```

Add the newly created project to the solution with the `dotnet cli`.

```bash
dotnet sln add ./RestaurantInspectionsEnrichment/
```

This project depends on the domain model created in the *RestaurantInspectionsML* project, so you need to add a reference to it.

```bash
dotnet add ./RestaurantInspectionsEnrichment/ reference ./RestaurantInspectionsML/
```

This uses the following NuGet packages:

- Microsoft.Spark
- Microsoft.ML.LightGBM (This is not required but predictions may fail if the final model is a LightGBM model).

Install the packages with the following commands:

```bash
dotnet add ./RestaurantInspectionsEnrichment/ package Microsoft.Spark --version 0.4.0
dotnet add ./RestaurantInspectionsEnrichment/ package Microsoft.ML.LightGBM --version 1.3.1
```

## Build ETL application

The first step is to prepare the data. To do so, apply a set of transformations using Spark.NET.

### Download the data

Navigate to the *RestaurantInspectionsETL* project and create a *Data* directory.

```bash
mkdir Data
```

Then, download the data into the newly created *Data* directory.

```bash
wget https://data.cityofnewyork.us/api/views/43nn-pn8j/rows.csv?accessType=DOWNLOAD -O Data/NYC-Restaurant-Inspections.csv
```

### Build the ETL pipeline

Add the following usings to the *Program.cs* file.

```csharp
using System;
using System.IO;
using Microsoft.Spark.Sql;
using static Microsoft.Spark.Sql.Functions;
```

Not all of the columns are relevant. Inside the `Main` method of the *Program.cs* file, define the columns to be removed.

```csharp
string[] dropCols = new string[]
{
    "CAMIS",
    "CUISINE DESCRIPTION",
    "VIOLATION DESCRIPTION",
    "BORO",
    "BUILDING",
    "STREET",
    "ZIPCODE",
    "PHONE",
    "ACTION",
    "GRADE DATE",
    "RECORD DATE",
    "Latitude",
    "Longitude",
    "Community Board",
    "Council District",
    "Census Tract",
    "BIN",
    "BBL",
    "NTA"
};
```

The entrypoint of Spark applications is the `SparkSession`. Create `SparkSession` inside the `Main` method of the *Program.cs* file.

```csharp
var sc =
    SparkSession
        .Builder()
        .AppName("Restaurant_Inspections_ETL")
        .GetOrCreate();
```

Then, load the data stored in the *NYC-Restaurant-Inspections.csv* file into a `DataFrame`.

```csharp
DataFrame df =
    sc
    .Read()
    .Option("header", "true")
    .Option("inferSchema", "true")
    .Csv("Data/NYC-Restaurant-Inspections.csv");
```

`DataFrames` can be thought of as tables in a database or sheets in Excel. Spark has various ways of representing data but `DataFrames` are the format supported by Spark.NET. Additionally, the `DataFrame` API is higher-level and easier to work with.

Once the data is loaded, get rid of the data that are not needed by creating a new `DataFrame` that excludes the `dropCols` as well as missing values.

```csharp
DataFrame cleanDf =
    df
        .Drop(dropCols)
        .WithColumnRenamed("INSPECTION DATE","INSPECTIONDATE")
        .WithColumnRenamed("INSPECTION TYPE","INSPECTIONTYPE")
        .WithColumnRenamed("CRITICAL FLAG","CRITICALFLAG")
        .WithColumnRenamed("VIOLATION CODE","VIOLATIONCODE")
        .Na()
        .Drop();
```

Typically, machine learning models expect values to be numerical, so in the ETL step try to convert as many values as possible into numerical values. The `CRITICALFLAG` column contains "Y"/"N" values that can be encoded as 0 and 1.

```csharp
DataFrame labeledFlagDf =
    cleanDf
        .WithColumn("CRITICALFLAG",
            When(Functions.Col("CRITICALFLAG") == "Y",1)
            .Otherwise(0));
```

This dataset contains one violation per row which correspond to different inspections. Therefore, all of the violations need to be aggregated by business and inspection.

```csharp
DataFrame groupedDf =
    labeledFlagDf
        .GroupBy("DBA", "INSPECTIONDATE", "INSPECTIONTYPE", "CRITICALFLAG", "SCORE", "GRADE")
        .Agg(Functions.CollectSet(Functions.Col("VIOLATIONCODE")).Alias("CODES"))
        .Drop("DBA", "INSPECTIONDATE")
        .WithColumn("CODES", Functions.ArrayJoin(Functions.Col("CODES"), ","))
        .Select("INSPECTIONTYPE", "CODES", "CRITICALFLAG", "SCORE", "GRADE");  
```

Now that the data is in the format used to train and make predictions, split the cleaned `DataFrame` into two new `DataFrames`, graded and ungraded. The graded dataset is the data used for training the machine learning model. The ungraded data will be used for enrichment.

```csharp
DataFrame gradedDf =
    groupedDf
    .Filter(
        Col("GRADE") == "A" |
        Col("GRADE") == "B" |
        Col("GRADE") == "C" );

DataFrame ungradedDf =
    groupedDf
    .Filter(
        Col("GRADE") != "A" &amp;
        Col("GRADE") != "B" &amp;
        Col("GRADE") != "C" );  
```

Take the `DataFrames` and save them as csv files for later use.

```csharp
var timestamp = ((DateTimeOffset) DateTime.UtcNow).ToUnixTimeSeconds().ToString();

var saveDirectory = Path.Join("Output",timestamp);

if(!Directory.Exists(saveDirectory))
{
    Directory.CreateDirectory(saveDirectory);
}

gradedDf.Write().Csv(Path.Join(saveDirectory,"Graded"));

ungradedDf.Write().Csv(Path.Join(saveDirectory,"Ungraded"));
```

### Publish and run the ETL application

The final *Program.cs* file should look as follows:

```csharp
using System;
using System.IO;
using Microsoft.Spark.Sql;
using static Microsoft.Spark.Sql.Functions;

namespace RestaurantInspectionsETL
{
    class Program
    {
        static void Main(string[] args)
        {
            // Define columns to remove
            string[] dropCols = new string[]
            {
                "CAMIS",
                "CUISINE DESCRIPTION",
                "VIOLATION DESCRIPTION",
                "BORO",
                "BUILDING",
                "STREET",
                "ZIPCODE",
                "PHONE",
                "ACTION",
                "GRADE DATE",
                "RECORD DATE",
                "Latitude",
                "Longitude",
                "Community Board",
                "Council District",
                "Census Tract",
                "BIN",
                "BBL",
                "NTA"
            };

            // Create SparkSession
            var sc =
                SparkSession
                    .Builder()
                    .AppName("Restaurant_Inspections_ETL")
                    .GetOrCreate();

            // Load data
            DataFrame df =
                sc
                .Read()
                .Option("header", "true")
                .Option("inferSchema", "true")
                .Csv("Data/NYC-Restaurant-Inspections.csv");

            //Remove columns and missing values
            DataFrame cleanDf =
                df
                    .Drop(dropCols)
                    .WithColumnRenamed("INSPECTION DATE","INSPECTIONDATE")
                    .WithColumnRenamed("INSPECTION TYPE","INSPECTIONTYPE")
                    .WithColumnRenamed("CRITICAL FLAG","CRITICALFLAG")
                    .WithColumnRenamed("VIOLATION CODE","VIOLATIONCODE")
                    .Na()
                    .Drop();

            // Encode CRITICAL FLAG column
            DataFrame labeledFlagDf =
                cleanDf
                    .WithColumn("CRITICALFLAG",
                        When(Functions.Col("CRITICALFLAG") == "Y",1)
                        .Otherwise(0));

             // Aggregate violations by business and inspection
            DataFrame groupedDf =
                labeledFlagDf
                    .GroupBy("DBA", "INSPECTIONDATE", "INSPECTIONTYPE", "CRITICALFLAG", "SCORE", "GRADE")
                    .Agg(Functions.CollectSet(Functions.Col("VIOLATIONCODE")).Alias("CODES"))
                    .Drop("DBA", "INSPECTIONDATE")
                    .WithColumn("CODES", Functions.ArrayJoin(Functions.Col("CODES"), ","))
                    .Select("INSPECTIONTYPE", "CODES", "CRITICALFLAG", "SCORE", "GRADE");

            // Split into graded and ungraded DataFrames
            DataFrame gradedDf =
                groupedDf
                .Filter(
                    Col("GRADE") == "A" |
                    Col("GRADE") == "B" |
                    Col("GRADE") == "C" );

            DataFrame ungradedDf =
                groupedDf
                    .Filter(
                        Col("GRADE") != "A" &amp;
                        Col("GRADE") != "B" &amp;
                        Col("GRADE") != "C" );

            // Save DataFrames
            var timestamp = ((DateTimeOffset) DateTime.UtcNow).ToUnixTimeSeconds().ToString();

            var saveDirectory = Path.Join("Output",timestamp);

            if(!Directory.Exists(saveDirectory))
            {
                Directory.CreateDirectory(saveDirectory);
            }

            gradedDf.Write().Csv(Path.Join(saveDirectory,"Graded"));

            ungradedDf.Write().Csv(Path.Join(saveDirectory,"Ungraded"));
        }
    }
}
```

Publish the application with the following command.

```bash
dotnet publish -f netcoreapp2.1 -r ubuntu.18.04-x64
```

Run the application with `spark-submit`.

```bash
spark-submit --class org.apache.spark.deploy.dotnet.DotnetRunner --master local bin/Debug/netcoreapp2.1/ubuntu.18.04-x64/publish/microsoft-spark-2.4.x-0.4.0.jar dotnet bin/Debug/netcoreapp2.1/ubuntu.18.04-x64/publish/RestaurantInspectionsETL.dll
```

## Build ML Domain

### Define the model input schema

Navigate to the *RestaurantInspectionsTraining* project directory and create a new file called *ModelInput.cs*.

```bash
touch ModelInput.cs
```

Open the *ModelInput.cs* file and add the following code.

```csharp
using Microsoft.ML.Data;

namespace RestaurantInspectionsML
{
    public class ModelInput
    {
        [LoadColumn(0)]
        public string InspectionType { get; set; }

        [LoadColumn(1)]
        public string Codes { get; set; }

        [LoadColumn(2)]
        public float CriticalFlag { get; set; }

        [LoadColumn(3)]
        public float InspectionScore { get; set; }

        [LoadColumn(4)]
        [ColumnName("Label")]
        public string Grade { get; set; }
    }
}
```

Using attributes in the schema, five properties are defined:

- InspectionType: The type of inspection performed.
- Codes: Violation codes found during inspection.
- CriticalFlag: Indicates if any of the violations during the inspection were critical (contribute to food-borne illness).
- InspectionScore: Score assigned after inspection.
- Grade: Letter grade assigned after inspection

The `LoadColumn` attribute defines the position of the column in the file. Data in the last column is assigned to the `Grade` property but is then referenced as `Label` in the `IDataView`. The reason for using the `ColumnName` attribute is ML.NET algorithms have default column names and renaming properties at the schema class level removes the need to define the feature and label columns as parameters in the training pipeline.

### Define the model output schema

In the *RestaurantInspectionsTraining* project directory and create a new file called *ModelOutput.cs*.

```bash
touch ModelOutput.cs
```

Open the *ModelOutput.cs* file and add the following code.

```csharp
namespace RestaurantInspectionsML
{
    public class ModelOutput
    {
        public float[] Scores { get; set; }
        public string PredictedLabel { get; set; }
    }
}
```

For the output schema, the `ModelOutput` class uses properties with the default column names of the outputs generated by the model training process:

- Scores: A float vector containing the probabilties for all the predicted classes.
- PredictedLabel: The value of the prediction. In this case, the `PredictedLabel` is the predicted grade expected to be assigned after inspection given the set of features for that inspection.

## Build the model training application

The application trains a multiclass classification algorithm. Finding the "best" algorithm with the right parameters requires experimentation. Fortunately, ML.NET's Auto ML does this for you given you provide it with the type of algorithm you want to train.

### Load the graded data

Navigate to the *RestaurantInspectionsTraining* project directory and add the following using statements to the *Program.cs* class.

```csharp
using System;
using System.IO;
using System.Linq;
using Microsoft.ML;
using static Microsoft.ML.DataOperationsCatalog;
using Microsoft.ML.AutoML;
using RestaurantInspectionsML;
```

Inside the `Main` method of the *Program.cs* file, define the path where the data files are stored.

```csharp
string solutionDirectory = "/home/lqdev/Development/RestaurantInspectionsSparkMLNET";
string dataLocation = Path.Combine(solutionDirectory,"RestaurantInspectionsETL","Output");
```

The entrypoint of an ML.NET application is the `MLContext`. Initialize an `MLContext` instance.

```csharp
MLContext mlContext = new MLContext();
```

Next, get the paths of the data files. The output generated by the *RestaurantInspectionsETL* application contains both the csv files as well as files containing information about the partitions that created them. For training, only the csv files are needed.

```csharp
var latestOutput =
    Directory
        .GetDirectories(dataLocation)
        .Select(directory =&gt; new DirectoryInfo(directory))
        .OrderBy(directoryInfo =&gt; directoryInfo.Name)
        .Select(directory =&gt; Path.Join(directory.FullName,"Graded"))
        .First();

var dataFilePaths =
    Directory
        .GetFiles(latestOutput)
        .Where(file =&gt; file.EndsWith("csv"))
        .ToArray();
```

Then, load the data into an `IDataView`. An `IDataView` is similar to a `DataFrame` in that it is a way to represent data as rows, columns and their schema.

```csharp
var dataLoader = mlContext.Data.CreateTextLoader&lt;ModelInput&gt;(separatorChar:',', hasHeader:false, allowQuoting:true, trimWhitespace:true);

IDataView data = dataLoader.Load(dataFilePaths);
```

It's good practice to split the data into training and test sets for evaluation. Split the data into 80% training and 20% test sets.

```csharp
TrainTestData dataSplit = mlContext.Data.TrainTestSplit(data,testFraction:0.2);
IDataView trainData = dataSplit.TrainSet;
IDataView testData = dataSplit.TestSet;
```

### Create the experiment

Auto ML takes the data and runs experiments using different models and hyper-parameters in search of the "best" model. Define the settings for your experiment. In this case, the model will run for 600 seconds or 10 minutes and will try to find the model with the lowest log loss metric.

```csharp
var experimentSettings = new MulticlassExperimentSettings();
experimentSettings.MaxExperimentTimeInSeconds = 600;
experimentSettings.OptimizingMetric = MulticlassClassificationMetric.LogLoss;
```

Then, create the experiment.

```csharp
var experiment = mlContext.Auto().CreateMulticlassClassificationExperiment(experimentSettings);
```

After creating the experiment, run it.

```csharp
var experimentResults = experiment.Execute(data, progressHandler: new ProgressHandler());
```

By default, running the application won’t display progress information. However, a `ProgressHandler` object can be passed into the `Execute` method of an experiment which calls the implemented `Report` method.

Inside the *RestaurantInspectionsTraining* project directory, create a new file called *ProgressHandler.cs*.

```bash
touch ProgressHandler.cs
```

Then, add the following code:

```csharp
using System;
using Microsoft.ML.Data;
using Microsoft.ML.AutoML;

namespace RestaurantInspectionsTraining
{
    public class ProgressHandler : IProgress&lt;RunDetail&lt;MulticlassClassificationMetrics&gt;&gt;
    {
        public void Report(RunDetail&lt;MulticlassClassificationMetrics&gt; run)
        {
            Console.WriteLine($"Trained {run.TrainerName} with Log Loss {run.ValidationMetrics.LogLoss:0.####} in {run.RuntimeInSeconds:0.##} seconds");
        }
    }
}
```

The ProgressHandler class derives from the `IProgress&lt;T&gt;` interface which requires the implementation of the `Report` method. The object being passed into the Report method after each run is an `RunDetail&lt;MulticlassClassificationMetrics&gt;` object. Each time a run is complete, the `Report` method is called and the code inside it executes.

### Evaluate the results

Once the experiment has finished running, get the model from the best run. Add the following code to the `Main` method of the *Program.cs*.

```csharp
var bestModel = experimentResults.BestRun.Model;
```

Evaluate the performance of the model using the test dataset and measure it's Micro-Accuracy metric.

```csharp
IDataView scoredTestData = bestModel.Transform(testData);  
var metrics = mlContext.MulticlassClassification.Evaluate(scoredTestData);
Console.WriteLine($"MicroAccuracy: {metrics.MicroAccuracy}");
```

### Save the trained model

Finally, save the trained model to the *RestaurantInspectionsML* project.

```csharp
string modelSavePath = Path.Join(solutionDirectory,"RestaurantInspectionsML","model.zip");
mlContext.Model.Save(bestModel, data.Schema, modelSavePath);
```

A file called *model.zip* should be created inside the *RestaurantInspectionsML* project.

Make sure that the trained model file is copied to the output directory by adding the following contents to the *RestaurantInspectionsML.csproj* file in the *RestaurantInspectionsML* directory.

```xml
&lt;ItemGroup&gt;
  &lt;None Include="model.zip"&gt;
    &lt;CopyToOutputDirectory&gt;PreserveNewest&lt;/CopyToOutputDirectory&gt;
  &lt;/None&gt;
&lt;/ItemGroup&gt;
```

Copying it to the output directory of the *RestaurantInspectionsML* makes it easier to reference from the *RestaurantInspectionsEnrichment* project since that project already contains a reference to the *RestaurantInspectionsML* class library.

## Train the model

The final *Program.cs* file should look as follows:

```csharp
using System;
using System.IO;
using System.Linq;
using Microsoft.ML;
using static Microsoft.ML.DataOperationsCatalog;
using Microsoft.ML.AutoML;
using RestaurantInspectionsML;

namespace RestaurantInspectionsTraining
{
    class Program
    {
        static void Main(string[] args)
        {
            // Define source data directory paths
            string solutionDirectory = "/home/lqdev/Development/RestaurantInspectionsSparkMLNET";
            string dataLocation = Path.Combine(solutionDirectory,"RestaurantInspectionsETL","Output");

            // Initialize MLContext
            MLContext mlContext = new MLContext();

            // Get directory name of most recent ETL output
            var latestOutput =
                Directory
                    .GetDirectories(dataLocation)
                    .Select(directory =&gt; new DirectoryInfo(directory))
                    .OrderBy(directoryInfo =&gt; directoryInfo.Name)
                    .Select(directory =&gt; Path.Join(directory.FullName,"Graded"))
                    .First();

            var dataFilePaths =
                Directory
                    .GetFiles(latestOutput)
                    .Where(file =&gt; file.EndsWith("csv"))
                    .ToArray();

            // Load the data
            var dataLoader = mlContext.Data.CreateTextLoader&lt;ModelInput&gt;(separatorChar:',', hasHeader:false, allowQuoting:true, trimWhitespace:true);
            IDataView data = dataLoader.Load(dataFilePaths);

            // Split the data
            TrainTestData dataSplit = mlContext.Data.TrainTestSplit(data,testFraction:0.2);
            IDataView trainData = dataSplit.TrainSet;
            IDataView testData = dataSplit.TestSet;

            // Define experiment settings
            var experimentSettings = new MulticlassExperimentSettings();
            experimentSettings.MaxExperimentTimeInSeconds = 600;
            experimentSettings.OptimizingMetric = MulticlassClassificationMetric.LogLoss;

            // Create experiment
            var experiment = mlContext.Auto().CreateMulticlassClassificationExperiment(experimentSettings);

            // Run experiment
            var experimentResults = experiment.Execute(data, progressHandler: new ProgressHandler());

            // Best Run Results
            var bestModel = experimentResults.BestRun.Model;

            // Evaluate Model
            IDataView scoredTestData = bestModel.Transform(testData);  
            var metrics = mlContext.MulticlassClassification.Evaluate(scoredTestData);
            Console.WriteLine($"MicroAccuracy: {metrics.MicroAccuracy}");

            // Save Model
            string modelSavePath = Path.Join(solutionDirectory,"RestaurantInspectionsML","model.zip");
            mlContext.Model.Save(bestModel, data.Schema, modelSavePath);
        }
    }
}
```

Once all the code and configurations are complete, from the *RestaurantInspectionsTraining* directory, run the application using the `dotnet cli`. Remember this will take 10 minutes to run.

```bash
dotnet run
```

The console output should look similar to the output below:

```text
Trained LightGbmMulti with Log Loss 0.1547 in 1.55 seconds
Trained FastTreeOva with Log Loss 0.0405 in 65.58 seconds
Trained FastForestOva with Log Loss 0.0012 in 53.37 seconds
Trained LightGbmMulti with Log Loss 0.0021 in 4.55 seconds
Trained FastTreeOva with Log Loss 0.8315 in 5.22 seconds
MicroAccuracy: 0.999389615839469
```

## Build the data enrichment application

Now that the model is trained, it can be used to enrich the ungraded data.

### Initialize the PredictionEngine

Navigate to the *RestaurantInspectionsEnrichment* project directory and add the following using statements to the *Program.cs* class.

```csharp
using System.IO;
using System.Linq;
using Microsoft.ML;
using Microsoft.Spark.Sql;
using static Microsoft.Spark.Sql.Functions;
using RestaurantInspectionsML;
```

To make predictions, the model has to be loaded into the applicaton and because predictions are made one row at a time, a `PredictionEngine` has be created as well.

Inside the `Program` class, define the `PredictionEngine`.

```csharp
private static readonly PredictionEngine&lt;ModelInput,ModelOutput&gt; _predictionEngine;
```

Then, create a constructor to load the model and initialize it.

```csharp
static Program()
{
    MLContext mlContext = new MLContext();
    ITransformer model = mlContext.Model.Load("model.zip",out DataViewSchema schema);
    _predictionEngine = mlContext.Model.CreatePredictionEngine&lt;ModelInput,ModelOutput&gt;(model);
}
```

### Load the ungraded data

In the `Main` method of the `Program` class, define the location of the data files.

```csharp
string solutionDirectory = "/home/lqdev/Development/RestaurantInspectionsSparkMLNET";
string dataLocation = Path.Combine(solutionDirectory,"RestaurantInspectionsETL","Output");
```

Then, get the path of the most recent ungraded data generated by the *RestaurantInspectionsETL* application.

```csharp
var latestOutput =
    Directory
        .GetDirectories(dataLocation)
        .Select(directory =&gt; new DirectoryInfo(directory))
        .OrderBy(directoryInfo =&gt; directoryInfo.Name)
        .Select(directory =&gt; directory.FullName)
        .First();
```

Initialize a `SparkSession` for your enrichment application.

```csharp
var sc =
    SparkSession
        .Builder()
        .AppName("Restaurant_Inspections_Enrichment")
        .GetOrCreate();
```

The data generated by the *RestaurantInspectionsETL* does not have headers. However, the schema can be defined and set when the data is loaded.

```csharp
var schema = @"
    INSPECTIONTYPE string,
    CODES string,
    CRITICALFLAG int,
    INSPECTIONSCORE int,
    GRADE string";

DataFrame df = 
    sc
    .Read()
    .Schema(schema)
    .Csv(Path.Join(latestOutput,"Ungraded"));
```

### Define the UDF

There is no built-in function in Spark that allows you to use a `PredictionEngine`. However, Spark can be extended through UDFs. Keep in mind that UDFs are not optimized like the built-in functions. Therefore, whenever possible, try to use the built-in functions as much as possible.

In the `Program` class, create a new method called `PredictGrade` which takes in the set of features that make up the `ModelInput` expected by the trained model.

```csharp
public static string PredictGrade(
    string inspectionType,
    string violationCodes,
    int criticalFlag,
    int inspectionScore)
{
    ModelInput input = new ModelInput
    {
        InspectionType=inspectionType,
        Codes=violationCodes,
        CriticalFlag=(float)criticalFlag,
        InspectionScore=(float)inspectionScore
    };

    ModelOutput prediction = _predictionEngine.Predict(input);

    return prediction.PredictedLabel;
}
```

Then, inside the `Main` method, register the `PredictGrade` method as a UDF in your `SparkSession`.

```csharp
sc.Udf().Register&lt;string,string,int,int,string&gt;("PredictGrade",PredictGrade);
```

### Enrich the data

Once the UDF is registered, use it inside of a `Select` statement which creates a new `DataFrame` that includes the input features as well as the predicted grade output by the trained mdoel.

```csharp
var enrichedDf =
    df
    .Select(
        Col("INSPECTIONTYPE"),
        Col("CODES"),
        Col("CRITICALFLAG"),
        Col("INSPECTIONSCORE"),
        CallUDF("PredictGrade",
            Col("INSPECTIONTYPE"),
            Col("CODES"),
            Col("CRITICALFLAG"),
            Col("INSPECTIONSCORE")
        ).Alias("PREDICTEDGRADE")
    );
```

Finally, save the enriched `DataFrame`

```csharp
string outputId = new DirectoryInfo(latestOutput).Name;
string enrichedOutputPath = Path.Join(solutionDirectory,"RestaurantInspectionsEnrichment","Output");
string savePath = Path.Join(enrichedOutputPath,outputId);

if(!Directory.Exists(savePath))
{
    Directory.CreateDirectory(enrichedOutputPath);
}

enrichedDf.Write().Csv(savePath);
```

### Publish and run the enrichment application

The final *Program.cs* file should look as follows.

```csharp
using System.IO;
using System.Linq;
using Microsoft.ML;
using Microsoft.Spark.Sql;
using static Microsoft.Spark.Sql.Functions;
using RestaurantInspectionsML;

namespace RestaurantInspectionsEnrichment
{
    class Program
    {
        private static readonly PredictionEngine&lt;ModelInput,ModelOutput&gt; _predictionEngine;

        static Program()
        {
            MLContext mlContext = new MLContext();
            ITransformer model = mlContext.Model.Load("model.zip",out DataViewSchema schema);
            _predictionEngine = mlContext.Model.CreatePredictionEngine&lt;ModelInput,ModelOutput&gt;(model);
        }

        static void Main(string[] args)
        {
            // Define source data directory paths
            string solutionDirectory = "/home/lqdev/Development/RestaurantInspectionsSparkMLNET";
            string dataLocation = Path.Combine(solutionDirectory,"RestaurantInspectionsETL","Output");

            var latestOutput = 
                Directory
                    .GetDirectories(dataLocation)
                    .Select(directory =&gt; new DirectoryInfo(directory))
                    .OrderBy(directoryInfo =&gt; directoryInfo.Name)
                    .Select(directory =&gt; directory.FullName)
                    .First();

            var sc = 
                SparkSession
                    .Builder()
                    .AppName("Restaurant_Inspections_Enrichment")
                    .GetOrCreate();

            var schema = @"
                INSPECTIONTYPE string,
                CODES string,
                CRITICALFLAG int,
                INSPECTIONSCORE int,
                GRADE string";

            DataFrame df = 
                sc
                .Read()
                .Schema(schema)
                .Csv(Path.Join(latestOutput,"Ungraded"));

            sc.Udf().Register&lt;string,string,int,int,string&gt;("PredictGrade",PredictGrade);

            var enrichedDf = 
                df
                .Select(
                    Col("INSPECTIONTYPE"),
                    Col("CODES"),
                    Col("CRITICALFLAG"),
                    Col("INSPECTIONSCORE"),
                    CallUDF("PredictGrade",
                        Col("INSPECTIONTYPE"),
                        Col("CODES"),
                        Col("CRITICALFLAG"),
                        Col("INSPECTIONSCORE")
                    ).Alias("PREDICTEDGRADE")
                );

            string outputId = new DirectoryInfo(latestOutput).Name;
            string enrichedOutputPath = Path.Join(solutionDirectory,"RestaurantInspectionsEnrichment","Output");
            string savePath = Path.Join(enrichedOutputPath,outputId);

            if(!Directory.Exists(savePath))
            {
                Directory.CreateDirectory(enrichedOutputPath);
            }

            enrichedDf.Write().Csv(savePath);

        }

        public static string PredictGrade(
            string inspectionType,
            string violationCodes,
            int criticalFlag,
            int inspectionScore)
        {
            ModelInput input = new ModelInput
            {
                InspectionType=inspectionType,
                Codes=violationCodes,
                CriticalFlag=(float)criticalFlag,
                InspectionScore=(float)inspectionScore
            };

            ModelOutput prediction = _predictionEngine.Predict(input);

            return prediction.PredictedLabel;
        }
    }
}
```

From the *RestaurantInspectionsEnrichment* project publish the application with the following command.

```bash
dotnet publish -f netcoreapp2.1 -r ubuntu.18.04-x64
```

Navigate to the *publish* directory. In this case, it's *bin/Debug/netcoreapp2.1/ubuntu.18.04-x64/publish*.

From the *publish* directory, run the application with `spark-submit`.

```bash
spark-submit --class org.apache.spark.deploy.dotnet.DotnetRunner --master local microsoft-spark-2.4.x-0.4.0.jar dotnet RestaurantInspectionsEnrichment.dll
```

The file output should look similar to the contents below:

```text
Cycle Inspection / Initial Inspection,04N,1,13,A
Cycle Inspection / Re-inspection,08A,0,9,A
Cycle Inspection / Initial Inspection,"10B,10H",0,10,A
Cycle Inspection / Initial Inspection,10F,0,10,A
Cycle Inspection / Reopening Inspection,10F,0,3,C
```

## Conclusion

This solution showcased how Spark can be used within .NET applications with Spark.NET. Because it's part of the .NET ecosystem, other components and frameworks such as ML.NET can be leveraged to extend the system's capabilities. Although this sample was developed and run on a local, single-node cluster, Spark was made to run at scale. As such, this application can be further improved by setting up a cluster and running the ETL and enrichment workloads on there.

###### Resources

[Apache Spark](https://spark.apache.org/)
[Spark.NET](https://dotnet.microsoft.com/apps/data/spark)
[Spark.NET GitHub](https://github.com/dotnet/spark)
[Mobius](https://github.com/Microsoft/Mobius)
[NYC OpenData](https://opendata.cityofnewyork.us/)
]]&gt;</description>
      <link>https://www.lqdev.me/posts/restaurant-inspections-etl-data-enrichment-spark-auto-ml-net</link>
      <guid>https://www.lqdev.me/posts/restaurant-inspections-etl-data-enrichment-spark-auto-ml-net</guid>
      <pubDate>2019-09-15 15:12:01 -05:00</pubDate>
      <category>mlnet</category>
      <category>ml</category>
      <category>machine-learning</category>
      <category>ai</category>
      <category>artificial-intelligence</category>
      <category>big-data</category>
      <category>spark</category>
      <category>dotnet</category>
      <category>dotnetcore</category>
    </item>
    <item>
      <title>Machine Learning Lifecycle Management with ML.NET, Automated ML and MLFlow</title>
      <description>&lt;![CDATA[
## Introduction

As machine learning matures, best practices are starting to be adopted. Application lifecycle management has been a common practice within software development for some time. Now, some of those practices are starting to become adopted in the machine learning space. One of the challenges application lifecycle management addresses in machine learning is reproducibility.

Machine learning is extremely experimental in nature. Therefore, in order to find the "best" model, various algorithms and hyper-parameters need to be tested. This can sometimes be a manual process. At Build 2019, [Automated ML was announced](https://devblogs.microsoft.com/dotnet/announcing-ml-net-1-0/) for ML.NET. In addition to automating the training process, this framework will try to find the best model by iterating over various algorithms and hyper-parameters until it finds the "best" model based on the selected optimization metric. The output will consist of results for the best run along with results for all other runs. These runs contain performance metrics, learned model parameters, the training pipeline used and the trained model for the respective run. This information can then be used for auditing purposes as well as to reproduce results.

The results from running Automated ML can be persisted locally or in a database. However in 2018 a product called MLFlow was launched. [MLFlow](https://mlflow.org/) is an open source machine learning lifecycle management platform. Since its announcement, MLFlow has seen adoption throughout the industry and most recently [Microsoft announced native support for it inside of Azure ML](https://databricks.com/company/newsroom/press-releases/databricks-collaborates-with-microsoft-on-mlflow-open-source-project). Although MLFlow does not natively support .NET, it has a REST API that allows extensibility to non-natively supported languages. This means that if throughout your enterprise or projects, MLFlow has been adopted in Python or R applications, using the REST API you can integrate MLFlow into your ML.NET applications.

In this writeup, I will go over how to automatically build an ML.NET classification model that predicts iris flower types using Automated ML and then integrate MLFlow to log the results generated by the best run. The code for this sample can be found on [GitHub](https://github.com/lqdev/MLNETMLFlowSample).

## Prerequisites

This project was built on an Ubuntu 18.04 PC but should work on Windows and Mac. Note that MLFlow does not natively run on Windows at the time of this writing. To run it on Windows use [Windows Subsystem for Linux (WSL)](https://docs.microsoft.com/en-us/windows/wsl/install-win10).

- [Python 3.x](https://www.python.org/downloads/)
- [MLFlow](https://www.mlflow.org/docs/latest/quickstart.html)
- [.NET SDK 2.x](https://dotnet.microsoft.com/download)

## Setup

### Create Solution

First we'll start off by creating a solution for our project. In the terminal enter the following commands:

```bash
mkdir MLNETMLFlowSample &amp;&amp; cd MLNETMLFlowSample
dotnet new sln
```

### Create Console Application

Once the solution is created, from the root solution directory, enter the following commands into the terminal to create a console application.

```bash
dotnet new console -o MLNETMLFlowSampleConsole
```

Then, navigate into the newly created console application folder.

```bash
cd MLNETMLFlowSampleConsole
```

### Install NuGet Packages

For this solution, you'll need the following NuGet packages:

- [Microsoft.ML](https://www.nuget.org/packages/Microsoft.ML/)
- [Microsoft.ML.Auto](https://www.nuget.org/packages/Microsoft.ML.AutoML/)
- [MLFlow.NET](https://www.nuget.org/packages/MLFlow.NET/1.0.0-CI-20181206-054144)

From the console application directory, enter the following commands into the terminal to install the packages.

```bash
dotnet add package Microsof.ML
dotnet add package Microsoft.ML.AutoML
dotnet add package MLFlow.NET --version 1.0.0-CI-20181206-054144
```

### Get The Data

The data used in this dataset comes from the [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/index.php) and looks like the data below:

```text
5.1,3.5,1.4,0.2,Iris-setosa
4.9,3.0,1.4,0.2,Iris-setosa
4.7,3.2,1.3,0.2,Iris-setosa
4.6,3.1,1.5,0.2,Iris-setosa
```

First, create a directory for the data inside the console application directory:

```bash
mkdir Data
```

Then, download and save the file into the `Data` directory.

```bash
curl -o Data/iris.data https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data
```

Finally, make sure that the data file is copied into your output directory by adding the following section to your console application `csproj` file inside the `Project` tags:

```xml
&lt;ItemGroup&gt;
    &lt;Content Include="Data/iris.data"&gt;
        &lt;CopyToOutputDirectory&gt;PreserveNewest&lt;/CopyToOutputDirectory&gt;
    &lt;/Content&gt;
&lt;/ItemGroup&gt;
```

## Configure MLFlow Service

### MLFlow.NET Settings

MLFlow.NET requires two settings, the base URL where the MLFlow server listens on and the API endpoint. In this case since it will be running locally, the base URL is `http://localhost:5000`. In the console application directory, create a file called `appsettings.json` and add the following content:

```json
{
    "MLFlowConfiguration": {
        "MLFlowServerBaseUrl": "http://localhost:5000",
        "APIBase": "api/2.0/preview/mlflow/"
    }
}
```

To make sure that your `appsettings.json` is copied into your output directory, add the following content to your `csproj` file under the content tags that include the `iris.data` file.

```xml
&lt;Content Include="appsettings.json"&gt;
    &lt;CopyToOutputDirectory&gt;PreserveNewest&lt;/CopyToOutputDirectory&gt;
&lt;/Content&gt;
```

### Register MLFLow.NET Service

In this sample, the MLFlow.NET service is registered and used via dependency injection. However, in order to use dependency injection in our console application it first needs to be configured. In the console application directory, create a new file called `Startup.cs` and add the following code to it:

```csharp
using System;
using Microsoft.Extensions.Configuration;
using Microsoft.Extensions.DependencyInjection;
using MLFlow.NET.Lib;
using MLFlow.NET.Lib.Contract;
using MLFlow.NET.Lib.Model;

namespace MLNETMLFlowSampleConsole
{
    public class Startup
    {
        private readonly IConfiguration Configuration;
        public IServiceProvider Services;

        public Startup()
        {
            Configuration =
                new ConfigurationBuilder()
                    .AddJsonFile("appsettings.json", false)
                    .Build();
        }

        public void ConfigureServices()
        {
            var services = new ServiceCollection();

            // Add and configure MLFlow Service
            services.AddMFlowNet();
            services.Configure&lt;MLFlowConfiguration&gt;(
                Configuration.GetSection(nameof(MLFlowConfiguration))
            );

            Services = services.BuildServiceProvider();
        }
    }
}
```

The `Startup` class loads configuration settings from the `appsettings.json` file in the constructor. Then, the `ConfigureServices` method registers the MLFlow.NET service and configures it using the settings defined in the `appsettings.json` file. Once that this is set up, the service can be used throughout the application.

## Create Data Schema

When working with ML.NET, it often helps to create data models or classes that define the data's schema.

For this sample, there are four columns with float values which will be the input data or features. The last column is the type of iris flower which will be used as the label or the value to predict. 

First, create a new directory called `Domain` inside the console application directory to store the data model classes.

```bash
mkdir Domain
```

Inside the `Domain` directory, create a new file called `IrisData.cs` and add the following contents to the file:

```csharp
using Microsoft.ML.Data;

namespace MLNETMLFlowSample.Domain
{
    public class IrisData
    {
        [LoadColumn(0, 3),
        VectorType(4),
        ColumnName("Features")]
        public float Features { get; set; }

        [LoadColumn(4),
        ColumnName("Label")]
        public string IrisType { get; set; }
    }
}
```

Using attributes in the schema, we define two properties: `Features` and `IrisType`. Data from columns in positions 0-3 will be loaded as a float vector of size four into the `Features` property. ML.NET will then reference that column by the name `Features`. Data in the last column will be loaded into the `IrisType` property and be referenced by the name `Label`. The reason for setting column names is ML.NET algorithms have a default column names and renaming properties at the schema level removes the need to define the feature and label columns in the pipeline.

## Create Progress Handler

By default, running the application won't display progress information. However, a `ProgressHandler` object can be passed into the `Execute` method of an experiment which calls the implemented `Report` method.

Inside the console application directory, create a new file called `ProgressHandler.cs` and add the following code:

```csharp
using System;
using Microsoft.ML.AutoML;
using Microsoft.ML.Data;
using Microsoft.ML.Trainers;

namespace MLNETMLFlowSampleConsole
{
    public class ProgressHandler : IProgress&lt;RunDetail&lt;MulticlassClassificationMetrics&gt;&gt;
    {
        public void Report(RunDetail&lt;MulticlassClassificationMetrics&gt; runDetails)
        {
            Console.WriteLine($"Ran {runDetails.TrainerName} in {runDetails.RuntimeInSeconds:0.##} with Log Loss {runDetails.ValidationMetrics.LogLoss:0.####}");
        }
    }
}
```

The `ProgressHandler` class derives from the `IProgress&lt;T&gt;` interface which requires the implementation of the `Report` method. The object being passed into the `Report` method after each run is an `RunDetail&lt;MulticlassCLassificationMetrics&gt;` object. Each time a run is complete, the `Report` method is called and the code inside it executes.

## Create Experiment

Open the `Program.cs` file and add the following `using` statements.

```csharp
using System;
using System.IO;
using System.Threading.Tasks;
using Microsoft.ML;
using Microsoft.ML.Data;
using Microsoft.ML.AutoML;
using Microsoft.Extensions.DependencyInjection;
using MLNETMLFlowSampleConsole.Domain;
using MLFlow.NET.Lib;
using MLFlow.NET.Lib.Contract;
using MLFlow.NET.Lib.Model;
using MLFlow.NET.Lib.Model.Responses.Experiment;
using MLFlow.NET.Lib.Model.Responses.Run;
```

### Initialize Services

Then, inside of the `Program` class, define the `IMLFlowService`:

```csharp
private readonly static IMLFlowService _mlFlowService;
```

Directly after that, create a constructor which is where `_mlFLowService` will be instantiated.

```csharp
static Program()
{
    // Initialize app configuration
    var appConfig = new Startup();
    appConfig.ConfigureServices();

    // Initialize MLFlow service
    _mlFlowService = appConfig.Services.GetService&lt;IMLFlowService&gt;();
}
```

### Define Experiment Steps

Then, add a method called `RunExperiment` inside the `Program` class that contains the following code:

```csharp
public static async Task RunExperiment()
{
    // 1. Create MLContext
    MLContext ctx = new MLContext();

    // 2. Load data
    IDataView data = ctx.Data.LoadFromTextFile&lt;IrisData&gt;("Data/iris.data", separatorChar: ',');

    // 3. Define Automated ML.NET experiment settings
    var experimentSettings = new MulticlassExperimentSettings();
    experimentSettings.MaxExperimentTimeInSeconds = 30;
    experimentSettings.OptimizingMetric = MulticlassClassificationMetric.LogLoss;

    // 4. Create Automated ML.NET
    var experiment = ctx.Auto().CreateMulticlassClassificationExperiment(experimentSettings);

    // 5. Create experiment in MLFlow
    var experimentName = Guid.NewGuid().ToString();
    var experimentRequest = await _mlFlowService.GetOrCreateExperiment(experimentName);

    // 6. Run Automated ML.NET experiment
    var experimentResults = experiment.Execute(data, progressHandler: new ProgressHandler());

    // 7. Log Best Run
    LogRun(experimentRequest.ExperimentId,experimentResults);

    string savePath = Path.Join("MLModels", $"{experimentName}");
    string modelPath = Path.Join(savePath, "model.zip");

    if (!Directory.Exists(savePath))
    {
        Directory.CreateDirectory(savePath);
    }

    // 8. Save Best Trained Model
    ctx.Model.Save(experimentResults.BestRun.Model, data.Schema, modelPath);
}
```

The `RunExperiment` method does the following:

1. Creates an `MLContext` object.
2. Loads data from the `iris.data` file into an `IDataView`.
3. Configures experiment to run for 30 seconds and optimize the Log Loss metric.
4. Creates a new Automated ML.NET experiment.
5. Creates a new experiment in MLFlow to log information to.
6. Runs the Automated ML.NET experiment and provide an instance of `ProgressHandler` to output progress to the console.
7. Uses the `LogRun` method to log the results of the best run to MLFlow.
8. Creates a directory inside the `MLModels` directory using the name of the experiment and saves the trained model inside it under the `model.zip` file name.

### Log Progress

After the `RunExperiment` method, create the `LogRun` method and add the following code to it:

```csharp
static async void LogRun(int experimentId, ExperimentResult&lt;MulticlassClassificationMetrics&gt; experimentResults)
{
    // Define run
    var runObject = new CreateRunRequest();
    runObject.ExperimentId = experimentId;
    runObject.StartTime = ((DateTimeOffset)DateTime.UtcNow).ToUnixTimeMilliseconds();
    runObject.UserId = Environment.UserName;
    runObject.SourceType = SourceType.LOCAL;

    // Create new run in MLFlow
    var runRequest = await _mlFlowService.CreateRun(runObject);

    // Get information for best run
    var runDetails = experimentResults.BestRun;

    // Log trainer name
    await _mlFlowService.LogParameter(runRequest.Run.Info.RunUuid, nameof(runDetails.TrainerName), runDetails.TrainerName);

    // Log metrics
    await _mlFlowService.LogMetric(runRequest.Run.Info.RunUuid, nameof(runDetails.RuntimeInSeconds), (float)runDetails.RuntimeInSeconds);
    await _mlFlowService.LogMetric(runRequest.Run.Info.RunUuid, nameof(runDetails.ValidationMetrics.LogLoss), (float)runDetails.ValidationMetrics.LogLoss);
    await _mlFlowService.LogMetric(runRequest.Run.Info.RunUuid, nameof(runDetails.ValidationMetrics.MacroAccuracy), (float)runDetails.ValidationMetrics.MacroAccuracy);
    await _mlFlowService.LogMetric(runRequest.Run.Info.RunUuid, nameof(runDetails.ValidationMetrics.MicroAccuracy), (float)runDetails.ValidationMetrics.MicroAccuracy);
}
```

The `LogRun` method takes in the experiment ID and results. Then, it does the following:

1. Configures local `RunRequest` object to log in MLFlow.
2. Creates run in MLFLow using predefined configuration.
3. Logs the name of the machine learning algorithm used to train the best model in MLFlow.
4. Logs the amount of seconds it took to train the model in MLFLow.
5. Logs various performance metrics in MLFlow

### Implement Main Method

Finally, in the `Main` method of the `Program` class, call the `RunExperiment` method.

```csharp
static async Task Main(string[] args)
{
    // Run experiment
    await RunExperiment();
}
```

Since the `Main` method in the `Program` class will be async, you need to use the latest version of C#. To do so, add the following configuration inside the `PropertyGroup` section of your `csproj` file.

```xml
&lt;LangVersion&gt;latest&lt;/LangVersion&gt;
```

## Run The Application

### Start MLFlow Server

In the terminal, from the console application directory, enter the following command to start the MLFlow Server:

```bash
mlflow server
```

Navigate to `http://localhost:5000` in your browser. This will load the MLFLow UI.

![](http://cdn.lqdev.tech/files/images/ml-lifecycle-management-mlflow-automated-ml-net-1.png)

### Train Model

Then, in another terminal, from the console application directory, enter the following command to run the experiment:

```bash
dotnet build
dotnet run
```

As the experiment is running, the progress handler should be posting output to the console after each run.

```text
Ran AveragedPerceptronOva in 1.24 with Log Loss 0.253
Ran SdcaMaximumEntropyMulti in 3.21 with Log Loss 0.0608
Ran LightGbmMulti in 0.64 with Log Loss 0.2224
Ran FastTreeOva in 1.54 with Log Loss 0.3978
Ran LinearSvmOva in 0.25 with Log Loss 0.2874
Ran LbfgsLogisticRegressionOva in 0.36 with Log Loss 0.566
Ran SgdCalibratedOva in 0.78 with Log Loss 0.7224
Ran FastForestOva in 1.28 with Log Loss 0.125
Ran LbfgsMaximumEntropyMulti in 0.25 with Log Loss 0.4537
Ran SdcaMaximumEntropyMulti in 0.19 with Log Loss 0.4576
Ran LightGbmMulti in 0.25 with Log Loss 0.2592
Ran FastForestOva in 1.98 with Log Loss 0.0961
Ran SdcaMaximumEntropyMulti in 0.39 with Log Loss 0.108
```

Navigate to `http://localhost:5000` in your browser. You should then see the results of your experiment and runs there.

![](http://cdn.lqdev.tech/files/images/ml-lifecycle-management-mlflow-automated-ml-net-2.png)

Inspecting the detailed view of the best run for that experiment would look like the image below:

![](http://cdn.lqdev.tech/files/images/ml-lifecycle-management-mlflow-automated-ml-net-3.png)

You'll also notice that two directories were created inside the console application directory. On is an `MLModels` directory, inside of which a nested directory with the name of the experiment contains the trained model. Another called `mlruns`. In the `mlruns` directory are the results of the experiments logged in MLFlow.

## Conclusion

In this writeup, we built an ML.NET classification model using Automated ML. Then, the results of the best run generated by Automated ML were logged to an MLFlow server for later analysis. Note that although some of these tools are still in their nascent stage, as open source software, the opportunities for extensibility and best practice implementations are there. Happy coding!]]&gt;</description>
      <link>https://www.lqdev.me/posts/ml-lifecycle-management-mlflow-automated-ml-net</link>
      <guid>https://www.lqdev.me/posts/ml-lifecycle-management-mlflow-automated-ml-net</guid>
      <pubDate>2019-05-09 19:19:20 -05:00</pubDate>
      <category>machine-learning</category>
      <category>artificial-intelligence</category>
      <category>mlnet</category>
      <category>dotnet</category>
      <category>dotnetcore</category>
      <category>automatedml</category>
    </item>
    <item>
      <title>The Case for Doing Machine Learning with F#</title>
      <description>&lt;![CDATA[
## Introduction

This post is part of the 2018 [FsAdvent](https://sergeytihon.com/tag/fsadvent/) series organized by [Sergey Tihon](https://twitter.com/sergey_tihon).

When searching for tools and languages to implement machine learning applications, there are numerous options to choose from each with their own set of advantages and disadvantages. Out of all, however, Python seems to be the most salient. Not only is it a popular language but also many of the tools available for machine learning are either implemented in Python or support it in some capacity whether it's native or through community libraries. Very rarely though is F# mentioned in these discussions despite having many of the features that make languages like Python so loved and extending them to empower users. In this writeup, I will do a short review of many of the advantages of Python such as succinctness, platform support, library availability as well as many others and compare it to F#'s capabilities.

![2017 Top Languages](http://cdn.lqdev.tech/files/images/case-fsharp-ml-0.PNG)

## Python's Advantages

### Learning Curve

One of the reasons why Python is so widely adopted is its learning curve. Whether an individual knows how to program or not, at times, Python can look like pseudocode making it accessible to not only readers but also writers. As with anything the more complex the task, the steeper the learning curve. However, at a simpler level, Python makes it as easy as possible to get started. 

Although at first it may not appear to be the case with F#, the learning curve is not much steeper than that of Python. The syntax can sometimes look intimidating to individuals, but the steepest part of the learning curve doesn't necessarily come from the language itself but rather from the way of reasoning about the logic of the programs. As a functional language, there is somewhat of a paradigm shift from that of a procedural execution model. Below is an example that defines a function that doubles an integer in both languages.  

##### Python

```python
def double(x):
    return x * 2
```

##### FSharp

```fsharp
let double x = 
    x * 2
```

As it can be seen, despite some minor syntax and character differences the functions are essentially the same.  

### Intended Purpose

Depending on the task at hand, some languages are more adept for handling respective tasks. For example, R and Julia are excellent languages when performing statistical tasks. However, outside of those types of tasks their abilities are more limited. Python, being a general-purpose language means that not only can you use it for machine learning tasks but also to build n-tier applications entirely in Python without having to worry about integrations, plugins or having to learn an entirely different language to perform such actions. 

Similarly, F# is a general-purpose language which allows you to build web and console applications as well as machine learning applications all from the comfort of the same ecosystem.

### Strong Library Support

When performing data analysis and machine learning, practicioners use a variety of libraries for their development such as [NumPy](http://www.numpy.org/) and [Pandas](https://pandas.pydata.org/) for data wrangling, [scikit-learn](https://scikit-learn.org/stable/index.html) for machine learning algorithms and [matplotlib](https://matplotlib.org/) for creating visualizations. Although all of these tasks could most certainly be implemented from scratch, libraries speed up the development process allowing practitioners to focus more on the domain and experiment with the models that best solve the respective problem they are facing.  

F#, like Python has exceptional library support, specifically as it regards data science and machine learning. [FsLab](https://fslab.org/) is a collection of open source F# packages for machine learning that contain libraries such as [FSharp.Data](https://fsharp.github.io/FSharp.Data/) and [Deedle](https://fslab.org/Deedle/) for data wrangling, [Math.NET Numerics](https://numerics.mathdotnet.com/) for machine learning algorithms and [XPlot](https://fslab.org/XPlot/) to help with data visualization. Furthermore, at Build 2018, Microsoft released [ML.NET](https://dotnet.microsoft.com/apps/machinelearning-ai/ml-dotnet), an open-source, cross-platform machine learning framework for .NET which allows .NET users to not only perform machine learning tasks within .NET but also allows extensibility via Tensorflow, ONNX and Python extensions. For a more detailed writup on using ML.NET with F#, check out the post [A Christmas Classifier](https://towardsdatascience.com/f-advent-calendar-a-christmas-classifier-72fb9e9d8f23) by Willie Tetlow or my post [Classification with F# ML.NET Models](http://luisquintanilla.me/2018/06/13/mlnet-classification-fsharp/).

Libraries for F# are also not confined only to those written in F#. In many instances, because F# is a .NET language, there is interoperability with C# libraries further extending the capabilities of F#.

### Platform Support

One of the things that makes Python so attractive is that it runs cross-platform. It does not matter whether you're on Windows, Mac or Linux; Python code runs the same. That being said though, not all platforms are created equal and although it is possible to run Python code on all platforms, essential libraries such as NumPy, Pandas and scikit-learn run best on Unix environments. It is possible to run them on Windows but the set up is not as straightforward. 

As a .NET Language, F# runs on Windows. With the help of the Mono runtime and most recently .NET Core, it also runs on Mac and Linux. Like Python, depending on the runtime and dependencies used by the respective software packages there may be limitations as to which platform code can be run on. However, from my experience most of the FsLab set of packages work cross-platform. 

### Succintness

Productivity is an important measure of a language. One way to achieve it is to write logic using the least number of characters. This is where Python shines. As a dynamically typed, whitespace ruled language, Python does not require developers to declare types associated with the objects and variables defined nor does it require the use of brackets and any other special characters. As expected, this allows for developers to write the same logic with less characters much faster. 

Unlike Python, F# is a statically typed language. However, thanks to type inference and the help of the compiler, writing programs often does not require developers to explicitly define what types objects and variables are. Additionally, it is a whitespace ruled language therefore removing the need for brackets and additional characters further speeding up the development process in a safe manner.

### Immediate Feedback

Writing safe and effective code takes time and experience. However, even the most experienced developers often makes mistakes. Therefore, getting immediate feedback before adding certain logic to programs goes a long way to making code that is safe, efficient and tested.  

#### Read-Evaluate-Print Loop (REPL)

One way in which both Python and F# provide immediate feedback is via the command line using the Read-Evaluate-Print Loop (REPL). The REPL is a programming environment that reads the user input, evaluates it and prints out the results, hence the name. Below are screenshots of what that environment looks like using both Python and F#.

##### Python

![](http://cdn.lqdev.tech/files/images/case-fsharp-ml-1.png)

##### FSharp

![](http://cdn.lqdev.tech/files/images/case-fsharp-ml-2.png)

As it can be seen, getting that immediate feedback makes it easier to see whether the code is behaving the way it should. Although useful, this environment is not ideal when experimenting and making tweaks to the code. Additionally, because of the lack of a graphical user interface, the navigation can be less than ideal. Fortunately there is a solution out there that provides the same level of interactivity along with a graphical user interface that allows for ad-hoc experimentation and re-running of code at different points in time which is essential when developing machine learning applications.

#### Jupyter Notebooks

Much of machine learning deals with experimentation. Experimentation involves having a way to tweak parameters and evaluate the results. In addition, experiments should have a way of being documented and reproduced. As alluded to previously, such development environment and capabilities can be found in [Jupyter Notebook](https://jupyter.org/). 

As mentioned on the project's website: 

&gt; The Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. Uses include: data cleaning and transformation, numerical simulation, statistical modeling, data visualization, machine learning, and much more.

Jupyter Notebooks work with various languages which include but are not limited to Python and F# and can be run both on local machines as well as via a hosted service. One such service is Microsoft's [Azure Notebooks](https://notebooks.azure.com/) which allows you to use Jupyter Notebooks in the cloud for free. All you need is to have a Microsoft account. Below are screenshots of what that environment looks like in both Python and F#.   

##### Python

![](http://cdn.lqdev.tech/files/images/case-fsharp-ml-3.png)

##### FSharp

![](http://cdn.lqdev.tech/files/images/case-fsharp-ml-4.png)

## Beyond Python

F#, is comparable to Python on many of the features that make Python a great language for both development and machine learning. However, there are some areas where F# provides additional safety and functionality that greatly improve the way in which machine learning applications are built. 

### Typing

As previously mentioned, F# is a statically typed language. However, it also makes use of type inference which means that declaring types is not always required. With the help of the compiler, based on the structure of functions and variables it is possible to determine which type an object or variable is. This has several advantages. One advantage of being strongly typed is that when the types are declared the code becomes self-documented because it is easier to deduce what functions are doing based on the types being passed in and returned. Another advantage is that it makes it harder to write bad code. Having the compiler help you when you write your code allows you to find errors prior to compilation or running the code. This along with the REPL gives you additional reassurance that your code is executing the intended logic. 

Python is making strides in acquiring some of that functionality with the introduction of type hints in version 3.6. However, this has not always been a core feature of the language and is only in its nascent stages. 

### Immutability

As a functional language, immutability is something that is a native part of the language. While in some cases it can change the way in which code is written, immutability has one advantage, especially when it comes to machine learning. With immutability, parallelization can be fully exploited for those algorithms which take advantage of it. 

## Conclusion

In this writeup, I went over how F# is comparable to Python on many of the features that make it such a popular language such as library support, succinctness, general purpose and interactivity. However, F# has additional capabilities such as static typing and immutability that further enhance its capabilities as a language for machine learning. That is not to say that one is better than the other as they both are more adept for performing certain tasks. When it comes to machine learning it does become a matter of choice as they are both robust, powerful and strongly supported languages. Therefore next time you're looking to build a machine learning application, hopefully you give F# a try. Happy coding!

###### Resources

[2018 Top Programming Languages](https://spectrum.ieee.org/at-work/innovation/the-2018-top-programming-languages)  
[Get Programming with F#](https://www.manning.com/books/get-programming-with-f-sharp)  
[ML.NET Machine Learning Samples](https://github.com/dotnet/machinelearning-samples)]]&gt;</description>
      <link>https://www.lqdev.me/posts/case-fsharp-machine-learning</link>
      <guid>https://www.lqdev.me/posts/case-fsharp-machine-learning</guid>
      <pubDate>2018-12-14 23:34:50 -05:00</pubDate>
      <category>mlnet</category>
      <category>machine learning</category>
      <category>fsharp</category>
      <category>dotnet</category>
      <category>programming</category>
      <category>python</category>
      <category>ai</category>
      <category>dotnetcore</category>
      <category>artificial intelligence</category>
      <category>fsadvent</category>
      <category>artificialintelligence</category>
      <category>machinelearning</category>
      <category>data science</category>
      <category>functional programming</category>
    </item>
    <item>
      <title>Operationalizing Machine Learning with ML.NET, Azure DevOps and Azure Container Instances</title>
      <description>&lt;![CDATA[

## Introduction

Azure DevOps, formerly known as Visual Studio Team Services (VSTS), helps individuals and organizations plan, collaborate and ship products faster. One if its noteworthy services, Azure Pipelines, helps developers build Continuous Integration (CI) and Continuous Delivery (CD) pipelines that automate and standardize the build, test and deploy phases of the software development process. In addition, Azure Pipelines provides native container support and works with any language, platform and cloud. Machine learning like software development is also a process that includes a build, test and deploy phase which makes it a good candidate for automation and standardization. At Build 2018, Microsoft announced [ML.NET](https://github.com/dotnet/machinelearning), an open-source, cross-plaform machine learning framework for .NET. If we were to put all of these tools and services together, it means that we can automate and standardize the training of a machine learning model built with ML.NET, package it into a Docker container and deploy it to Azure Container Instances (ACI). In this writeup, I will go through the process of building a CI/CD pipeline in Azure Devops that trains, packages and deploys an ML.NET machine learning model to predict which class an Iris flower belongs to using a variety of measurements. Source code for this project can be found at this [link](https://github.com/lqdev/mlnetazdevopssample).

## Prerequisites

- [Git](https://git-scm.com/)
- [GitHub Account](https://github.com/)
- [.NET Core SDK](https://www.microsoft.com/net/download)  
- [Azure Account](https://azure.microsoft.com/en-us/free/)

## The Application

Because the purpose of this post is to demonstrate the functionality of Azure Devops and not that of ML.NET, I'll start with a pre-built application. For some more information and detail into the functionality of ML.NET, check out the official documentation [page](https://docs.microsoft.com/en-us/dotnet/machine-learning/) as well as some of my previous posts: 

- [Serverless Machine Learning with ML.NET and Azure Functions](http://luisquintanilla.me/2018/08/21/serverless-machine-learning-mlnet-azure-functions/)
- [Deploy .NET Machine Learning Models with ML.NET, ASP.NET Core, Docker and Azure Container Instances](http://luisquintanilla.me/2018/05/11/deploy-netml-docker-aci/).

The application used in this writeup contains three .NET Core projects within it. One is a class library which is what we'll use to wrap ML.NET functionality for training models as well as loading pre-trained models that will then be used to make predictions. Another is a .NET Core console application which references the class library to train and persist an ML.NET model. Finally, there's the ASP.NET Core Web API which also references the class library application to load the pre-trained model created by the console application and then makes predictions via HTTP. This application can be utilized and deployed standalone but in this writeup it will be packaged into a Docker image that will then be deployed to Azure Container Instances.  

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-1.png)

### Class Library

The class library can be found in the `MLModel` directory. The class library defines the observation and prediction data classes which can be found in the `IrisData.cs` and `IrisPrediction.cs` files respectively. Additionally, the `Model` class contains helper methods that train and save machine learning models, load pre-trained models and use these models to make predictions. 

### Console Application

In the solution directory we also have a console application in the `ModelTrainer` directory. This application references the class library in the `MLModel` directory to train and persist the machine learning model. 

### API

The `ModelApi` directory contains an ASP.NET Core Web API application that references the `MLModel` class library project to load the pre-trained model that is trained by the `ModelTrainer` console application and makes predictions via HTTP. The logic for making predictions can be found in the `PredictController.cs` class in the `Controllers` directory of the `ModelApi` application. 

## CI/CD Pipeline Flow

Conceptually, when the application is built and deployed manually, the machine learning model is defined and developed inside the `MLModel` class library. Once satisfied with the model, the class library is built. The console application which references the `MLModel` class library is built as well as run to train and persist a classification model in a file called `model.zip`. The `MLModel` class library is also referenced in the `ModelApi` ASP.NET Core project. Because `ModelApi` is the application we're looking to deploy in order to expose our pre-trained machine learning model, we need to find a way to package it for deployment. We'll be deploying `ModelApi` using Azure Container Instances which means we need to create a Docker image of the project that will then be pushed to a Docker registry where it will be made available for public consumption. The building of multiple projects as well as the building, publishing and deployment of the Docker image to Azure Container Instances can be standardized and automated using Azure DevOps. The rest of this write-up will focus on demonstrating step-by-step how to operationalize this machine learning application via CI/CD pipelines in Azure DevOps using Azure Pipelines.   

### Getting The Code

Before getting started, the first thing you'll want to do is fork the [mlnetazdevopssample](https://github.com/lqdev/mlnetazdevopssample) GitHub repository into your own GitHub account.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-2.png)

### Creating the Project

Navigate to [https://devops.azure.com](https://devops.azure.com), click `Start Free` and follow the prompts to either create a new account or sign into your existing account.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-3.png)

Once logged in, click `Create Project`.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-4.png)

Enter the name of your project as well as a short description. Then, click `Create`.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-5.png)

## The Continuous Integration (CI) Pipeline

Using Azure Pipelines, we'll configure a CI pipeline for the build and packaging steps of our application. Below is an illustration of all the steps involved in our CI pipeline:

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-6.png)

1. Build the class library application
2. Build the console application
3. Train and persist the ML.NET Model by running the console application.
4. Copy ML.NET model file created by console application into ASP.NET Core Web API application directory
5. Build ASP.NET Core Web API application
6. Build Docker image 
7. Push Docker image to Docker Hub

### CI Pipeline Setup

Once the project is created, in the main project page, hover over `Pipelines` and click on `Builds`.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-7.png)

In the `Builds` pipeline page, click `New pipeline`.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-8.png)

Select GitHub as the source and connect your GitHub account with Azure DevOps.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-9.png)

Once you have authorized Azure DevOps to use your GitHub account, select the repository and branch that will be used for this build pipeline. In our case, we'll be using the master branch of the `mlnetazdevopssample` repository. When finished configuring, click `Continue`.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-10.png)

The next step will be to select the jobs to execute in our pipeline. Because there are multiple steps in this build pipeline, let's start with an `Empty Job` and customize it to our needs.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-11.png)

From inside the build pipeline page, before we start adding jobs, lets select the agent that will execute the jobs. For this pipeline, select the `Hosted Ubuntu 1604` option from the dropdown.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-12.png)

### 1. Build the Class Library Application

The first step in our CI Pipeline will be to build our class library which contains methods that wrap the training, loading and prediction functionality of the ML.NET framework and persisted models.

To achieve that, we'll add a .NET Core task to our `Agent Job 1`.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-13.png)

Once added to the pipeline, let's configure this task. To make it more descriptive, we can give it a name such as `Build Class Library`. Because this task will be responsible for building the .NET Core class library, we'll leave the default `build` Command setting as is. 

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-14.png)

The other setting we'll want to configure is the `Working Directory`. We can do so by clicking the `Advanced` tab. 

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-15.png)

For this task we'll use the `MLModel` directory.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-16.png)

When finished with the configuration, click `Save &amp; Queue` -&gt; `Save` on the top toolbar.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-17.png)

Enter a detailed comment describing the change to the pipeline and click `Save`.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-18.png)

### 2. Building The Console Application

Once we've built the class library application which we'll reference from the .NET Core console and ASP.NET Core Web API applications, it's time to build the console application which will serve the purpose of training and persisting the ML.NET model.

Similar to the previous step, add a new .NET Core *build* task to the pipeline. The only setting that will change for this task is the `Working Directory` which will have the value of `ModelTrainer`. 

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-19.png)

Although not required, when finished configuring the task, click `Save &amp; Queue` -&gt; `Save` to save and comment the changes to the pipeline. 

### 3. Train and persist the ML.NET Model

Now that our console application is built, it's time to run it in order to train and persist the ML.NET model. To do so, we'll add another .NET Core task. The difference is that the `Command` setting will now be configured with the `run` value. 

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-20.png)

The `Working Directory` will be set to `ModelTrainer` like in the previous task.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-21.png)

Remember to save and comment the new changes to the pipeline.

### 4. Copy ML.NET Model to Web API Directory

After the console application is run and the ML.NET model is trained, it is persisted in a file called `model.zip` inside the `ModelTrainer` directory. We can use this persisted version of the model to make predictions from both the console application or any other application of our choice. In this case, we'll be making predictions via an ASP.NET Core Web API. In order for our API to reference this file, we need to copy it into the root directory of our `ModelApi` directory. A way to perform that task is via bash script. To add a bash script to our pipeline, all we need to do is add a Bash task to it. 

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-22.png)

Once added to our pipeline, it's time to configure the task. We'll set the `Type` setting to `Inline` which will bring up a text box for us to type in the script. 

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-23.png)

Inside of the text box, enter the following content:

```bash
# Write your commands here

cp ../ModelTrainer/model.zip .

# Use the environment variables input below to pass secret variables to this script
```

This command will copy the `model.zip` file from the `ModelTrainer` directory to the `ModelApi` directory.

We can set the `Working Directory` of this step to `ModelApi`.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-24.png)

Once finished, save and comment the new changes to the pipeline. 

### 5. Build ASP.NET Core Web API application

Now that we have the necessary files inside our `ModelApi` application, it's time to build it. We'll add a .NET Core task to our pipeline and set the `Command` to `build`. The `Working Directory` will be `ModelApi` like the previous task.

Save and comment the new changes to the pipeline when finished.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-25.png)

### 6. Build ASP.NET Core Web API Docker Image

The method of deployment for the ASP.NET Core Web API application is via containers. Therefore, after building the application, we have to build a Docker image for it that can then be pushed to a Docker registry of your choice. To build a Docker image, we'll add a Docker task to our pipeline.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-26.png)

When we configure the task, we'll start off by setting the `Container Registry Type` to `Container Registry`.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-27.png)

This will prompt the setup of a service connection to a Docker registry if one does not already exist.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-28.png)

The Docker registry type we'll be using is Docker Hub. Give the connection a name, enter the credentials to your Docker Hub account and click `Verify this connection` to make sure that your credentials are valid and a connection can be established with Docker Hub. When finished click `OK`.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-29.png)

The `Command` setting will be `build` so we can leave the default as is as well as the `Dockerfile` setting which will use the Dockerfile in the root `mlnetazdevopssample` directory.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-30.png)

Finally, we'll configure the `Image name` setting. The convention we'll use is `&lt;docker-hub-username&gt;/&lt;image-name&gt;`. In my case, `lqdev` is my Docker Hub username and I'll name my image `mlnetazdevopssample` resulting in `lqdev/mlnetazdevopssample`. Additionally, check the `Include latest tag` checkbox to have every build be the latest as opposed to tagging it with versions numbers. 

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-31.png)

Remember to save and comment the recent changes to the pipeline.

### 7. Push Docker Image to Docker Hub

The last step in our CI pipeline is to push our newly built image to Docker Hub. To do so we'll use anoter Docker task. 

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-32.png)

Like in the previous task, we'll set the `Container registry type` to `Container Registry`. Set the `Docker registry service connection` to the most recently created connection by selecting it from the dropdown. We'll be changing our `Command` to `push` and set the `Image name` to the name of the image built in the previous step. The naming convention is `&lt;docker-hub-username&gt;/&lt;image-name&gt;:latest`. The latest tag was added by our previous Docker build task so make sure that you include it in this task.

Once finished, click `Save &amp; Queue` -&gt; `Save &amp; Queue`. As opposed to only clicking `Save`, this action will manually trigger the CI pipeline.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-33.png)

Don't forget to comment your changes and click `Save &amp; queue` to kick off the CI pipeline.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-34.png)

### Monitoring the Build

When the build starts, you can click on `Builds` under the `Pipelines` section on the left pane.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-35.png)

Select the first build from the list to get more details on the build.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-36.png)

This will take you to the logs which show the status of the pipeline near real-time.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-37.png)

### Confirming CI Pipeline Success

If the build is successful, navigate to [https://hub.docker.com/](https://hub.docker.com/) to check whether the Docker image was pushed to the registry.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-38.png)

## The Continuous Delivery (CD) Pipeline

Now that we have our CI pipeline set up which will build and package our application, it's time to deploy it. We could do this ourselves or automate it using a CD pipeline. Our application wil be deployed to Azure Container Instances which is an Azure service that offers a quick way to run containers without having to worry about the management of virtual machines or orchestration services. The steps involved in our CD pipeline are the following:

1. Create Azure Resource Group for deployment
2. Deploy application to Azure Container Instances.

### CD Pipeline Setup

To get started setting up a CD pipeline, from the Azure DevOps project main page, hover over `Pipelines` and click on `Releases`.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-39.png)

Once in that page, click on `New pipeline`.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-40.png)

As with our CI pipeline, we'll start off with an `Empty Job` which we'll configure at a later time.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-41.png)

### Triggering Deployments

Once our pipeline is created, it's time to configure it. The first thing we'll want to do is add an artifact. An artifact can be a variety of things including the output of our build pipeline. In our case, the end our CI pipeline will be the trigger for our CD pipeline. To add an artifact, click `Add an artifact`.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-42.png)

In the configuration form, set the `Source type` to `Build` and the `Source` to the name of the CI pipeline created in the previous steps. When finished, click `Add`.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-43.png)


After configuring our artifact, it's time to configure the steps in the CD pipeline. To do so, click on the `Stage 1` option in the `Stages` section of the release pipeline page and change the name to something more descriptive.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-44.png)

When finished, close out the form and click on the hyperlink below the stage title. 

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-45.png)

You should now be on a page similar to the CI pipeline job configuration page. On this page, we'll want to click on the `Agent Job` panel to set the `Agent pool` setting to `Hosted Ubuntu 1604`.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-46.png)

Once that is complete, it's time to configure the tasks in the CD pipeline.

### 1. Create Azure Resource Group

Start off adding an `Azure CLI` task to the pipeline. In this task we'll create a resource group in Azure to which we'll deploy our application to. 

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-47.png)

Before doing anything else, link DevOps to an Azure Subscription by selecting one from the dropdown and clicking `Authorize` which will prompt you to authenticate your subscription. 

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-48.png)

Once an Azure subscription has been linked, let's change the `Script Location` setting to `Inline Script`.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-49.png)

In the `Inline Script` text box enter the following:

```bash
az group create --name mlnetazdevopssampleresourcegroup --location eastus
```
This script will create a resource group in Azure called `mlnetazdevopssampleresourcegroup` that is located in `eastus`. Both of these are configurable to your preference. 

### 2. Deploy Docker Image to Azure Container Instances

The next and final step in our CD pipeline is the deployment to Azure Container Instances. To deploy our application, we'll add another `Azure CLI` task. This time, since we already configured our `Azure subscription` in the previous task, we can select the service connection as opposed to a subscription from the dropdown.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-50.png)

Like in the previous task, our script will be inline. 

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-51.png)

In the `Inline Script` text box enter the following:

```bash
az container create --resource-group mlnetazdevopssampleresourcegroup --name mlnetcontainer --image lqdev/mlnetazdevopssample:latest --ports 80 --ip-address public
```

This script creates a container in the resource group created by the previous task of the pipeline with the name `mlnetcontainer` from the Docker image that was pushed to Docker Hub by the CI pipeline. Additionally, it opens up port 80 and assigns a publicly accessible IP address for the container to be accessed externally. 

Once this step has been configured, make sure to save and comment all your changes by clicking `Save`.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-52.png)

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-53.png)

Then, to make it easily recognizable, edit the name of the pipeline by hovering near `New release pipeline` and clicking on the pencil icon.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-54.png)

Make sure to save and comment your changes.

## Automating CI/CD Pipelines

In the previous steps, we configured CI and CD pipelines. However, we have still not fully automated the triggers that kick off both of these. 

### CI Pipeline Trigger

First, lets start off by automating the CI pipeline. To do so, go the project's main page, hover over `Pipelines` and click on `Builds`.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-55.png)

This will take you to the CI pipeline page. While on this page, click `Edit`.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-56.png)

Then, click on `Triggers`.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-57.png)

Once on this page, check the `Enable continous integration` checkbox and save and comment your changes by clicking `Save &amp; Queue` -&gt; `Save`.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-58.png)


### CD Pipeline Trigger

To automate the CD pipeline trigger, click on `Releases` under the `Pipelines` page to automate the CD pipeline.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-59.png)

Once on the CD pipeline's page, click `Edit`.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-60.png)

Then, click on the lightning icon in the Artifacts section which will show a configuration form. In this form, toggle the `Continuous deployment trigger` setting to `Enabled`.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-61.png)

When finished, save and comment your changes. 

## Running CI/CD Pipelines

Although going forward builds and deployments will be started when new changes are checked into the master branch of the `mlnetazdevopssample` repository, for demonstration purposes we will manually kick off the CI/CD pipelines we have just configured. To do so, click on `Builds` under the `Pipelines` section on the left pane.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-62.png)

From the CI pipeline page click `Queue`.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-63.png)

This will prompt a modal to show up in which you can just click `Queue` to start the build.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-64.png)

This will kick off a new CI build which subsequently will also kick off the CD pipeline of your application. 

## Testing The Deployment

If all is successful, a Docker image of an ASP.NET Core Web API application will be deployed to Azure Container Instances which can be accessed via a public IP address. 

To see whether the deployment worked, navigate to [https://portal.azure.com/](https://portal.azure.com/) and click on `Resource groups`.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-65.png)

At this point, you should see the resource group that was created by the CD pipeline. If that's the case, click on it. 

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-66.png)

This will then show a page that displays the container that was deployed to this resource group. Click on that.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-67.png)

The container page will display diagnostic and configuration information about the container. The information we're interested in is the `IP address`. Hover to the right of it and click on the icon that says `Click to copy`. This will copy the address to the clipboard.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-68.png)

In an application like Postman or Insomnia, make an HTTP POST request to `http://&lt;ip-address&gt;/api/predict` where `ip-address` is the public IP address of the container in Azure with the following body.

```json
{
    "SepalLength":3.3,
    "SepalWidth":1.6,
    "PetalLength":0.2,
    "PetalWidth":5.1
}
```

If successful, the response will be `Iris-virginica`.

![](http://cdn.lqdev.tech/files/images/azdevops-mlnet-69.png)

## Conclusion

In this writeup, we operationalized the building, packaging and deployment of an ML.NET application that predicts the class of an Iris flower using a variety of mesurements with Azure DevOps. We created both a Continous Integration as well as a Continous Delivery pipeline which deploys the Docker image of an ASP.NET Core Web API to Azure Container Instances. Keep in mind this is just one way of doing it and Azure DevOps is flexible in how all of these tasks and workflows are configured to meet your requirements. Happy coding!

###### Resources

[ML.NET Samples](https://github.com/dotnet/machinelearning-samples)
[DevOps for Data Science](https://www.youtube.com/watch?v=bUTBBS1TECc)]]&gt;</description>
      <link>https://www.lqdev.me/posts/azdevops-mlnet-aci</link>
      <guid>https://www.lqdev.me/posts/azdevops-mlnet-aci</guid>
      <pubDate>2018-11-26 23:50:23 -05:00</pubDate>
      <category>mlnet</category>
      <category>machinelearning</category>
      <category>ai</category>
      <category>dotnet</category>
      <category>dotnetcore</category>
      <category>devops</category>
      <category>azure</category>
      <category>docker</category>
      <category>containers</category>
      <category>microsoft</category>
      <category>artificialintelligence</category>
      <category>programming</category>
      <category>webapi</category>
      <category>aci</category>
      <category>development</category>
    </item>
    <item>
      <title>Serverless Machine Learning with ML.NET and Azure Functions</title>
      <description>&lt;![CDATA[
## Introduction

In a previous blog [post](http://luisquintanilla.me/2018/05/11/deploy-netml-docker-aci/), I explored how to build and deploy machine learning models built with the `ML.NET` framework using an ASP.NET Core Web API, Docker and Azure Container Instances. While this is certainly a good way to deploy such models especially those that are critical and require high availability and/or consist of long-running processes, it's not the case when those requirements are not needed. In such cases serverless computing makes more sense from a cost and resource utilization standpoint. Therefore, in this blog post I will go over how to train a classification model with `ML.NET` and deploy it using Azure Functions. Source code for this post can be found at the following [link](https://github.com/lqdev/azfnmlnetdemo).

## Prerequisites

Prior to starting, make sure you have all of the necessary software to build this project. Although this project was built on a system running Ubuntu 16.04 it should work cross-platform.

- [Azure CLI](https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest)
- [Azure Functions Core Tools Version 2.x](https://docs.microsoft.com/en-us/azure/azure-functions/functions-run-local)
- [.NET Core SDK 2.0+](https://www.microsoft.com/net/download)

## Set Up Azure Environment

Before writing any code we want to configure our Azure environment. To do so we'll be using the Azure CLI. Although in these examples I am providing the resource group name, storage account name and function application name feel free to use one of your choosing. Naming is not as important for resource group or storage account but definitely is the case for the application.

Fist we want to log into our account using the following command

```bash
az login
```

This will guide you through a series of prompts that will eventually result in you being logged in. To make sure you are logged in you can use the `account` command.

```bash
az account list
```

The following output should appear if successfull.

```bash
[
  {
    "cloudName": "AzureCloud",
    "id": "&lt;YOUR-ID&gt;",
    "isDefault": true,
    "name": "Pay-As-You-Go",
    "state": "Enabled",
    "tenantId": "&lt;YOUR-TENANT-ID&gt;",
    "user": {
      "name": "&lt;YOUR-USERNAME&gt;",
      "type": "user"
    }
  }
]
```

Next, we want to create a resource group to contain all of our Azure resources for this application.

```bash
az group create --name azfnmlnetdemo --location eastus
```

Once our resource group is created, it's time to start adding resources for it. First we'll add a storage account which will contain our trained model.

```bash
az storage account create --name azfnmlnetdemostorage --location eastus --resource-group azfnmlnetdemo --sku Standard_LRS
```

Then we'll create an Serverless Function Application and link it to our storage account. We'll want to create a unique name for it. An easy way to do so is to add the date to the end of the name of our application (i.e. myappname20180816).

```bash
az functionapp create --name azfnmlnetdemo20180821 --storage-account azfnmlnetdemostorage --consumption-plan-location eastus --resource-group azfnmlnetdemo
```

The final step in the environment setup is to set the runtime of our Serverless Function Application in the Application Settings to `beta` which supports `.NET Core`.

```bash
az functionapp config appsettings set --name azfnmlnetdemo20180821 --resource-group azfnmlnetdemo --settings FUNCTIONS_EXTENSION_VERSION=beta
```

Now we're ready to build our machine learning model and upload it to our storage account

## Building The Model

Once our environment is set up we can start building our solution. The first step is to create a directory and initialize our solution inside of it.

### Set Up The Solution

```bash
mkdir azfnmlnetdemo
cd azfnmlnetdemo
dotnet new sln
```

### Create The Model Project

Then we want to create a console project for our model and add it to our solution.

```bash
dotnet new console -o model
dotnet sln add model/model.csproj
```

### Add Dependencies

Since we’ll be using the `ML.NET` framework, we need to add it to our model project.

```
cd model
dotnet add package Microsoft.ML
dotnet restore
```

### Download The Data

Before we start training the model, we need to download the data we’ll be using to train. We do so by creating a directory called `data` and downloading the data file onto there.

```bash
mkdir data
curl -o data/iris.txt https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data
```

If we take a look at the data file, it should look something like this:

```bash
5.1,3.5,1.4,0.2,Iris-setosa
4.9,3.0,1.4,0.2,Iris-setosa
4.7,3.2,1.3,0.2,Iris-setosa
4.6,3.1,1.5,0.2,Iris-setosa
5.0,3.6,1.4,0.2,Iris-setosa
5.4,3.9,1.7,0.4,Iris-setosa
4.6,3.4,1.4,0.3,Iris-setosa
5.0,3.4,1.5,0.2,Iris-setosa
4.4,2.9,1.4,0.2,Iris-setosa
4.9,3.1,1.5,0.1,Iris-setosa
```

### Train The Model

Now that we have all our dependencies set up, it’s time to train our model. I leveraged the demo that is used on the [ML.NET Getting-Started website](https://www.microsoft.com/net/learn/machine-learning-and-ai/get-started-with-ml-dotnet-tutorial).

#### Define Data Structures

In the root directory of our `model` project, let’s create two classes called `IrisData` and `IrisPrediction` which will define our features and predicted attribute respectively. Both of them will use `Microsoft.ML.Runtime.Api` to add the property attributes.

Here is what our `IrisData` class looks like:

```csharp
using Microsoft.ML.Runtime.Api;

namespace model
{
    public class IrisData
    {
        [Column("0")]
        public float SepalLength;

        [Column("1")]
        public float SepalWidth;

        [Column("2")]
        public float PetalLength;

        [Column("3")]
        public float PetalWidth;

        [Column("4")]
        [ColumnName("Label")]
        public string Label;
    }
}
```

Similarly, here is the `IrisPrediction` class:

```csharp
using Microsoft.ML.Runtime.Api;

namespace model
{
    public class IrisPrediction
    {
        [ColumnName("PredictedLabel")]
        public string PredictedLabels;
    }
}
```

#### Build the Training Pipeline

The way the `ML.NET` computations process data is via a sequential pipeline of steps that are performed eventually leading up to the training of the model. Therefore, we can create a class called `Model` to perform all of these tasks for us.

```csharp
using Microsoft.ML.Data;
using Microsoft.ML;
using Microsoft.ML.Runtime.Api;
using Microsoft.ML.Trainers;
using Microsoft.ML.Transforms;
using Microsoft.ML.Models;
using System;
using System.Threading.Tasks;

namespace model
{
    class Model
    {

        public static async Task&lt;PredictionModel&lt;IrisData,IrisPrediction&gt;&gt; Train(LearningPipeline pipeline, string dataPath, string modelPath)
        {
            // Load Data
            pipeline.Add(new TextLoader(dataPath).CreateFrom&lt;IrisData&gt;(separator:','));

            // Transform Data
            // Assign numeric values to text in the "Label" column, because
            // only numbers can be processed during model training
            pipeline.Add(new Dictionarizer("Label"));

            // Vectorize Features
            pipeline.Add(new ColumnConcatenator("Features", "SepalLength", "SepalWidth", "PetalLength", "PetalWidth"));

            // Add Learner
            pipeline.Add(new StochasticDualCoordinateAscentClassifier());

            // Convert Label back to text
            pipeline.Add(new PredictedLabelColumnOriginalValueConverter() {PredictedLabelColumn = "PredictedLabel"});

            // Train Model
            var model = pipeline.Train&lt;IrisData,IrisPrediction&gt;();

            // Persist Model
            await model.WriteAsync(modelPath);

            return model;
        }
    }
}
```

In addition to building our pipeline and training our machine learning model, the `Model` class also serialized and persisted the model for future use in a file called `model.zip`.

### Test The Model

Now that we have our data structures and model training pipeline set up, it’s time to test everything to make sure it’s working. We’ll put our logic inside of our `Program.cs` file.

```csharp
using System;
using Microsoft.ML;

namespace model
{
    class Program
    {
        static void Main(string[] args)
        {

            string dataPath = "model/data/iris.txt";

            string modelPath = "model/model.zip";

            var model = Model.Train(new LearningPipeline(),dataPath,modelPath).Result;

            // Test data for prediction
            var prediction = model.Predict(new IrisData()
            {
                SepalLength = 3.3f,
                SepalWidth = 1.6f,
                PetalLength = 0.2f,
                PetalWidth = 5.1f
            });

            Console.WriteLine($"Predicted flower type is: {prediction.PredictedLabels}");
        }
    }
}
```

All set to run. We can do so by entering the following command from our solution directory:

```bash
dotnet run -p model/model.csproj
```

Once the application has been run, the following output should display on the console.

```bash
Automatically adding a MinMax normalization transform, use 'norm=Warn' or
'norm=No' to turn this behavior off.Using 2 threads to train.
Automatically choosing a check frequency of 2.Auto-tuning parameters: maxIterations = 9998.
Auto-tuning parameters: L2 = 2.667734E-05.
Auto-tuning parameters: L1Threshold (L1/L2) = 0.Using best model from iteration 882.
Not training a calibrator because it is not needed.
Predicted flower type is: Iris-virginica
```

Additionally, you’ll notice that a file called `model.zip` was created in the root directory of our model project. This persisted model can now be used outside of our application to make predictions, but first we need to upload it to our Azure Storage account.

### Upload The Model

Now that we have a trained model and it has been persisted to the `model.zip` file, it's time to upload it to Azure Storage so that it is available to our Azure Functions application.

To get started with that, first we need the access keys for our storage account. You can get those by using the following command.

```bash
az storage account keys list --account-name azfnmlnetdemostorage --resource-group azfnmlnetdemo
```

The result of that command should return your primary and secondary keys. You can use either one for the following steps.

Although we can upload directly to the account, it's best to create a container to upload our model to. To keep it simple, I'll call the container `models`.

```bash
az storage container create --name models --account-key &lt;YOUR-ACCOUNT-KEY&gt; --account-name azfnmlnetdemostorage --fail-on-exist
```

Once our container's created, we can upload our `model.zip` file to it.

```bash
az storage blob upload --container-name models --account-name azfnmlnetdemostorage --file model/model.zip --name model.zip
```

To verify that the file has been uploaded, you can list the files inside the `models` storage container.

```bash
az storage blob list --container-name models --account-name azfnmlnetdemostorage --output table
```

That command should produce output similar to that below:

```bash
Name       Blob Type    Blob Tier    Length    Content Type     Last Modified              Snapshot
---------  -----------  -----------  --------  ---------------  -------------------------  ----------
model.zip  BlockBlob                 4373      application/zip  2018-08-21T19:26:09+00:00
```

That's all there is to the upload process. It's now time to build our Azure Functions Application

## Build The Azure Functions Application

### Initialize Azure Function Project

In our solution directory, we want to create a new directory for our Azure Function project

```bash
mkdir serverlessfunctionapp
dotnet sln add serverlessfunctionapp/serverlessfunctionapp.csproj
```

Then, we can scaffold an Azure Functions project inside our newly created `serverlessfunctionapp` project directory using Azure Functions Core Tools

```bash
cd serverlessfunctionapp
func init
```

At this point you will be prompted to select the runtime for your application. For this application select `dotnet`.

This will generate a few files in the `serverlessfunctionapp` directory. Keep in mind though that this does not create the function.

### Add Dependencies

Before we create any functions, we need to add the dependencies for our Azure Functions application. Since we'll be using `Microsoft.ML` in our Azure Function application, we'll need to add it as a dependency. From the `serverlessfunctionapp` enter the following command:

```bash
dotnet add package Microsoft.ML
dotnet restore
```

### Create Serverless Function

Once we've added the dependencies it's time to create a new function. To do so we'll use the Azure Functions Core Tools `new` command. Although not required, it's good practice to separate functions and related files into their own directory.

```bash
mkdir Predict
cd Predict
func new
```

At this time you will be prompted to select a template. For our classification model, we'll be using an HttpTrigger which is exactly what it sounds like. An HTTP request is what calls or invokes our function. With that being said, select the `HttpTrigger` option.

You will then be prompted to enter a name for your function. You can use any name but to make things easy, name it the same as the directory the function is in. Once that process is complete, there should be a file called `Predict.cs` inside our `serverlessfunctionapp/Predict` directory. This is where we'll write the logic for our application.

### Define Data Structures

We'll also be making use of the IrisData and IrisPrediction classes inside our `Predict` function. Therefore, we need to create classes for them inside our `Predict` directory. The content will be the same as when we trained our model with the exception of the namespace which will now be `serverlessfunctionapp.Predict`. The content of those files should look like the code below:

```csharp
//IrisData.cs
using Microsoft.ML.Runtime.Api;

namespace serverlessfunctionapp.Predict
{
    public class IrisData
    {
        [Column("0")]
        public float SepalLength;

        [Column("1")]
        public float SepalWidth;

        [Column("2")]
        public float PetalLength;

        [Column("3")]
        public float PetalWidth;

        [Column("4")]
        [ColumnName("Label")]
        public string Label;
    }
}

//IrisPrediction.cs
using Microsoft.ML.Runtime.Api;

namespace serverlessfunctionapp.Predict
{
    public class IrisPrediction
    {
        [ColumnName("PredictedLabel")]
        public string PredictedLabels;
    }
}
```

### Write Function Logic

With our dependencies and data structures set up, it's time to write our function logic to make predictions. The first thing we want to do is replace the `Run` method inside the `Predict` class with the following code.

```csharp
public static IActionResult Run(
    [HttpTrigger(AuthorizationLevel.Function, "get", "post", Route = null)]HttpRequest req,
    [Blob("models/model.zip", FileAccess.Read, Connection = "AzureWebJobsStorage")] Stream serializedModel,
    TraceWriter log)
{
    // Workaround for Azure Functions Host
    if (typeof(Microsoft.ML.Runtime.Data.LoadTransform) == null ||
        typeof(Microsoft.ML.Runtime.Learners.LinearClassificationTrainer) == null ||
        typeof(Microsoft.ML.Runtime.Internal.CpuMath.SseUtils) == null ||
        typeof(Microsoft.ML.Runtime.FastTree.FastTree) == null)
    {
        log.Error("Error loading ML.NET");
        return new StatusCodeResult(500);
    }

    //Read incoming request body
    string requestBody = new StreamReader(req.Body).ReadToEnd();

    log.Info(requestBody);

    //Bind request body to IrisData object
    IrisData data = JsonConvert.DeserializeObject&lt;IrisData&gt;(requestBody);

    //Load prediction model
    var model = PredictionModel.ReadAsync&lt;IrisData, IrisPrediction&gt;(serializedModel).Result;

    //Make prediction
    IrisPrediction prediction = model.Predict(data);

    //Return prediction
    return (IActionResult)new OkObjectResult(prediction.PredictedLabels);
}
```

There are a few notable change worth looking at. One of them is the workaround at the beginning of the function.

```csharp
if (typeof(Microsoft.ML.Runtime.Data.LoadTransform) == null ||
    typeof(Microsoft.ML.Runtime.Learners.LinearClassificationTrainer) == null ||
    typeof(Microsoft.ML.Runtime.Internal.CpuMath.SseUtils) == null ||
    typeof(Microsoft.ML.Runtime.FastTree.FastTree) == null)
{
    log.Error("Error loading ML.NET");
    return new StatusCodeResult(500);
}
```

There are some issues with Azure Functions and ML.NET Assemblies which are being worked on by both teams at Microsoft (see [Github Issue](https://github.com/Azure/azure-functions-host/issues/3190)). In the meantime, it's safe to just include that code in there.

The other addition to note is the method signature. As you can see, I have added an additional parameter called `serializedModel` which is decorated by the `Blob` attribute.

```csharp
[Blob("models/model.zip", FileAccess.Read, Connection = "AzureWebJobsStorage")] Stream serializedModel
```

What this code is doing is telling the function to import the blob `model.zip` as a `Stream` and bind it to `serializedModel`. Using additional arguments, I tell my function to only have `Read` access to the `model.zip` blob inside the `models` container which can be accessed with the `AzureWebJobsStorage` connection string. Right now that last part might seem confusing, but this is something we configured when we set up the Azure environment and linked `azfnmlnetdemostorage` account with our `azfnmlnetdemo20180821` serverless function app using the `--storage-account` option. Although the production environment is configured, if we try to test our application locally we won't be able to access our storage account because we have not configured the connection string locally. We can do so by looking in the `local.settings.json` file inside our `serverlessfunctionapp` directory. The contents should look like the following.

```json
{
  "IsEncrypted": false,
  "Values": {
    "AzureWebJobsStorage": "",
    "AzureWebJobsDashboard": "",
    "FUNCTIONS_WORKER_RUNTIME": "dotnet"
  }
}
```

Our function running locally will look in this file, try to find `AzureWebJobsStorage` and use the connection string value in the `Predict` function. To get the connection string for our `azfnmlnetdemostorage` account, enter the following command.

```bash
az storage account show-connection-string --name azfnmlnetdemostorage
```

The output of that command should look like the following:

```json
{
  "connectionString": "&lt;YOUR-CONNECTION-STRING&gt;"
}
```

At this point, you just need to copy the value of `connectionString` to your `local.settings.json` file and replace the current empty string for `AzureWebJobsStorage`. It's important to note that it's okay to paste the connection string in here since the `local.settings.json` file is not committed to version control. (See `.gitignore` inside `serverlessfunctionapp` directory). Now the application is ready to be tested locally.

### Testing The Function Locally

To test the application, first build your project by entering the following command from the `serverlessfunctionapp` directory.

```bash
dotnet build
```

Then, navigate to the build directory `./bin/Debug/netstandard2.0` and enter the following command:

```bash
func host start
```

Finally, using a tool like Postman or Insomnia make an HTTP POST request to the `http://localhost:7071/api/Predict` endpoint with the following body:

```json
{
  "SepalLength": 3.3,
  "SepalWidth": 1.6,
  "PetalLength": 0.2,
  "PetalWidth": 5.1
}
```

If everything is set up correctly, you should receive the following output

```bash
Iris-virginica
```

Once satisfied with testing, press `Ctrl + C` to stop the application.

## Deploy To Azure

### Push Build

Great! Now on to the final step, deploying our application to production. Since we already configured everything it should only require a few commands to do so.

First, make sure you are logged in. Using Azure Functions Core Tools log in with the following command:

```bash
func azure login
```

Like with the Azure CLI, you will follow a series of prompts to log into your account.

Once you have successfully logged in, it's time to publish our application to Azure. From the `serverlessfunctionapp` directory enter the following command.

```bash
func azure functionapp publish azfnmlnetdemo20180821
```

When our deployment is complete, we can check whether our function was published successfully by using the following command.

```bash
func azure functionapp list-functions azfnmlnetdemo20180821
```

The output should look similar to that below.

```bash
Functions in azfnmlnetdemo20180821:
    Predict - [httpTrigger]
```

### Configure Platform

For the last part of the deployment step, we'll need to head over to the Azure Portal. To do so, visit [https://portal.azure.com](https://portal.azure.com) and log in.

Once logged in, type the name of your application into the search bar at the top of the page and select your Azure Function application of type `App Service`

![](http://cdn.lqdev.tech/files/images/azfnmlnetdemo1.png)

Then, from the accordion element on the left, select the top-most item with your appplication name on it. Then, select the `Platform features` tab and open the `Application settings` option.

![](http://cdn.lqdev.tech/files/images/azfnmlnetdemo2.png)

When the `Application settings` page loads, change the `Platform` setting to `64-bit`. The reason for this is `ML.NET` has to be built and run on a 64-bit environment due to some of its native dependencies. 

![](http://cdn.lqdev.tech/files/images/azfnmlnetdemo3.png)

That's all there is to it.

### Test The Deployed Function

Now it's time to test our deployed function. We can do so from the portal by going back to the accordion and selecting the function name below the `Functions` parent element and clicking on the `Test` button on the far right. Doing so will show a form that will allow us to test our application. Make sure the `HTTP method` option is set to POST. In the text area for the `Request body` paste the following content:

```json
{
  "SepalLength": 3.3,
  "SepalWidth": 1.6,
  "PetalLength": 0.2,
  "PetalWidth": 5.1
}
```

Once the form is filled in, click `Run` at the top of the page and if successful `Iris-virginica` should show up in the `Output` area.

![](http://cdn.lqdev.tech/files/images/azfnmlnetdemo4.png)

To test the function outside the portal, you can click on the `Get function URL` link next to the `Run` button and make an HTTP POST request using that link.

## Conclusion

In this writeup, we trained a classification model that predicts a class of flower using Microsoft's `ML.NET` framework. Then, we exposed this model for inference via an Azure Functions serverless application. In doing so, we can more efficiently manage our cost as well as our resource utilization. Happy coding!

###### Resources

[Create a function app for serverless code execution](https://docs.microsoft.com/en-us/azure/azure-functions/scripts/functions-cli-create-serverless)  
[Using the Azure CLI 2.0 with Azure Storage](https://docs.microsoft.com/en-us/azure/storage/common/storage-azure-cli)  
[Work with Azure Functions Core Tools](https://docs.microsoft.com/en-us/azure/azure-functions/functions-run-local)
]]&gt;</description>
      <link>https://www.lqdev.me/posts/serverless-machine-learning-mlnet-azure-functions</link>
      <guid>https://www.lqdev.me/posts/serverless-machine-learning-mlnet-azure-functions</guid>
      <pubDate>2018-08-21 19:13:47 -05:00</pubDate>
      <category>serverless</category>
      <category>azurefunctions</category>
      <category>mlnet</category>
      <category>machinelearning</category>
      <category>dotnet</category>
      <category>dotnetcore</category>
      <category>csharp</category>
      <category>microsoft</category>
      <category>devops</category>
      <category>artificialintelligence</category>
      <category>ai</category>
    </item>
    <item>
      <title>Classification with F# ML.NET Models</title>
      <description>&lt;![CDATA[
# Introduction

In a previous [post](http://luisquintanilla.me/2018/05/11/deploy-netml-docker-aci/), I detailed how to build and deploy C# `ML.NET` models with `Docker` and `ASP.NET Core`. With inspiration from [Jeff Fritz](https://twitter.com/csharpfritz), I have been learning F# for the past week and a half or so. When trying to think of projects to start practicing my F#, porting over the code I had built in C# naturally came to mind. After overcoming many obstacles and with much guidance from [Alan Ball](https://github.com/voronoipotato) and [Isaac Abraham](https://twitter.com/isaac_abraham) whose F# [book](https://www.amazon.com/Get-Programming-guide-NET-developers/dp/1617293997/ref=sr_1_1?ie=UTF8&amp;qid=1528929802&amp;sr=8-1&amp;keywords=get+programming+with+F%23) I highly recommend, I was able to successfully port over the main parts of my code which highlight `ML.NET` functionality. In this writeup, I will port a C# `ML.NET` classification model to F# which predicts the type of flower based on four numerical measurement inputs. I tried to keep the organization of this post nearly identical to that of the C# article where possible. Sample code for this project can be found at the following [link](https://github.com/lqdev/fsmlnetdemo).

## Prerequisites

This project was built on a Linux PC but should work cross-platform on Mac and Windows.

- [.NET Core SDK 2.0+](https://www.microsoft.com/net/download/linux)
- [Ionide Extension - Option 1](https://fsharp.org/use/linux/)
- [ML.NET v 0.2.0](https://www.nuget.org/packages/Microsoft.ML/)

## Setting Up The Project

The first thing we want to do is create a folder for our solution.

```bash
mkdir fsharpmlnetdemo
```

Then, we want to create a solution inside our newly created folder.

```bash
cd fsharpmlnetdemo
dotnet new sln
```

## Building The Model

### Setting Up The Model Project

First, we want to create the project. From the solution folder enter:

```bash
dotnet new console -o model -lang f#
```

Now we want to add this new project to our solution.

```bash
dotnet sln add model/model.fsproj
```

### Adding Dependencies

Since we’ll be using the `ML.NET` framework, we need to add it to our `model` project.

```bash
dotnet add model/model.fsproj package Microsoft.ML
```

### Download The Data

Before we start training the model, we need to download the data we’ll be using to train. We do so by downloading the data file into our root solution directory.

```bash
curl -o iris-data.txt https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data
```

If we take a look at the data file, it should look something like this:

```bash
5.1,3.5,1.4,0.2,Iris-setosa
4.9,3.0,1.4,0.2,Iris-setosa
4.7,3.2,1.3,0.2,Iris-setosa
4.6,3.1,1.5,0.2,Iris-setosa
5.0,3.6,1.4,0.2,Iris-setosa
5.4,3.9,1.7,0.4,Iris-setosa
4.6,3.4,1.4,0.3,Iris-setosa
5.0,3.4,1.5,0.2,Iris-setosa
4.4,2.9,1.4,0.2,Iris-setosa
4.9,3.1,1.5,0.1,Iris-setosa
```

### Train Model

Now that we have all our dependencies set up, it’s time to build our model. I leveraged the demo that is used on the `ML.NET` Getting-Started [website](https://www.microsoft.com/net/learn/apps/machine-learning-and-ai/ml-dotnet/get-started/linux/ubuntu16-04).

#### Defining Data Structures

At the time of this writing, `ML.NET` version `0.2.0` does not fully support F# Records. A workaround for this are mutable classes. Not really inline with F# paradigms, but it should be good enough.

In the `Program.fs` file of our `model` project directory, let’s create two mutable classes called `IrisData` and `IrisPrediction` which will define our features and predicted attribute respectively. Both of them will use `Microsoft.ML.Runtime.Api` to add the property attributes.

Here is what our `IrisData` class looks like:

```fsharp
type IrisData() =
    [&lt;Column(ordinal = "0");DefaultValue&gt;]
    val mutable public SepalLength: float32

    [&lt;Column(ordinal = "1");DefaultValue&gt;]
    val mutable public SepalWidth: float32

    [&lt;Column(ordinal = "2");DefaultValue&gt;]
    val mutable public PetalLength:float32

    [&lt;Column(ordinal = "3");DefaultValue&gt;]
    val mutable public PetalWidth:float32

    [&lt;Column(ordinal = "4",name="Label");DefaultValue&gt;]
    val mutable public Label: string
```

Similarly, here is the `IrisPrediction` class:

```fsharp
type IrisPrediction() =
    [&lt;ColumnName "PredictedLabel";DefaultValue&gt;] val mutable public PredictedLabel : string
```

#### Building Training Pipeline

The way the `ML.NET` computations process is via a sequential pipeline of steps that are performed eventually leading up to the training of the model. We can add that logic inside the `main` function of our `Program.fs` file.

```fsharp
let dataPath = "./iris-data.txt"

// Initialize Compute Graph
let pipeline = new LearningPipeline()

// Load Data
pipeline.Add((new TextLoader(dataPath).CreateFrom&lt;IrisData&gt;separator=','))

// Transform Data
// Assign numeric values to text in the "Label" column, because
// only numbers can be processed during model training
pipeline.Add(new Transforms.Dictionarizer("Label"))

// Vectorize Features
pipeline.Add(new ColumnConcatenator("Features","SepalLength", "SepalWidth", "PetalLength", "PetalWidth"))

// Add Learner
pipeline.Add(new StochasticDualCoordinateAscentClassifier())

// Convert Label back to text
pipeline.Add(new ransforms.PredictedLabelColumnOriginalValueConverterPredictedLabelColumn = "PredictedLabel"))

//Train the model
let model = pipeline.Train&lt;IrisData, IrisPrediction&gt;()
```

#### Testing Our Model

Now that we have our data structures and model trained, it’s time to test it to make sure it's working. Following our training operation, we can add the following code.

```fsharp
// Test data for prediction
let testInstance = IrisData()
testInstance.SepalLength &lt;- 3.3f
testInstance.SepalWidth &lt;- 1.6f
testInstance.PetalLength &lt;- 0.2f
testInstance.PetalWidth &lt;- 5.1f

//Get Prediction
let prediction = model.Predict(testInstance)

//Output Prediction
printfn "Predicted flower type is: %s" prediction.PredictedLabel
```

Our final `Program.fs` file should contain content similar to that below:

```fsharp
open System
open Microsoft.ML
open Microsoft.ML.Runtime
open Microsoft.ML.Runtime.Api
open Microsoft.ML.Data
open Microsoft.ML.Transforms
open Microsoft.ML.Trainers

type IrisData() =

    [&lt;Column(ordinal = "0");DefaultValue&gt;] val mutable public SepalLength: float32
    [&lt;Column(ordinal = "1");DefaultValue&gt;] val mutable public SepalWidth: float32
    [&lt;Column(ordinal = "2");DefaultValue&gt;] val mutable public PetalLength:float32
    [&lt;Column(ordinal = "3");DefaultValue&gt;] val mutable public PetalWidth:float32
    [&lt;Column(ordinal = "4",name="Label");DefaultValue&gt;] val mutable public Label: string


type IrisPrediction() =

    [&lt;ColumnName "PredictedLabel";DefaultValue&gt;] val mutable public PredictedLabel : string

[&lt;EntryPoint&gt;]
let main argv =

    let dataPath = "./iris-data.txt"

    // Initialize Compute Graph
    let pipeline = new LearningPipeline()

    // Load Data
    pipeline.Add((new TextLoader(dataPath)).CreateFrom&lt;IrisData&gt;(separator=','))

    // Transform Data
    // Assign numeric values to text in the "Label" column, because
    // only numbers can be processed during model training
    pipeline.Add(new Transforms.Dictionarizer("Label"))

    // Vectorize Features
    pipeline.Add(new ColumnConcatenator("Features","SepalLength", "SepalWidth", "PetalLength", "PetalWidth"))

    // Add Learner
    pipeline.Add(new StochasticDualCoordinateAscentClassifier())

    // Convert Label back to text
    pipeline.Add(new Transforms.PredictedLabelColumnOriginalValueConverter(PredictedLabelColumn = "PredictedLabel"))

    //Train the model
    let model = pipeline.Train&lt;IrisData, IrisPrediction&gt;()

    // Test data for prediction
    let testInstance = IrisData()
    testInstance.SepalLength &lt;- 3.3f
    testInstance.SepalWidth &lt;- 1.6f
    testInstance.PetalLength &lt;- 0.2f
    testInstance.PetalWidth &lt;- 5.1f

    //Get Prediction
    let prediction = model.Predict(testInstance)

    //Output Prediction
    printfn "Predicted flower type is: %s" prediction.PredictedLabel
    0 // return an integer exit code
```

All set to run. We can do so by entering the following command from our solution directory:

```fsharp
dotnet run -p model/model.fsproj
```

Once the application has been run, the following output should display on the console.

```bash
Automatically adding a MinMax normalization transform, use 'norm=Warn' or 'norm=No' to turn this behavior off.
Using 2 threads to train.
Automatically choosing a check frequency of 2.
Auto-tuning parameters: maxIterations = 9998.
Auto-tuning parameters: L2 = 2.667734E-05.Auto-tuning parameters: L1Threshold (L1/L2) = 0.
Using best model from iteration 1066.Not training a calibrator because it is not needed.
Predicted flower type is: Iris-virginica
```

## Conclusion

In this post, we ported over a C# `ML.NET` classification model to F# which predicts the class of flower based on numerical measurement inputs. While several workarounds needed to be made, `ML.NET` is still in its infancy. As more people become involved and provide feedback hopefully in the near future, F# support and functionality will become more stable. Happy coding!
]]&gt;</description>
      <link>https://www.lqdev.me/posts/mlnet-classification-fsharp</link>
      <guid>https://www.lqdev.me/posts/mlnet-classification-fsharp</guid>
      <pubDate>2018-06-13 18:19:05 -05:00</pubDate>
      <category>fsharp</category>
      <category>dotnet</category>
      <category>dotnetcore</category>
      <category>programming</category>
      <category>development</category>
      <category>mlnet</category>
      <category>machinelearning</category>
      <category>artificialintelligence</category>
      <category>functionalprogramming</category>
    </item>
    <item>
      <title>Deploy .NET Machine Learning Models with ML.NET, ASP.NET Core, Docker and Azure Container Instances</title>
      <description>&lt;![CDATA[

# Introduction

Leading up to and during MS Build 2018 Microsoft has released a wide range of products that reduce the complexity that comes with building and deploying software. The focus this year was on Machine Learning and Artificial Intelligence. Some of the products I found particularly interesting are [Azure Container Instances](https://azure.microsoft.com/en-us/services/container-instances/) which makes it easier to run containerized applications without provisioning or managing servers and [ML.NET](https://www.microsoft.com/net/learn/apps/machine-learning-and-ai/ml-dotnet) which is a .NET cross-platform machine learning framework. In this writeup, I will make use of both these products by creating a machine learning classification model with `ML.NET`, exposing it via an ASP.NET Core Web API, packaging it into a Docker container and deploying it to the cloud via Azure Container Instances. Source code for this project can be found [here](https://github.com/lqdev/mlnetacidemo).

## Prerequisites

This writeup assumes that you have some familiarity with Docker. The following software/dependencies are also required to build and deploy the sample application. It's important to note the application was built on a Ubuntu 16.04 PC, but all the software is cross-platform and should work on any environment.

- [Docker](https://docs.docker.com/install/linux/docker-ce/ubuntu/)
- [Azure CLI](https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest)
- [.NET Core 2.0](https://www.microsoft.com/net/download/linux)
- [Docker Hub Account](https://hub.docker.com/)

## Setting Up The Project

The first thing we want to do is create a folder for our solution.

```bash
mkdir mlnetacidemo
```

Then, we want to create a solution inside our newly created folder.

```bash
cd mlnetacidemo
dotnet new sln
```

## Building The Model

Inside our solution folder, we want to create a new console application which is where we'll build and test our machine learning model.

### Setting Up the Model Project

First, we want to create the project. From the solution folder enter:

```bash
dotnet new console -o model
```

Now we want to add this new project to our solution.

```bash
dotnet sln mlnetacidemo.sln add model/model.csproj
```

### Adding Dependencies

Since we'll be using the `ML.NET` framework, we need to add it to our `model` project.

```bash
cd model
dotnet add package Microsoft.ML
dotnet restore
```

### Download The Data

Before we start training the model, we need to download the data we'll be using to train. We do so by creating a directory called `data` and downloading the data file onto there.

```bash
mkdir data
curl -o data/iris.txt https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data
```

If we take a look at the data file, it should look something like this:

```text
5.1,3.5,1.4,0.2,Iris-setosa
4.9,3.0,1.4,0.2,Iris-setosa
4.7,3.2,1.3,0.2,Iris-setosa
4.6,3.1,1.5,0.2,Iris-setosa
5.0,3.6,1.4,0.2,Iris-setosa
5.4,3.9,1.7,0.4,Iris-setosa
4.6,3.4,1.4,0.3,Iris-setosa
5.0,3.4,1.5,0.2,Iris-setosa
4.4,2.9,1.4,0.2,Iris-setosa
4.9,3.1,1.5,0.1,Iris-setosa
```

### Train Model

Now that we have all our dependencies set up, it's time to build our model. I leveraged the demo that is used on the [ML.NET Getting-Started website](https://www.microsoft.com/net/learn/apps/machine-learning-and-ai/ml-dotnet/get-started/linux/ubuntu16-04).

#### Defining Data Structures

In the root directory of our `model` project, let's create two classes called `IrisData` and `IrisPrediction` which will define our features and predicted attribute respectively. Both of them will use `Microsoft.ML.Runtime.Api` to add the property attributes.

Here is what our `IrisData` class looks like: 
```csharp
using Microsoft.ML.Runtime.Api;

namespace model
{
public class IrisData
    {
        [Column("0")]
        public float SepalLength;

        [Column("1")]
        public float SepalWidth;

        [Column("2")]
        public float PetalLength;
        
        [Column("3")]
        public float PetalWidth;

        [Column("4")]
        [ColumnName("Label")]
        public string Label;
    }       
}
```

Similarly, here is the `IrisPrediction` class:

```csharp
using Microsoft.ML.Runtime.Api;

namespace model
{
    public class IrisPrediction
    {
        [ColumnName("PredictedLabel")]
        public string PredictedLabels;
    }
}
```

#### Building Training Pipeline

The way the `ML.NET` computations process is via a sequential pipeline of steps that are performed eventually leading up to the training of the model. Therefore, we can create a class called `Model` to perform all of these tasks for us.

```csharp
using Microsoft.ML.Data;
using Microsoft.ML;
using Microsoft.ML.Runtime.Api;
using Microsoft.ML.Trainers;
using Microsoft.ML.Transforms;
using Microsoft.ML.Models;
using System;
using System.Threading.Tasks;

namespace model
{
    class Model
    {
        
        public static async Task&lt;PredictionModel&lt;IrisData,IrisPrediction&gt;&gt; Train(LearningPipeline pipeline, string dataPath, string modelPath)
        {
            // Load Data
            pipeline.Add(new TextLoader(dataPath).CreateFrom&lt;IrisData&gt;(separator:',')); 

            // Transform Data
            // Assign numeric values to text in the "Label" column, because 
            // only numbers can be processed during model training   
            pipeline.Add(new Dictionarizer("Label"));

            // Vectorize Features
            pipeline.Add(new ColumnConcatenator("Features", "SepalLength", "SepalWidth", "PetalLength", "PetalWidth"));

            // Add Learner
            pipeline.Add(new StochasticDualCoordinateAscentClassifier());

            // Convert Label back to text 
            pipeline.Add(new PredictedLabelColumnOriginalValueConverter() {PredictedLabelColumn = "PredictedLabel"});

            // Train Model
            var model = pipeline.Train&lt;IrisData,IrisPrediction&gt;();

            // Persist Model
            await model.WriteAsync(modelPath);

            return model;
        }
    }
}
```

In addition to building our pipeline and training our machine learning model, the `Model` class also serialized and persisted the model for future use in a file called `model.zip`.

#### Testing Our Model

Now that we have our data structures and model training pipeline set up, it's time to test everything to make sure it's working. We'll put our logic inside of our `Program.cs` file.

```csharp
using System;
using Microsoft.ML;

namespace model
{
    class Program
    {
        static void Main(string[] args)
        {

            string dataPath = "model/data/iris.txt";

            string modelPath = "model/model.zip";

            var model = Model.Train(new LearningPipeline(),dataPath,modelPath).Result;

            // Test data for prediction
            var prediction = model.Predict(new IrisData() 
            {
                SepalLength = 3.3f,
                SepalWidth = 1.6f,
                PetalLength = 0.2f,
                PetalWidth = 5.1f
            });

            Console.WriteLine($"Predicted flower type is: {prediction.PredictedLabels}");
        }
    }
}
```

All set to run. We can do so by entering the following command from our solution directory:

```bash
dotnet run -p model/model.csproj
```

Once the application has been run, the following output should display on the console. 

```text
Automatically adding a MinMax normalization transform, use 'norm=Warn' or
'norm=No' to turn this behavior off.Using 2 threads to train.
Automatically choosing a check frequency of 2.Auto-tuning parameters: maxIterations = 9998.
Auto-tuning parameters: L2 = 2.667734E-05.
Auto-tuning parameters: L1Threshold (L1/L2) = 0.Using best model from iteration 882.
Not training a calibrator because it is not needed.
Predicted flower type is: Iris-virginica
```

Additionally, you'll notice that a file called `model.zip` was created in the root directory of our `model` project. This persisted model can now be used outside of our application to make predictions, which is what we'll do next via an API.

## Exposing The Model

Once a machine learning model is built, you want to deploy it so it can start making predictions. One way to do that is via a REST API. At it's core, all our API needs to do is accept data input from the client and respond back with a prediction. To help us do that, we'll be using an ASP.NET Core API.

### Setting Up The API Project

The first thing we want to do is create the project.

```bash
dotnet new webapi -o api
```

Then we want to add this new project to our solution

```bash
dotnet sln mlnetacidemo.sln add api/api.csproj
```

### Adding Dependencies

Because we'll be loading our model and making predictions via our API, we need to add the `ML.NET` package to our `api` project.

```bash
cd api
dotnet add package Microsoft.ML
dotnet restore
```

### Referencing Our Model

In the previous step when we built our machine learning model, it was saved to a file called `model.zip`. This is the file we'll be referencing in our API to help us make predictions. To reference it in our API, simply copy it from the model project directory into our `api` project directory.

### Creating Data Models

Our model was built using data structures `IrisData` and `IrisPrediction` to define the features as well as the predicted attribute. Therefore, when our model makes predictions via our API, it needs to reference these data types as well. As a result, we need to define `IrisData` and `IrisPrediction` classes inside of our `api` project. The contents of the classes will be nearly identical to those in the `model` project with the only exception of our namespace changing from `model` to `api`.

```csharp
using Microsoft.ML.Runtime.Api;

namespace api
{
    public class IrisData
    {
        [Column("0")]
        public float SepalLength;

        [Column("1")]
        public float SepalWidth;

        [Column("2")]
        public float PetalLength;
        
        [Column("3")]
        public float PetalWidth;

        [Column("4")]
        [ColumnName("Label")]
        public string Label;
    }    
}
```

```csharp
using Microsoft.ML.Runtime.Api;

namespace api
{
    public class IrisPrediction
    {
        [ColumnName("PredictedLabel")]
        public string PredictedLabels;
    }
}
```

### Building Endpoints

Now that our project is set up, it's time to add a controller that will handle prediction requests from the client. In the `Controllers` directory of our `api` project we can create a new class called `PredictController` with a single `POST` endpoint. The contents of the file should look like the code below:

```csharp
using System;
using System.Collections.Generic;
using System.Linq;
using System.Threading.Tasks;
using Microsoft.AspNetCore.Mvc;
using Microsoft.ML;

namespace api.Controllers
{
    [Route("api/[controller]")]
    public class PredictController : Controller
    {
        // POST api/predict
        [HttpPost]
        public string Post([FromBody] IrisData instance)
        {
            var model = PredictionModel.ReadAsync&lt;IrisData,IrisPrediction&gt;("model.zip").Result;
            var prediction = model.Predict(instance);
            return prediction.PredictedLabels;
        }
    }
}
```

### Testing The API

Once our `predict` endpoint is set up, it's time to test it. From the root directory of our `mlnetacidemo` solution, enter the following command.

```bash
dotnet run -p api/api.csproj
```

In a client like POSTMAN or Insomnia, send an HHTP POST request to the endpoint `http://localhost:5000/api/predict`.

The body our request should look similar to the snippet below:

```json
{
	"SepalLength": 3.3,
	"SepalWidth": 1.6,
	"PetalLength": 0.2,
	"PetalWidth": 5.1,
}
```

If successful, the output returned should equal `Iris-virginica` just like our console application.

## Packaging The Application

Great! Now that our application is successfully running locally, it's time to package it up into a Docker container and push it to Docker Hub.

### Creating The Dockerfile

In our `mlnetacidemo` solution directory, create a `Dockerfile` with the following content:

```Dockerfile
FROM microsoft/dotnet:2.0-sdk AS build
WORKDIR /app

# copy csproj and restore as distinct layers
COPY *.sln .
COPY api/*.csproj ./api/
RUN dotnet restore

# copy everything else and build app
COPY api/. ./api/
WORKDIR /app/api
RUN dotnet publish -c release -o out


FROM microsoft/aspnetcore:2.0 AS runtime
WORKDIR /app
COPY api/model.zip .
COPY --from=build /app/api/out ./
ENTRYPOINT ["dotnet", "api.dll"]
```

### Building Our Image

To build the image, we need to enter the following command into the command prompt. This make take a while because it needs to download the .NET Core SDK and ASP.NET Core runtime Docker images.

```bash
docker build -t &lt;DOCKERUSERNAME&gt;/&lt;IMAGENAME&gt;:latest .
```

### Test Image Locally

We need to test our image locally to make sure it can run on the cloud. To do so, we can use the `docker run` command. 

```bash
docker run -d -p 5000:80 &lt;DOCKERUSERNAME&gt;/&lt;IMAGENAME&gt;:latest
```

Although the API is exposing port 80, we bind it to the local port 5000 just to keep our prior API request intact. When sending a POST request to `http://localhost:5000/api/predict` with the appropriate body, the response should again equal `Iris-virginica`.

To stop the container, use `Ctrl + C`.

### Push to Docker Hub

Now that the Docker image is successfully running locally, it's time to push to Docker Hub. Again, we use the Docker CLI to do this.

```bash
docker login
docker push &lt;DOCKERUSERNAME&gt;/&lt;IMAGENAME&gt;:latest
```

## Deploying To The Cloud

Now comes the final step which is to deploy and expose our machine learning model and API to the world. Our deployment will occur via Azure Container Instances because it requires almost no provisioning or management of servers. 

### Prepare Deployment Manifest

Although deployments can be performed inline in the command line, it's usually best to place all the configurations in a file for documentation and to save time not having to type in the parameters every time. With Azure, we can do that via a JSON file. 

```json
{
  "$schema":
    "https://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
  "contentVersion": "1.0.0.0",
  "parameters": {
    "containerGroupName": {
      "type": "string",
      "defaultValue": "mlnetacicontainergroup",
      "metadata": {
        "description": "Container Group name."
      }
    }
  },
  "variables": {
    "containername": "mlnetacidemo",
    "containerimage": "&lt;DOCKERUSERNAME&gt;/&lt;IMAGENAME&gt;:latest"
  },
  "resources": [
    {
      "name": "[parameters('containerGroupName')]",
      "type": "Microsoft.ContainerInstance/containerGroups",
      "apiVersion": "2018-04-01",
      "location": "[resourceGroup().location]",
      "properties": {
        "containers": [
          {
            "name": "[variables('containername')]",
            "properties": {
              "image": "[variables('containerimage')]",
              "resources": {
                "requests": {
                  "cpu": 1,
                  "memoryInGb": 1.5
                }
              },
              "ports": [
                {
                  "port": 80
                }
              ]
            }
          }
        ],
        "osType": "Linux",
        "ipAddress": {
          "type": "Public",
          "ports": [
            {
              "protocol": "tcp",
              "port": "80"
            }
          ]
        }
      }
    }
  ],
  "outputs": {
    "containerIPv4Address": {
      "type": "string",
      "value":
        "[reference(resourceId('Microsoft.ContainerInstance/containerGroups/', parameters('containerGroupName'))).ipAddress.ip]"
    }
  }
}
```

It's a lot to look at but for now we can use this template and save it to the file `azuredeploy.json` in the root directory of our `mlnetacidemo` solution. The only thing that needs to be changed is the value of the `containerimage` property. Replace it with your Docker Hub username and the name of the image you just pushed to Docker Hub.

### Deploy

In order to deploy our application we need to make sure to log into our Azure account. To do so via the Azure CLI, type into the command prompt:

```bash
az login
```

Follow the prompts to log in. Once logged in, it's time to create a resource group for our container.

```bash
az group create --name mlnetacidemogroup --location eastus
```

After the group has been successfully created it's time to deploy our application.

```bash
az group deployment create --resource-group mlnetacidemogroup --template-file azuredeploy.json
```

Give it a few minutes for your deployment to initialize. If the deployment was successful, you should see some output on the command line. Look for the `ContainerIPv4Address` property. This is the IP Address where your container is accessible. In POSTMAN or Insomnia, replace the URL to which you previously made a POST request to with `http://&lt;ContainerIPv4Address&gt;/api/predict` where `ContainerIPv4Address` is the value that was returned to the command line after the deployment. If successful, the response should be just like previous requests `Iris-virginica`.

Once you're finished, you can clean up resources with the following command:

```bash
az group delete --name mlnetacidemogroup
```

## Conclusion

In this writeup, we built a classification machine learning model using `ML.NET` that predicts the class of an iris plant given four measurement features, exposed it via an ASP.NET Core REST API, packaged it into a container and deployed it to the cloud using Azure Container Instances. As the model changes and becomes more complex, the process is standardized enough that extending this example would require minimal changes to our existing application. Happy Coding!
]]&gt;</description>
      <link>https://www.lqdev.me/posts/deploy-netml-docker-aci</link>
      <guid>https://www.lqdev.me/posts/deploy-netml-docker-aci</guid>
      <pubDate>2018-05-11 21:17:00 -05:00</pubDate>
      <category>azure</category>
      <category>devops</category>
      <category>dotnet</category>
      <category>ml</category>
      <category>ai</category>
      <category>microsoft</category>
      <category>programming</category>
      <category>development</category>
      <category>csharp</category>
      <category>aci</category>
      <category>docker</category>
      <category>mlnet</category>
      <category>webapi</category>
      <category>aspnetcore</category>
      <category>aspnet</category>
      <category>machinelearning</category>
      <category>artificialintelligence</category>
    </item>
  </channel>
</rss>