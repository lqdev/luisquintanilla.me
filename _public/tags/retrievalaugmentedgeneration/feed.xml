<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>Luis Quintanilla - retrievalaugmentedgeneration</title>
    <link>https://www.lqdev.me/tags/retrievalaugmentedgeneration</link>
    <description>All content tagged with 'retrievalaugmentedgeneration' by Luis Quintanilla</description>
    <lastBuildDate>2024-04-09 00:32 -05:00</lastBuildDate>
    <language>en</language>
    <item>
      <title>ARAGOG: Advanced RAG Output Grading</title>
      <description>&lt;![CDATA[[reshare] &lt;blockquote class="blockquote"&gt;
&lt;p&gt;Retrieval-Augmented Generation (RAG) is essential for integrating external knowledge into Large Language Model (LLM) outputs. While the literature on RAG is growing, it primarily focuses on systematic reviews and comparisons of new state-of-the-art (SoTA) techniques against their predecessors, with a gap in extensive experimental comparisons. This study begins to address this gap by assessing various RAG methods' impacts on retrieval precision and answer similarity. We found that Hypothetical Document Embedding (HyDE) and LLM reranking significantly enhance retrieval precision. However, Maximal Marginal Relevance (MMR) and Cohere rerank did not exhibit notable advantages over a baseline Naive RAG system, and Multi-query approaches underperformed. Sentence Window Retrieval emerged as the most effective for retrieval precision, despite its variable performance on answer similarity. The study confirms the potential of the Document Summary Index as a competent retrieval approach. All resources related to this research are publicly accessible for further investigation through our GitHub repository ARAGOG (this https URL). We welcome the community to further this exploratory study in RAG systems.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href="https://github.com/predlico/ARAGOG"&gt;GitHub repo&lt;/a&gt;&lt;/p&gt;
]]&gt;</description>
      <link>https://www.lqdev.me/responses/aragog-advanced-rag-output-grading</link>
      <guid>https://www.lqdev.me/responses/aragog-advanced-rag-output-grading</guid>
      <pubDate>2024-04-09 00:32 -05:00</pubDate>
      <category>rag</category>
      <category>ai</category>
      <category>research</category>
      <category>llm</category>
      <category>knowledge</category>
      <category>retrieval</category>
      <category>retrievalaugmentedgeneration</category>
    </item>
    <item>
      <title>Enhancing RAG-based application accuracy by constructing and leveraging knowledge graphs</title>
      <description>&lt;![CDATA[[reshare] &lt;blockquote class="blockquote"&gt;
&lt;p&gt;A practical guide to constructing and retrieving information from knowledge graphs in RAG applications with Neo4j and LangChain&lt;br /&gt;
&lt;br&gt;
Graph retrieval augmented generation (Graph RAG) is gaining momentum and emerging as a powerful addition to traditional vector search retrieval methods. This approach leverages the structured nature of graph databases, which organize data as nodes and relationships, to enhance the depth and contextuality of retrieved information.&lt;/p&gt;
&lt;/blockquote&gt;
]]&gt;</description>
      <link>https://www.lqdev.me/responses/enhace-rag-application-accuracy-knowledge-graphs</link>
      <guid>https://www.lqdev.me/responses/enhace-rag-application-accuracy-knowledge-graphs</guid>
      <pubDate>2024-03-17 21:29 -05:00</pubDate>
      <category>knowledgegraph</category>
      <category>rag</category>
      <category>genai</category>
      <category>langchain</category>
      <category>generativeai</category>
      <category>retrievalaugmentedgeneration</category>
      <category>patterns</category>
      <category>applicationpatterns</category>
    </item>
    <item>
      <title>Large Language Models with Semantic Search</title>
      <description>&lt;![CDATA[[bookmark] &lt;blockquote class="blockquote"&gt;
&lt;p&gt;Keyword search has been a common method for search for many years. But for content-rich websites like news media sites or online shopping platforms, the keyword search capability can be limiting. Incorporating large language models (LLMs) into your search can significantly enhance the user experience by allowing them to ask questions and find information in a much easier way.&lt;/p&gt;
&lt;p&gt;This course teaches the techniques needed to leverage LLMs into search.&lt;/p&gt;
&lt;p&gt;Throughout the lessons, youâ€™ll explore key concepts like dense retrieval, which elevates the relevance of retrieved information, leading to improved search results beyond traditional keyword search, and reranking, which injects the intelligence of LLMs into your search system, making it faster and more effective.&lt;/p&gt;
&lt;/blockquote&gt;
]]&gt;</description>
      <link>https://www.lqdev.me/bookmarks/llm-semantic-search-deeplearningai-course</link>
      <guid>https://www.lqdev.me/bookmarks/llm-semantic-search-deeplearningai-course</guid>
      <pubDate>2023-08-16 22:43 -05:00</pubDate>
      <category>ai</category>
      <category>llm</category>
      <category>course</category>
      <category>retrievalaugmentedgeneration</category>
    </item>
  </channel>
</rss>