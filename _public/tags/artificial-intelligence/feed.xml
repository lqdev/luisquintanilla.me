<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>Luis Quintanilla - artificial-intelligence</title>
    <link>https://www.lqdev.me/tags/artificial-intelligence</link>
    <description>All content tagged with 'artificial-intelligence' by Luis Quintanilla</description>
    <lastBuildDate>2019-12-17 19:59:06 -05:00</lastBuildDate>
    <language>en</language>
    <item>
      <title>Use machine learning to categorize web links with F# and ML.NET</title>
      <description>&lt;![CDATA[
## Introduction

This post is part of [F# Advent 2019](https://sergeytihon.com/2019/11/05/f-advent-calendar-in-english-2019/). Thank you [Sergey Tihon](https://twitter.com/sergey_tihon) for organizing this and the rest of the contributors for producing interesting, high-quality content.

I scan and read articles on a constant basis, such as those published as part of F# Advent. Those that I find interesting, or I want to save for later, I bookmark using [Pocket](https://getpocket.com/). One of the neat features it provides is tagging. You can add as many tags as you want to organize the bookmarked links. When I first started using the service, I was fairly good at adding tags. However, I've gotten lazy and don't do it as much. It would be nice if bookmarked links could automatically be categorized for me without having to provide the tags manually. Using machine learning, this task can be automated. In this writeup, I will show how to build a machine learning model using [ML.NET](https://dotnet.microsoft.com/apps/machinelearning-ai/ml-dotnet), a .NET, open-source, cross-platform machine learning framework to automatically categorize web links / articles.

## Prerequisites

This application was built on a Windows 10 PC, but should work cross-platform.

- [.NET Core SDK 2.1+](https://dotnet.microsoft.com/download)
- [Visual Studio Code](https://code.visualstudio.com/Download)
- [Ionide](http://ionide.io/)
- [Microsoft.ML NuGet package](https://www.nuget.org/packages/Microsoft.ML/)

## Create the solution

Make a new directory and create a solution by using the .NET CLI.

```powershell
mkdir FsAdvent2019
cd FsAdvent2019
dotnet new sln
```

Then, create an F# Console application.

```powershell
dotnet new console -o FsAdvent2019 -lang f#
```

Navigate to the console application directory and install the Microsoft.ML NuGet package.

```powershell
cd FsAdvent2019
dotnet add package Microsoft.ML -v 1.4.0
```

## Get the data

[Click on this link to download and unzip the data anywhere on your PC](https://archive.ics.uci.edu/ml/machine-learning-databases/00359/NewsAggregatorDataset.zip).

The data contains information about several articles that are separated into four categories: business (b), science and technology (t), entertainment (e) and health (h). Visit the [UCI Machine Learning repository website](https://archive.ics.uci.edu/ml/datasets/News+Aggregator) to learn more about the dataset.

Below is a sample of the data.

```text
ID    Title    Url    Publisher    Category    Story    Hostname    Timestamp
2	Fed's Charles Plosser sees high bar for change in pace of tapering	http://www.livemint.com/Politics/H2EvwJSK2VE6OF7iK1g3PP/Feds-Charles-Plosser-sees-high-bar-for-change-in-pace-of-ta.html	Livemint	b	ddUyU0VZz0BRneMioxUPQVP6sIxvM	www.livemint.com	1394470371207
3	US open: Stocks fall after Fed official hints at accelerated tapering	http://www.ifamagazine.com/news/us-open-stocks-fall-after-fed-official-hints-at-accelerated-tapering-294436	IFA Magazine	b	ddUyU0VZz0BRneMioxUPQVP6sIxvM	www.ifamagazine.com	1394470371550
4	Fed risks falling 'behind the curve', Charles Plosser says	http://www.ifamagazine.com/news/fed-risks-falling-behind-the-curve-charles-plosser-says-294430	IFA Magazine	b	ddUyU0VZz0BRneMioxUPQVP6sIxvM	www.ifamagazine.com	1394470371793
```

Inside the console application directory, create a new directory called *data* and copy the *newsCorpora.csv* file to it.

```powershell
mkdir data
```

## Define the schema

Open the *Program.fs* file and add the following `open` statements at the top.

```fsharp
open Microsoft.ML
open Microsoft.ML.Data
```

Directly below the `open` statements, define the data schema of the input and output of the machine learning model as records called `ModelInput` and `ModelOutput` respectively.

```fsharp
[&lt;CLIMutable&gt;]
type ModelInput = {
    [&lt;LoadColumn(1)&gt;]
    Title:string
    [&lt;LoadColumn(2)&gt;]
    Url:string
    [&lt;LoadColumn(3)&gt;]
    Publisher:string
    [&lt;LoadColumn(4)&gt;]
    Category:string
    [&lt;LoadColumn(6)&gt;]
    Hostname:string
}

[&lt;CLIMutable&gt;]
type ModelOutput = {
    PredictedLabel: string
}
```

As input, only the **Title**, **Url**, **Publisher** and **Hostname** columns are used to train the machine learning model and make predictions. The label or value to predict in this case is the **Category**. When a prediction is output by the model, its value is stored in a column called **PredictedLabel**.

## Create the application entry point

The `MLContext` is the entry point of all ML.NET applications which binds all tasks like data loading, data transformations, model training, model evaluation, and model saving/loading.

Inside of the `main` function, create an instance of `MLContext`.

```fsharp
let mlContext = MLContext()
```

## Load the data

Once the `MLContext` is initialized, use the `LoadFromTextFile` function and provide the path to the file containing the data.

```fsharp
let data = mlContext.Data.LoadFromTextFile&lt;ModelInput&gt;("data/newsCorpora.csv")
```

## Create training and test datasets

It's often good practice to split the data into train and test sets. The goal of a machine learning model is to accurately make predictions on data it has not seen before. Therefore, making predictions using inputs that are the same as those it was trained on may provide misleading accuracy metrics.

Use the `TrainTestSplit` to split the data into train / test sets with 90% of the data used for training and 10% used for testing.

```fsharp
let datasets = mlContext.Data.TrainTestSplit(data,testFraction=0.1)
```

## Define the transformation and algorithm pipelines

Now that the data is split, define the set of transformations to be applied to the data. The purpose of transforming the data is to convert it into numbers which are more easily processed by machine learning algorithms.

### Preprocessing pipeline

The preprocessing pipeline contains the series of transformations that take place before training the model. To create a pipeline, initialize an `EstimatorChain` and append the desired transformations to it.

```fsharp
let preProcessingPipeline = 
    EstimatorChain()
        .Append(mlContext.Transforms.Text.FeaturizeText("FeaturizedTitle","Title"))
        .Append(mlContext.Transforms.Text.FeaturizeText("FeaturizedUrl","Url"))
        .Append(mlContext.Transforms.Text.FeaturizeText("FeaturizedPublisher","Publisher"))
        .Append(mlContext.Transforms.Text.FeaturizeText("FeaturizedHost","Hostname"))
        .Append(mlContext.Transforms.Concatenate("Features",[|"FeaturizedTitle"; "FeaturizedUrl" ;"FeaturizedPublisher"; "FeaturizedHost"|]))
        .Append(mlContext.Transforms.Conversion.MapValueToKey("Label","Category"))
```

In this preprocessing pipeline, the following transformations are taking place:

1. Convert the *Title*, *Url*, *Publisher* and *Hostname* columns into numbers and store the transformed value into the *FeaturizedTitle*, *FeaturizedUrl*, *FeaturizedPublisher* and *FeaturizedHost* columns respectively.
2. Combine the *FeaturizedTitle*, *FeaturizedUrl*, *FeaturizedPublisher* and *FeaturizedHost* into one column called *Features*.
3. Create a mapping of the text value contained in the *Category* column to a numerical key and store the result into a new column called *Label*.

### Algorithm pipeline

The algorithm pipeline contains the algorithm used to train the machine learning model. In this application, the multiclass classification algorithm used is `LbfgsMaximumEntropy`. To learn more about the algorithm, see the [ML.NET LbfgsMaximumEntropy multiclass trainer API documentation](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.lbfgsmaximumentropymulticlasstrainer?view=ml-dotnet#training-algorithm-details).

```fsharp
let algorithm = 
    mlContext.MulticlassClassification.Trainers.LbfgsMaximumEntropy()
```

### Postprocessing pipeline

The postprocessing pipeline contains the series of transformations to get the output of training into a more readable format. The only transformation performed in this pipeline is mapping back the numerical value mapping of the predicted value into text form. 

```fsharp
let postProcessingPipeline = 
    mlContext.Transforms.Conversion.MapKeyToValue("PredictedLabel")
```

### Create training pipeline

Once the pipelines are defined, combine them into a single pipeline which applies all of the transformations to the data with a single function call.

```fsharp
let trainingPipeline = 
    preProcessingPipeline
        .Append(algorithm)
        .Append(postProcessingPipeline)
```

## Train the model

Use the `Fit` function to train the model by applying the set of transformations defined by `trainingPipeline` to the training dataset.

```fsharp
let model =
    datasets.TrainSet |&gt; trainingPipeline.Fit
```

## Evaluate the model

Once the model is trained, evaluate how well it performs against the test dataset. First, use the trained model to get the predicted category by using the `Transform` function. Then, provide the test dataset containing predictions to the `Evaluate` function which calculates the model's performance metrics by comparing the predicted category to the actual category and print some of them out.

```fsharp
let metrics = 
    (datasets.TestSet |&gt; model.Transform)
    |&gt; mlContext.MulticlassClassification.Evaluate

printfn "Log Loss: %f | MacroAccuracy: %f" metrics.LogLoss metrics.MacroAccuracy
```

## Using the model on real data

Create a list of `ModelInput` items and use the `Transform` method to get the predicted category.

```fsharp
let predictions = 
    [
        { 
            Title="A FIRST LOOK AT SURFACE DUO, MICROSOFT’S FOLDABLE ANDROID PHONE"
            Url="https://www.theverge.com/2019/10/3/20895268/microsoft-surface-duo-foldable-phone-dual-screen-android-hands-on-features-price-photos-video"
            Publisher="The Verge"
            Hostname="www.theverge.com" 
            Category = "" 
        }
        { 
            Title="This Shrinking Economy With Low Inflation Is Stuck on Rates"
            Url="https://www.bloomberg.com/news/articles/2019-12-12/when-a-shrinking-economy-and-low-inflation-don-t-mean-rate-cuts?srnd=economics-vp"
            Publisher="Bloomberg"
            Hostname="www.bloomberg.com" 
            Category = "" 
        }
    ] 
    |&gt; mlContext.Data.LoadFromEnumerable
    |&gt; model.Transform
```

Then, create a `Sequence` of `ModelOutput` values and print out the *PredictedLabel* values.

```fsharp
mlContext.Data.CreateEnumerable&lt;ModelOutput&gt;(predictions,false)
|&gt; Seq.iter(fun prediction -&gt; printfn "Predicted Value: %s" prediction.PredictedLabel)
```

The final *Program.fs* file should look as follows:

```fsharp
open System
open Microsoft.ML
open Microsoft.ML.Data

[&lt;CLIMutable&gt;]
type ModelInput = {
    [&lt;LoadColumn(1)&gt;]
    Title:string
    [&lt;LoadColumn(2)&gt;]
    Url:string
    [&lt;LoadColumn(3)&gt;]
    Publisher:string
    [&lt;LoadColumn(4)&gt;]
    Category:string
    [&lt;LoadColumn(6)&gt;]
    Hostname:string
}

[&lt;CLIMutable&gt;]
type ModelOutput = {
    PredictedLabel: string
}

[&lt;EntryPoint&gt;]
let main argv =

    let mlContext = MLContext()

    let data = mlContext.Data.LoadFromTextFile&lt;ModelInput&gt;("data/newsCorpora.csv")

    let datasets = mlContext.Data.TrainTestSplit(data,testFraction=0.1)

    let preProcessingPipeline = 
        EstimatorChain()
            .Append(mlContext.Transforms.Text.FeaturizeText("FeaturizedTitle","Title"))
            .Append(mlContext.Transforms.Text.FeaturizeText("FeaturizedUrl","Url"))
            .Append(mlContext.Transforms.Text.FeaturizeText("FeaturizedPublisher","Publisher"))
            .Append(mlContext.Transforms.Text.FeaturizeText("FeaturizedHost","Hostname"))
            .Append(mlContext.Transforms.Concatenate("Features",[|"FeaturizedTitle"; "FeaturizedUrl" ;"FeaturizedPublisher"; "FeaturizedHost"|]))
            .Append(mlContext.Transforms.Conversion.MapValueToKey("Label","Category"))

    let algorithm = 
        mlContext.MulticlassClassification.Trainers.LbfgsMaximumEntropy()

    let postProcessingPipeline = 
        mlContext.Transforms.Conversion.MapKeyToValue("PredictedLabel")

    let trainingPipeline = 
        preProcessingPipeline
            .Append(algorithm)
            .Append(postProcessingPipeline)

    let model =
        datasets.TrainSet |&gt; trainingPipeline.Fit

    let metrics = 
        (datasets.TestSet |&gt; model.Transform)
        |&gt; mlContext.MulticlassClassification.Evaluate

    printfn "Log Loss: %f | MacroAccuracy: %f" metrics.LogLoss metrics.MacroAccuracy

    let predictions = 
        [
            { 
                Title="A FIRST LOOK AT SURFACE DUO, MICROSOFT’S FOLDABLE ANDROID PHONE"
                Url="https://www.theverge.com/2019/10/3/20895268/microsoft-surface-duo-foldable-phone-dual-screen-android-hands-on-features-price-photos-video"
                Publisher="The Verge"
                Hostname="www.theverge.com" 
                Category = "" 
            }
            { 
                Title="This Shrinking Economy With Low Inflation Is Stuck on Rates"
                Url="https://www.bloomberg.com/news/articles/2019-12-12/when-a-shrinking-economy-and-low-inflation-don-t-mean-rate-cuts?srnd=economics-vp"
                Publisher="Bloomberg"
                Hostname="www.bloomberg.com" 
                Category = "" 
            }
        ] 
        |&gt; mlContext.Data.LoadFromEnumerable
        |&gt; model.Transform
 
    mlContext.Data.CreateEnumerable&lt;ModelOutput&gt;(predictions,false)
    |&gt; Seq.iter(fun prediction -&gt; printfn "Predicted Value: %s" prediction.PredictedLabel)

    0 // return an integer exit code
```

## Run the application

This particular model achieved a macro-accuracy of 0.92, where closer to 1 is preferred and log loss of 0.20 where closer to 0 is preferred.

```bash
Log Loss: 0.200502 | MacroAccuracy: 0.927742
```

The predicted values are the following:

```bash
Predicted Value: t
Predicted Value: b
```

Upon inspection, they appear to be correct, science and technology for the first link and business for the second link.

## Conclusion

In this writeup, I showed how to build a machine learning multiclass classification model that categorizes web links using ML.NET. Now that you have a model trained, you can save it and deploy it in another application (desktop, web) that bookmarks links. This model can be further improved and personalized by using data from Pocket which has already been tagged. Happy coding!]]&gt;</description>
      <link>https://www.lqdev.me/posts/categorize-web-links-ml-net-fsharp-fsadvent2019</link>
      <guid>https://www.lqdev.me/posts/categorize-web-links-ml-net-fsharp-fsadvent2019</guid>
      <pubDate>2019-12-17 19:59:06 -05:00</pubDate>
      <category>dotnet</category>
      <category>dotnet-core</category>
      <category>machine-learning</category>
      <category>ai</category>
      <category>artificial-intelligence</category>
      <category>ml</category>
      <category>fsharp</category>
      <category>functional-programming</category>
    </item>
    <item>
      <title>Restaurant Inspections ETL &amp; Data Enrichment with Spark.NET and ML.NET Automated (Auto) ML</title>
      <description>&lt;![CDATA[
## Introduction

Apache Spark is an open-source, distributed, general-purpose analytics engine. For years, it has been a staple in the Big Data ecosystem for batch and real-time processing on large datasets. Although native support for the platform is limited to the JVM set of languages, other languages typically used for data processing and analytics like Python and R have plugged into Spark's Interop layer to make use of its functionality. Around the Build 2019 conference, Microsoft announced Spark.NET. Spark.NET provides bindings written for the Spark Interop layer that allow you to work with components like Spark SQL and Spark Streaming inside your .NET applications. Because Spark.NET is .NET Standard 2.0 compliant, it can run operating systems like Windows, Mac and Linux. Spark.NET is an evolution of the Mobius project which provided .NET bindings for Spark.

This sample takes a restaurant violation dataset from the NYC Open Data portal and processes it using Spark.NET. Then, the processed data is used to train a machine learning model that attempts to predict the grade an establishment will receive after an inspection. The model will be trained using ML.NET, an open-source, cross-platform machine learning framework. Finally, data for which no grade currently exists will be enriched using the trained model to assign an expected grade.

The source code for this sample can be found in the [lqdev/RestaurantInspectionsSparkMLNET
GitHub repo](https://github.com/lqdev/RestaurantInspectionsSparkMLNET).

## Pre-requisites

This project was built using Ubuntu 18.04 but should work on Windows and Mac devices.

- [.NET Core 2.1 SDK](https://dotnet.microsoft.com/download/dotnet-core/2.1)
- [Java 8](https://www.java.com/en/download/)
- [Apache Spark 2.4.1 with Hadoop 2.7](https://archive.apache.org/dist/spark/spark-2.4.1/)
- [.NET Spark Worker 0.4.0](https://github.com/dotnet/spark/releases)

### Install Java

Since Spark runs on the JVM, you'll need Java on your PC. The minimum version required is version 8. To install and Java, enter the following command into the terminal:

```bash
sudo apt install openjdk-8-jdk openjdk-8-jre
```

Then, make sure that the recently installed version is the default

```bash
sudo update-alternatives --config java
```

### Download and configure Spark

Download Spark 2.4.1 with Hadoop 2.7 onto your computer. In this case, I'm placing it into my *Downloads* folder.

```bash
wget https://archive.apache.org/dist/spark/spark-2.4.1/spark-2.4.1-bin-hadoop2.7.tgz -O ~/Downloads/spark-2.4.1-bin-hadoop2.7.tgz
```

Extract the contents of the recently downloaded file into the */usr/bin/local* directory.

```bash
sudo tar -xvf ~/Downloads/spark-2.4.1-bin-hadoop2.7.tgz --directory /usr/local/bin
```

### Download and configure .NET Spark Worker

Download the .NET Spark worker onto your computer. In this case, I'm placing it into the *Downloads* folder.

```bash
wget https://github.com/dotnet/spark/releases/download/v0.4.0/Microsoft.Spark.Worker.netcoreapp2.1.linux-x64-0.4.0.tar.gz -O ~/Downloads/Microsoft.Spark.Worker.netcoreapp2.1.linux-x64-0.4.0.tar.gz
```

Extract the contents of the recently downloaded file into the */usr/bin/local* directory.

```bash
sudo tar -xvf ~/Downloads/Microsoft.Spark.Worker.netcoreapp2.1.linux-x64-0.4.0.tar.gz --directory /usr/local/bin
```

Finally, raise the permissions on the `Microsoft.Spark.Worker` program. This is required to execute User-Defined Functions (UDF).

```bash
sudo chmod +x /usr/local/bin/Microsoft.Spark.Worker-0.4.0/Microsoft.Spark.Worker
```

### Configure environment variables

Once you download and configure the pre-requisites, configure their locations in the system as environment variables. Open the *~/.bashrc* file and add the following content at the end of the file.

```bash
export SPARK_PATH=/usr/local/bin/spark-2.4.1-bin-hadoop2.7
export PATH=$SPARK_PATH/bin:$PATH
export HADOOP_HOME=$SPARK_PATH
export SPARK_HOME=$SPARK_PATH
export DOTNET_WORKER_DIR=/usr/local/bin/Microsoft.Spark.Worker-0.4.0
```

## Solution description

### Understand the data

The dataset used in this solution is the [*DOHMH New York City Restaurant Inspection Results*](https://data.cityofnewyork.us/Health/DOHMH-New-York-City-Restaurant-Inspection-Results/43nn-pn8j) and comes from the NYC Open Data portal. It is updated daily and contains assigned and pending inspection results and violation citations for restaurants and college cafeterias. The dataset excludes establishments that have gone out of business. Although the dataset contains several columns, only a subset of them are used in this solution. For a detailed description of the dataset, visit the dataset website.

### Understand the solution

This solution is made up of four different .NET Core applications:

- *RestaurantInspectionsETL*: .NET Core Console application that takes raw data and uses Spark.NET to clean and transform the data into a format that is easier to use as input for training and making predictions with a machine learning model built with ML.NET.
- *RestaurantInspectionsML*: .NET Core Class Library that defines the input and output schema of the ML.NET machine learning model. Additionally, this is where the trained model is saved to.
- *RestaurantInspectionsTraining*: .NET Core Console application that uses the graded data generated by the *RestaurantInspectionsETL* application to train a multiclass classification machine learning model using ML.NET's Auto ML.
- *RestaurantInspectionsEnrichment*: .NET Core Console application that uses the ungraded data generated by the *RestaurantInspectionsETL* application as input for the trained ML.NET machine learning model which predicts what grade an establishment is most likely to receive based on the violations found during inspection.

## Set up the solution

### Create solution directory

Create a new directory for your projects called *RestaurantInspectionsSparkMLNET* and navigate to it with the following command.

```bash
mkdir RestaurantInspectionsSparkMLNET &amp;&amp; cd RestaurantInspectionsSparkMLNET
```

Then, create a solution using the `dotnet cli`.

```bash
dotnet new sln
```

To ensure that the 2.1 version of the .NET Core SDK is used as the target framework, especially if you have multiple versions of the .NET SDK installed, create a file called *globals.json* in the *RestaurantInspectionsSparkMLNET* solution directory.

```bash
touch global.json
```

In the *global.json* file, add the following content. Make sure to use the specific version of the SDK installed on your computer. In this case, I have version `2.1.801` installed on my computer. You can use the `dotnet --list-sdks` command to list the installed SDK versions.

```json
{
  "sdk": {
    "version": "2.1.801"
  }
}
```

### Create and configure the ETL project

The ETL project is responsible for taking the raw source data and using Spark to apply a series of transformations to prepare the data to train the machine learning model as well as to enrich data with missing grades.

Inside the *RestaurantInspectionsSparkMLNET* solution directory, create a new console application called *RestaurantInspectionsETL* using the `dotnet cli`.

```bash
dotnet new console -o RestaurantInspectionsETL
```

Add the newly created project to the solution with the `dotnet cli`.

```bash
dotnet sln add ./RestaurantInspectionsETL/
```

Since this project uses the `Microsoft.Spark` NuGet package, use the `dotnet cli` to install it.

```bash
dotnet add ./RestaurantInspectionsETL/ package Microsoft.Spark --version 0.4.0
```

### Create and configure the ML model project

The ML model class library will contain the domain model that defines the schema of model inputs and outputs as well as the trained model itself.

Inside the *RestaurantInspectionsSparkMLNET* solution directory, create a new class library called *RestaurantInspectionsML* using the `dotnet cli`.

```bash
dotnet new classlib -o RestaurantInspectionsML
```

Add the newly created project to the solution with the `dotnet cli`.

```bash
dotnet sln add ./RestaurantInspectionsML/
```

Since this project uses the `Microsoft.ML` NuGet package, use the `dotnet cli` to install it.

```bash
dotnet add ./RestaurantInspectionsML/ package Microsoft.ML --version 1.3.1
```

### Create and configure the ML training project

The purpose of the training project is to use the pre-processed graded data output by the *RestaurantInspectionsETL* project as input to train a multiclass classification model with ML.NET's Auto ML API. The trained model will then be saved in the *RestaurantInspectionsML* directory.

Inside the *RestaurantInspectionsSparkMLNET* solution directory, create a new console application called *RestaurantInspectionsTraining* using the `dotnet cli`.

```bash
dotnet new console -o RestaurantInspectionsTraining
```

Add the newly created project to the solution with the `dotnet cli`.

```bash
dotnet sln add ./RestaurantInspectionsTraining/
```

This project depends on the domain model created in the *RestaurantInspectionsML* project, so you need to add a reference to it.  

```bash
dotnet add ./RestaurantInspectionsTraining/ reference ./RestaurantInspectionsML/
```

Since this project uses the `Microsoft.Auto.ML` NuGet package, use the `dotnet cli` to install it.

```bash
dotnet add ./RestaurantInspectionsTraining/ package Microsoft.ML.AutoML --version 0.15.1
```

### Create and configure the data enrichment project

The data enrichment application uses the trained machine learning model created by the *RestaurantInspectionsTraining* application and use it on the pre-processed ungraded data created by the *RestaurantInspectionsETL* application to predict what grade that establishment is most likely to receive based on the violations found during inspection.

Inside the *RestaurantInspectionsSparkMLNET* solution directory, create a new console application called *RestaurantInspectionsEnrichment* using the `dotnet cli`.

```bash
dotnet new console -o RestaurantInspectionsEnrichment
```

Add the newly created project to the solution with the `dotnet cli`.

```bash
dotnet sln add ./RestaurantInspectionsEnrichment/
```

This project depends on the domain model created in the *RestaurantInspectionsML* project, so you need to add a reference to it.

```bash
dotnet add ./RestaurantInspectionsEnrichment/ reference ./RestaurantInspectionsML/
```

This uses the following NuGet packages:

- Microsoft.Spark
- Microsoft.ML.LightGBM (This is not required but predictions may fail if the final model is a LightGBM model).

Install the packages with the following commands:

```bash
dotnet add ./RestaurantInspectionsEnrichment/ package Microsoft.Spark --version 0.4.0
dotnet add ./RestaurantInspectionsEnrichment/ package Microsoft.ML.LightGBM --version 1.3.1
```

## Build ETL application

The first step is to prepare the data. To do so, apply a set of transformations using Spark.NET.

### Download the data

Navigate to the *RestaurantInspectionsETL* project and create a *Data* directory.

```bash
mkdir Data
```

Then, download the data into the newly created *Data* directory.

```bash
wget https://data.cityofnewyork.us/api/views/43nn-pn8j/rows.csv?accessType=DOWNLOAD -O Data/NYC-Restaurant-Inspections.csv
```

### Build the ETL pipeline

Add the following usings to the *Program.cs* file.

```csharp
using System;
using System.IO;
using Microsoft.Spark.Sql;
using static Microsoft.Spark.Sql.Functions;
```

Not all of the columns are relevant. Inside the `Main` method of the *Program.cs* file, define the columns to be removed.

```csharp
string[] dropCols = new string[]
{
    "CAMIS",
    "CUISINE DESCRIPTION",
    "VIOLATION DESCRIPTION",
    "BORO",
    "BUILDING",
    "STREET",
    "ZIPCODE",
    "PHONE",
    "ACTION",
    "GRADE DATE",
    "RECORD DATE",
    "Latitude",
    "Longitude",
    "Community Board",
    "Council District",
    "Census Tract",
    "BIN",
    "BBL",
    "NTA"
};
```

The entrypoint of Spark applications is the `SparkSession`. Create `SparkSession` inside the `Main` method of the *Program.cs* file.

```csharp
var sc =
    SparkSession
        .Builder()
        .AppName("Restaurant_Inspections_ETL")
        .GetOrCreate();
```

Then, load the data stored in the *NYC-Restaurant-Inspections.csv* file into a `DataFrame`.

```csharp
DataFrame df =
    sc
    .Read()
    .Option("header", "true")
    .Option("inferSchema", "true")
    .Csv("Data/NYC-Restaurant-Inspections.csv");
```

`DataFrames` can be thought of as tables in a database or sheets in Excel. Spark has various ways of representing data but `DataFrames` are the format supported by Spark.NET. Additionally, the `DataFrame` API is higher-level and easier to work with.

Once the data is loaded, get rid of the data that are not needed by creating a new `DataFrame` that excludes the `dropCols` as well as missing values.

```csharp
DataFrame cleanDf =
    df
        .Drop(dropCols)
        .WithColumnRenamed("INSPECTION DATE","INSPECTIONDATE")
        .WithColumnRenamed("INSPECTION TYPE","INSPECTIONTYPE")
        .WithColumnRenamed("CRITICAL FLAG","CRITICALFLAG")
        .WithColumnRenamed("VIOLATION CODE","VIOLATIONCODE")
        .Na()
        .Drop();
```

Typically, machine learning models expect values to be numerical, so in the ETL step try to convert as many values as possible into numerical values. The `CRITICALFLAG` column contains "Y"/"N" values that can be encoded as 0 and 1.

```csharp
DataFrame labeledFlagDf =
    cleanDf
        .WithColumn("CRITICALFLAG",
            When(Functions.Col("CRITICALFLAG") == "Y",1)
            .Otherwise(0));
```

This dataset contains one violation per row which correspond to different inspections. Therefore, all of the violations need to be aggregated by business and inspection.

```csharp
DataFrame groupedDf =
    labeledFlagDf
        .GroupBy("DBA", "INSPECTIONDATE", "INSPECTIONTYPE", "CRITICALFLAG", "SCORE", "GRADE")
        .Agg(Functions.CollectSet(Functions.Col("VIOLATIONCODE")).Alias("CODES"))
        .Drop("DBA", "INSPECTIONDATE")
        .WithColumn("CODES", Functions.ArrayJoin(Functions.Col("CODES"), ","))
        .Select("INSPECTIONTYPE", "CODES", "CRITICALFLAG", "SCORE", "GRADE");  
```

Now that the data is in the format used to train and make predictions, split the cleaned `DataFrame` into two new `DataFrames`, graded and ungraded. The graded dataset is the data used for training the machine learning model. The ungraded data will be used for enrichment.

```csharp
DataFrame gradedDf =
    groupedDf
    .Filter(
        Col("GRADE") == "A" |
        Col("GRADE") == "B" |
        Col("GRADE") == "C" );

DataFrame ungradedDf =
    groupedDf
    .Filter(
        Col("GRADE") != "A" &amp;
        Col("GRADE") != "B" &amp;
        Col("GRADE") != "C" );  
```

Take the `DataFrames` and save them as csv files for later use.

```csharp
var timestamp = ((DateTimeOffset) DateTime.UtcNow).ToUnixTimeSeconds().ToString();

var saveDirectory = Path.Join("Output",timestamp);

if(!Directory.Exists(saveDirectory))
{
    Directory.CreateDirectory(saveDirectory);
}

gradedDf.Write().Csv(Path.Join(saveDirectory,"Graded"));

ungradedDf.Write().Csv(Path.Join(saveDirectory,"Ungraded"));
```

### Publish and run the ETL application

The final *Program.cs* file should look as follows:

```csharp
using System;
using System.IO;
using Microsoft.Spark.Sql;
using static Microsoft.Spark.Sql.Functions;

namespace RestaurantInspectionsETL
{
    class Program
    {
        static void Main(string[] args)
        {
            // Define columns to remove
            string[] dropCols = new string[]
            {
                "CAMIS",
                "CUISINE DESCRIPTION",
                "VIOLATION DESCRIPTION",
                "BORO",
                "BUILDING",
                "STREET",
                "ZIPCODE",
                "PHONE",
                "ACTION",
                "GRADE DATE",
                "RECORD DATE",
                "Latitude",
                "Longitude",
                "Community Board",
                "Council District",
                "Census Tract",
                "BIN",
                "BBL",
                "NTA"
            };

            // Create SparkSession
            var sc =
                SparkSession
                    .Builder()
                    .AppName("Restaurant_Inspections_ETL")
                    .GetOrCreate();

            // Load data
            DataFrame df =
                sc
                .Read()
                .Option("header", "true")
                .Option("inferSchema", "true")
                .Csv("Data/NYC-Restaurant-Inspections.csv");

            //Remove columns and missing values
            DataFrame cleanDf =
                df
                    .Drop(dropCols)
                    .WithColumnRenamed("INSPECTION DATE","INSPECTIONDATE")
                    .WithColumnRenamed("INSPECTION TYPE","INSPECTIONTYPE")
                    .WithColumnRenamed("CRITICAL FLAG","CRITICALFLAG")
                    .WithColumnRenamed("VIOLATION CODE","VIOLATIONCODE")
                    .Na()
                    .Drop();

            // Encode CRITICAL FLAG column
            DataFrame labeledFlagDf =
                cleanDf
                    .WithColumn("CRITICALFLAG",
                        When(Functions.Col("CRITICALFLAG") == "Y",1)
                        .Otherwise(0));

             // Aggregate violations by business and inspection
            DataFrame groupedDf =
                labeledFlagDf
                    .GroupBy("DBA", "INSPECTIONDATE", "INSPECTIONTYPE", "CRITICALFLAG", "SCORE", "GRADE")
                    .Agg(Functions.CollectSet(Functions.Col("VIOLATIONCODE")).Alias("CODES"))
                    .Drop("DBA", "INSPECTIONDATE")
                    .WithColumn("CODES", Functions.ArrayJoin(Functions.Col("CODES"), ","))
                    .Select("INSPECTIONTYPE", "CODES", "CRITICALFLAG", "SCORE", "GRADE");

            // Split into graded and ungraded DataFrames
            DataFrame gradedDf =
                groupedDf
                .Filter(
                    Col("GRADE") == "A" |
                    Col("GRADE") == "B" |
                    Col("GRADE") == "C" );

            DataFrame ungradedDf =
                groupedDf
                    .Filter(
                        Col("GRADE") != "A" &amp;
                        Col("GRADE") != "B" &amp;
                        Col("GRADE") != "C" );

            // Save DataFrames
            var timestamp = ((DateTimeOffset) DateTime.UtcNow).ToUnixTimeSeconds().ToString();

            var saveDirectory = Path.Join("Output",timestamp);

            if(!Directory.Exists(saveDirectory))
            {
                Directory.CreateDirectory(saveDirectory);
            }

            gradedDf.Write().Csv(Path.Join(saveDirectory,"Graded"));

            ungradedDf.Write().Csv(Path.Join(saveDirectory,"Ungraded"));
        }
    }
}
```

Publish the application with the following command.

```bash
dotnet publish -f netcoreapp2.1 -r ubuntu.18.04-x64
```

Run the application with `spark-submit`.

```bash
spark-submit --class org.apache.spark.deploy.dotnet.DotnetRunner --master local bin/Debug/netcoreapp2.1/ubuntu.18.04-x64/publish/microsoft-spark-2.4.x-0.4.0.jar dotnet bin/Debug/netcoreapp2.1/ubuntu.18.04-x64/publish/RestaurantInspectionsETL.dll
```

## Build ML Domain

### Define the model input schema

Navigate to the *RestaurantInspectionsTraining* project directory and create a new file called *ModelInput.cs*.

```bash
touch ModelInput.cs
```

Open the *ModelInput.cs* file and add the following code.

```csharp
using Microsoft.ML.Data;

namespace RestaurantInspectionsML
{
    public class ModelInput
    {
        [LoadColumn(0)]
        public string InspectionType { get; set; }

        [LoadColumn(1)]
        public string Codes { get; set; }

        [LoadColumn(2)]
        public float CriticalFlag { get; set; }

        [LoadColumn(3)]
        public float InspectionScore { get; set; }

        [LoadColumn(4)]
        [ColumnName("Label")]
        public string Grade { get; set; }
    }
}
```

Using attributes in the schema, five properties are defined:

- InspectionType: The type of inspection performed.
- Codes: Violation codes found during inspection.
- CriticalFlag: Indicates if any of the violations during the inspection were critical (contribute to food-borne illness).
- InspectionScore: Score assigned after inspection.
- Grade: Letter grade assigned after inspection

The `LoadColumn` attribute defines the position of the column in the file. Data in the last column is assigned to the `Grade` property but is then referenced as `Label` in the `IDataView`. The reason for using the `ColumnName` attribute is ML.NET algorithms have default column names and renaming properties at the schema class level removes the need to define the feature and label columns as parameters in the training pipeline.

### Define the model output schema

In the *RestaurantInspectionsTraining* project directory and create a new file called *ModelOutput.cs*.

```bash
touch ModelOutput.cs
```

Open the *ModelOutput.cs* file and add the following code.

```csharp
namespace RestaurantInspectionsML
{
    public class ModelOutput
    {
        public float[] Scores { get; set; }
        public string PredictedLabel { get; set; }
    }
}
```

For the output schema, the `ModelOutput` class uses properties with the default column names of the outputs generated by the model training process:

- Scores: A float vector containing the probabilties for all the predicted classes.
- PredictedLabel: The value of the prediction. In this case, the `PredictedLabel` is the predicted grade expected to be assigned after inspection given the set of features for that inspection.

## Build the model training application

The application trains a multiclass classification algorithm. Finding the "best" algorithm with the right parameters requires experimentation. Fortunately, ML.NET's Auto ML does this for you given you provide it with the type of algorithm you want to train.

### Load the graded data

Navigate to the *RestaurantInspectionsTraining* project directory and add the following using statements to the *Program.cs* class.

```csharp
using System;
using System.IO;
using System.Linq;
using Microsoft.ML;
using static Microsoft.ML.DataOperationsCatalog;
using Microsoft.ML.AutoML;
using RestaurantInspectionsML;
```

Inside the `Main` method of the *Program.cs* file, define the path where the data files are stored.

```csharp
string solutionDirectory = "/home/lqdev/Development/RestaurantInspectionsSparkMLNET";
string dataLocation = Path.Combine(solutionDirectory,"RestaurantInspectionsETL","Output");
```

The entrypoint of an ML.NET application is the `MLContext`. Initialize an `MLContext` instance.

```csharp
MLContext mlContext = new MLContext();
```

Next, get the paths of the data files. The output generated by the *RestaurantInspectionsETL* application contains both the csv files as well as files containing information about the partitions that created them. For training, only the csv files are needed.

```csharp
var latestOutput =
    Directory
        .GetDirectories(dataLocation)
        .Select(directory =&gt; new DirectoryInfo(directory))
        .OrderBy(directoryInfo =&gt; directoryInfo.Name)
        .Select(directory =&gt; Path.Join(directory.FullName,"Graded"))
        .First();

var dataFilePaths =
    Directory
        .GetFiles(latestOutput)
        .Where(file =&gt; file.EndsWith("csv"))
        .ToArray();
```

Then, load the data into an `IDataView`. An `IDataView` is similar to a `DataFrame` in that it is a way to represent data as rows, columns and their schema.

```csharp
var dataLoader = mlContext.Data.CreateTextLoader&lt;ModelInput&gt;(separatorChar:',', hasHeader:false, allowQuoting:true, trimWhitespace:true);

IDataView data = dataLoader.Load(dataFilePaths);
```

It's good practice to split the data into training and test sets for evaluation. Split the data into 80% training and 20% test sets.

```csharp
TrainTestData dataSplit = mlContext.Data.TrainTestSplit(data,testFraction:0.2);
IDataView trainData = dataSplit.TrainSet;
IDataView testData = dataSplit.TestSet;
```

### Create the experiment

Auto ML takes the data and runs experiments using different models and hyper-parameters in search of the "best" model. Define the settings for your experiment. In this case, the model will run for 600 seconds or 10 minutes and will try to find the model with the lowest log loss metric.

```csharp
var experimentSettings = new MulticlassExperimentSettings();
experimentSettings.MaxExperimentTimeInSeconds = 600;
experimentSettings.OptimizingMetric = MulticlassClassificationMetric.LogLoss;
```

Then, create the experiment.

```csharp
var experiment = mlContext.Auto().CreateMulticlassClassificationExperiment(experimentSettings);
```

After creating the experiment, run it.

```csharp
var experimentResults = experiment.Execute(data, progressHandler: new ProgressHandler());
```

By default, running the application won’t display progress information. However, a `ProgressHandler` object can be passed into the `Execute` method of an experiment which calls the implemented `Report` method.

Inside the *RestaurantInspectionsTraining* project directory, create a new file called *ProgressHandler.cs*.

```bash
touch ProgressHandler.cs
```

Then, add the following code:

```csharp
using System;
using Microsoft.ML.Data;
using Microsoft.ML.AutoML;

namespace RestaurantInspectionsTraining
{
    public class ProgressHandler : IProgress&lt;RunDetail&lt;MulticlassClassificationMetrics&gt;&gt;
    {
        public void Report(RunDetail&lt;MulticlassClassificationMetrics&gt; run)
        {
            Console.WriteLine($"Trained {run.TrainerName} with Log Loss {run.ValidationMetrics.LogLoss:0.####} in {run.RuntimeInSeconds:0.##} seconds");
        }
    }
}
```

The ProgressHandler class derives from the `IProgress&lt;T&gt;` interface which requires the implementation of the `Report` method. The object being passed into the Report method after each run is an `RunDetail&lt;MulticlassClassificationMetrics&gt;` object. Each time a run is complete, the `Report` method is called and the code inside it executes.

### Evaluate the results

Once the experiment has finished running, get the model from the best run. Add the following code to the `Main` method of the *Program.cs*.

```csharp
var bestModel = experimentResults.BestRun.Model;
```

Evaluate the performance of the model using the test dataset and measure it's Micro-Accuracy metric.

```csharp
IDataView scoredTestData = bestModel.Transform(testData);  
var metrics = mlContext.MulticlassClassification.Evaluate(scoredTestData);
Console.WriteLine($"MicroAccuracy: {metrics.MicroAccuracy}");
```

### Save the trained model

Finally, save the trained model to the *RestaurantInspectionsML* project.

```csharp
string modelSavePath = Path.Join(solutionDirectory,"RestaurantInspectionsML","model.zip");
mlContext.Model.Save(bestModel, data.Schema, modelSavePath);
```

A file called *model.zip* should be created inside the *RestaurantInspectionsML* project.

Make sure that the trained model file is copied to the output directory by adding the following contents to the *RestaurantInspectionsML.csproj* file in the *RestaurantInspectionsML* directory.

```xml
&lt;ItemGroup&gt;
  &lt;None Include="model.zip"&gt;
    &lt;CopyToOutputDirectory&gt;PreserveNewest&lt;/CopyToOutputDirectory&gt;
  &lt;/None&gt;
&lt;/ItemGroup&gt;
```

Copying it to the output directory of the *RestaurantInspectionsML* makes it easier to reference from the *RestaurantInspectionsEnrichment* project since that project already contains a reference to the *RestaurantInspectionsML* class library.

## Train the model

The final *Program.cs* file should look as follows:

```csharp
using System;
using System.IO;
using System.Linq;
using Microsoft.ML;
using static Microsoft.ML.DataOperationsCatalog;
using Microsoft.ML.AutoML;
using RestaurantInspectionsML;

namespace RestaurantInspectionsTraining
{
    class Program
    {
        static void Main(string[] args)
        {
            // Define source data directory paths
            string solutionDirectory = "/home/lqdev/Development/RestaurantInspectionsSparkMLNET";
            string dataLocation = Path.Combine(solutionDirectory,"RestaurantInspectionsETL","Output");

            // Initialize MLContext
            MLContext mlContext = new MLContext();

            // Get directory name of most recent ETL output
            var latestOutput =
                Directory
                    .GetDirectories(dataLocation)
                    .Select(directory =&gt; new DirectoryInfo(directory))
                    .OrderBy(directoryInfo =&gt; directoryInfo.Name)
                    .Select(directory =&gt; Path.Join(directory.FullName,"Graded"))
                    .First();

            var dataFilePaths =
                Directory
                    .GetFiles(latestOutput)
                    .Where(file =&gt; file.EndsWith("csv"))
                    .ToArray();

            // Load the data
            var dataLoader = mlContext.Data.CreateTextLoader&lt;ModelInput&gt;(separatorChar:',', hasHeader:false, allowQuoting:true, trimWhitespace:true);
            IDataView data = dataLoader.Load(dataFilePaths);

            // Split the data
            TrainTestData dataSplit = mlContext.Data.TrainTestSplit(data,testFraction:0.2);
            IDataView trainData = dataSplit.TrainSet;
            IDataView testData = dataSplit.TestSet;

            // Define experiment settings
            var experimentSettings = new MulticlassExperimentSettings();
            experimentSettings.MaxExperimentTimeInSeconds = 600;
            experimentSettings.OptimizingMetric = MulticlassClassificationMetric.LogLoss;

            // Create experiment
            var experiment = mlContext.Auto().CreateMulticlassClassificationExperiment(experimentSettings);

            // Run experiment
            var experimentResults = experiment.Execute(data, progressHandler: new ProgressHandler());

            // Best Run Results
            var bestModel = experimentResults.BestRun.Model;

            // Evaluate Model
            IDataView scoredTestData = bestModel.Transform(testData);  
            var metrics = mlContext.MulticlassClassification.Evaluate(scoredTestData);
            Console.WriteLine($"MicroAccuracy: {metrics.MicroAccuracy}");

            // Save Model
            string modelSavePath = Path.Join(solutionDirectory,"RestaurantInspectionsML","model.zip");
            mlContext.Model.Save(bestModel, data.Schema, modelSavePath);
        }
    }
}
```

Once all the code and configurations are complete, from the *RestaurantInspectionsTraining* directory, run the application using the `dotnet cli`. Remember this will take 10 minutes to run.

```bash
dotnet run
```

The console output should look similar to the output below:

```text
Trained LightGbmMulti with Log Loss 0.1547 in 1.55 seconds
Trained FastTreeOva with Log Loss 0.0405 in 65.58 seconds
Trained FastForestOva with Log Loss 0.0012 in 53.37 seconds
Trained LightGbmMulti with Log Loss 0.0021 in 4.55 seconds
Trained FastTreeOva with Log Loss 0.8315 in 5.22 seconds
MicroAccuracy: 0.999389615839469
```

## Build the data enrichment application

Now that the model is trained, it can be used to enrich the ungraded data.

### Initialize the PredictionEngine

Navigate to the *RestaurantInspectionsEnrichment* project directory and add the following using statements to the *Program.cs* class.

```csharp
using System.IO;
using System.Linq;
using Microsoft.ML;
using Microsoft.Spark.Sql;
using static Microsoft.Spark.Sql.Functions;
using RestaurantInspectionsML;
```

To make predictions, the model has to be loaded into the applicaton and because predictions are made one row at a time, a `PredictionEngine` has be created as well.

Inside the `Program` class, define the `PredictionEngine`.

```csharp
private static readonly PredictionEngine&lt;ModelInput,ModelOutput&gt; _predictionEngine;
```

Then, create a constructor to load the model and initialize it.

```csharp
static Program()
{
    MLContext mlContext = new MLContext();
    ITransformer model = mlContext.Model.Load("model.zip",out DataViewSchema schema);
    _predictionEngine = mlContext.Model.CreatePredictionEngine&lt;ModelInput,ModelOutput&gt;(model);
}
```

### Load the ungraded data

In the `Main` method of the `Program` class, define the location of the data files.

```csharp
string solutionDirectory = "/home/lqdev/Development/RestaurantInspectionsSparkMLNET";
string dataLocation = Path.Combine(solutionDirectory,"RestaurantInspectionsETL","Output");
```

Then, get the path of the most recent ungraded data generated by the *RestaurantInspectionsETL* application.

```csharp
var latestOutput =
    Directory
        .GetDirectories(dataLocation)
        .Select(directory =&gt; new DirectoryInfo(directory))
        .OrderBy(directoryInfo =&gt; directoryInfo.Name)
        .Select(directory =&gt; directory.FullName)
        .First();
```

Initialize a `SparkSession` for your enrichment application.

```csharp
var sc =
    SparkSession
        .Builder()
        .AppName("Restaurant_Inspections_Enrichment")
        .GetOrCreate();
```

The data generated by the *RestaurantInspectionsETL* does not have headers. However, the schema can be defined and set when the data is loaded.

```csharp
var schema = @"
    INSPECTIONTYPE string,
    CODES string,
    CRITICALFLAG int,
    INSPECTIONSCORE int,
    GRADE string";

DataFrame df = 
    sc
    .Read()
    .Schema(schema)
    .Csv(Path.Join(latestOutput,"Ungraded"));
```

### Define the UDF

There is no built-in function in Spark that allows you to use a `PredictionEngine`. However, Spark can be extended through UDFs. Keep in mind that UDFs are not optimized like the built-in functions. Therefore, whenever possible, try to use the built-in functions as much as possible.

In the `Program` class, create a new method called `PredictGrade` which takes in the set of features that make up the `ModelInput` expected by the trained model.

```csharp
public static string PredictGrade(
    string inspectionType,
    string violationCodes,
    int criticalFlag,
    int inspectionScore)
{
    ModelInput input = new ModelInput
    {
        InspectionType=inspectionType,
        Codes=violationCodes,
        CriticalFlag=(float)criticalFlag,
        InspectionScore=(float)inspectionScore
    };

    ModelOutput prediction = _predictionEngine.Predict(input);

    return prediction.PredictedLabel;
}
```

Then, inside the `Main` method, register the `PredictGrade` method as a UDF in your `SparkSession`.

```csharp
sc.Udf().Register&lt;string,string,int,int,string&gt;("PredictGrade",PredictGrade);
```

### Enrich the data

Once the UDF is registered, use it inside of a `Select` statement which creates a new `DataFrame` that includes the input features as well as the predicted grade output by the trained mdoel.

```csharp
var enrichedDf =
    df
    .Select(
        Col("INSPECTIONTYPE"),
        Col("CODES"),
        Col("CRITICALFLAG"),
        Col("INSPECTIONSCORE"),
        CallUDF("PredictGrade",
            Col("INSPECTIONTYPE"),
            Col("CODES"),
            Col("CRITICALFLAG"),
            Col("INSPECTIONSCORE")
        ).Alias("PREDICTEDGRADE")
    );
```

Finally, save the enriched `DataFrame`

```csharp
string outputId = new DirectoryInfo(latestOutput).Name;
string enrichedOutputPath = Path.Join(solutionDirectory,"RestaurantInspectionsEnrichment","Output");
string savePath = Path.Join(enrichedOutputPath,outputId);

if(!Directory.Exists(savePath))
{
    Directory.CreateDirectory(enrichedOutputPath);
}

enrichedDf.Write().Csv(savePath);
```

### Publish and run the enrichment application

The final *Program.cs* file should look as follows.

```csharp
using System.IO;
using System.Linq;
using Microsoft.ML;
using Microsoft.Spark.Sql;
using static Microsoft.Spark.Sql.Functions;
using RestaurantInspectionsML;

namespace RestaurantInspectionsEnrichment
{
    class Program
    {
        private static readonly PredictionEngine&lt;ModelInput,ModelOutput&gt; _predictionEngine;

        static Program()
        {
            MLContext mlContext = new MLContext();
            ITransformer model = mlContext.Model.Load("model.zip",out DataViewSchema schema);
            _predictionEngine = mlContext.Model.CreatePredictionEngine&lt;ModelInput,ModelOutput&gt;(model);
        }

        static void Main(string[] args)
        {
            // Define source data directory paths
            string solutionDirectory = "/home/lqdev/Development/RestaurantInspectionsSparkMLNET";
            string dataLocation = Path.Combine(solutionDirectory,"RestaurantInspectionsETL","Output");

            var latestOutput = 
                Directory
                    .GetDirectories(dataLocation)
                    .Select(directory =&gt; new DirectoryInfo(directory))
                    .OrderBy(directoryInfo =&gt; directoryInfo.Name)
                    .Select(directory =&gt; directory.FullName)
                    .First();

            var sc = 
                SparkSession
                    .Builder()
                    .AppName("Restaurant_Inspections_Enrichment")
                    .GetOrCreate();

            var schema = @"
                INSPECTIONTYPE string,
                CODES string,
                CRITICALFLAG int,
                INSPECTIONSCORE int,
                GRADE string";

            DataFrame df = 
                sc
                .Read()
                .Schema(schema)
                .Csv(Path.Join(latestOutput,"Ungraded"));

            sc.Udf().Register&lt;string,string,int,int,string&gt;("PredictGrade",PredictGrade);

            var enrichedDf = 
                df
                .Select(
                    Col("INSPECTIONTYPE"),
                    Col("CODES"),
                    Col("CRITICALFLAG"),
                    Col("INSPECTIONSCORE"),
                    CallUDF("PredictGrade",
                        Col("INSPECTIONTYPE"),
                        Col("CODES"),
                        Col("CRITICALFLAG"),
                        Col("INSPECTIONSCORE")
                    ).Alias("PREDICTEDGRADE")
                );

            string outputId = new DirectoryInfo(latestOutput).Name;
            string enrichedOutputPath = Path.Join(solutionDirectory,"RestaurantInspectionsEnrichment","Output");
            string savePath = Path.Join(enrichedOutputPath,outputId);

            if(!Directory.Exists(savePath))
            {
                Directory.CreateDirectory(enrichedOutputPath);
            }

            enrichedDf.Write().Csv(savePath);

        }

        public static string PredictGrade(
            string inspectionType,
            string violationCodes,
            int criticalFlag,
            int inspectionScore)
        {
            ModelInput input = new ModelInput
            {
                InspectionType=inspectionType,
                Codes=violationCodes,
                CriticalFlag=(float)criticalFlag,
                InspectionScore=(float)inspectionScore
            };

            ModelOutput prediction = _predictionEngine.Predict(input);

            return prediction.PredictedLabel;
        }
    }
}
```

From the *RestaurantInspectionsEnrichment* project publish the application with the following command.

```bash
dotnet publish -f netcoreapp2.1 -r ubuntu.18.04-x64
```

Navigate to the *publish* directory. In this case, it's *bin/Debug/netcoreapp2.1/ubuntu.18.04-x64/publish*.

From the *publish* directory, run the application with `spark-submit`.

```bash
spark-submit --class org.apache.spark.deploy.dotnet.DotnetRunner --master local microsoft-spark-2.4.x-0.4.0.jar dotnet RestaurantInspectionsEnrichment.dll
```

The file output should look similar to the contents below:

```text
Cycle Inspection / Initial Inspection,04N,1,13,A
Cycle Inspection / Re-inspection,08A,0,9,A
Cycle Inspection / Initial Inspection,"10B,10H",0,10,A
Cycle Inspection / Initial Inspection,10F,0,10,A
Cycle Inspection / Reopening Inspection,10F,0,3,C
```

## Conclusion

This solution showcased how Spark can be used within .NET applications with Spark.NET. Because it's part of the .NET ecosystem, other components and frameworks such as ML.NET can be leveraged to extend the system's capabilities. Although this sample was developed and run on a local, single-node cluster, Spark was made to run at scale. As such, this application can be further improved by setting up a cluster and running the ETL and enrichment workloads on there.

###### Resources

[Apache Spark](https://spark.apache.org/)
[Spark.NET](https://dotnet.microsoft.com/apps/data/spark)
[Spark.NET GitHub](https://github.com/dotnet/spark)
[Mobius](https://github.com/Microsoft/Mobius)
[NYC OpenData](https://opendata.cityofnewyork.us/)
]]&gt;</description>
      <link>https://www.lqdev.me/posts/restaurant-inspections-etl-data-enrichment-spark-auto-ml-net</link>
      <guid>https://www.lqdev.me/posts/restaurant-inspections-etl-data-enrichment-spark-auto-ml-net</guid>
      <pubDate>2019-09-15 15:12:01 -05:00</pubDate>
      <category>mlnet</category>
      <category>ml</category>
      <category>machine-learning</category>
      <category>ai</category>
      <category>artificial-intelligence</category>
      <category>big-data</category>
      <category>spark</category>
      <category>dotnet</category>
      <category>dotnetcore</category>
    </item>
    <item>
      <title>Machine Learning Lifecycle Management with ML.NET, Automated ML and MLFlow</title>
      <description>&lt;![CDATA[
## Introduction

As machine learning matures, best practices are starting to be adopted. Application lifecycle management has been a common practice within software development for some time. Now, some of those practices are starting to become adopted in the machine learning space. One of the challenges application lifecycle management addresses in machine learning is reproducibility.

Machine learning is extremely experimental in nature. Therefore, in order to find the "best" model, various algorithms and hyper-parameters need to be tested. This can sometimes be a manual process. At Build 2019, [Automated ML was announced](https://devblogs.microsoft.com/dotnet/announcing-ml-net-1-0/) for ML.NET. In addition to automating the training process, this framework will try to find the best model by iterating over various algorithms and hyper-parameters until it finds the "best" model based on the selected optimization metric. The output will consist of results for the best run along with results for all other runs. These runs contain performance metrics, learned model parameters, the training pipeline used and the trained model for the respective run. This information can then be used for auditing purposes as well as to reproduce results.

The results from running Automated ML can be persisted locally or in a database. However in 2018 a product called MLFlow was launched. [MLFlow](https://mlflow.org/) is an open source machine learning lifecycle management platform. Since its announcement, MLFlow has seen adoption throughout the industry and most recently [Microsoft announced native support for it inside of Azure ML](https://databricks.com/company/newsroom/press-releases/databricks-collaborates-with-microsoft-on-mlflow-open-source-project). Although MLFlow does not natively support .NET, it has a REST API that allows extensibility to non-natively supported languages. This means that if throughout your enterprise or projects, MLFlow has been adopted in Python or R applications, using the REST API you can integrate MLFlow into your ML.NET applications.

In this writeup, I will go over how to automatically build an ML.NET classification model that predicts iris flower types using Automated ML and then integrate MLFlow to log the results generated by the best run. The code for this sample can be found on [GitHub](https://github.com/lqdev/MLNETMLFlowSample).

## Prerequisites

This project was built on an Ubuntu 18.04 PC but should work on Windows and Mac. Note that MLFlow does not natively run on Windows at the time of this writing. To run it on Windows use [Windows Subsystem for Linux (WSL)](https://docs.microsoft.com/en-us/windows/wsl/install-win10).

- [Python 3.x](https://www.python.org/downloads/)
- [MLFlow](https://www.mlflow.org/docs/latest/quickstart.html)
- [.NET SDK 2.x](https://dotnet.microsoft.com/download)

## Setup

### Create Solution

First we'll start off by creating a solution for our project. In the terminal enter the following commands:

```bash
mkdir MLNETMLFlowSample &amp;&amp; cd MLNETMLFlowSample
dotnet new sln
```

### Create Console Application

Once the solution is created, from the root solution directory, enter the following commands into the terminal to create a console application.

```bash
dotnet new console -o MLNETMLFlowSampleConsole
```

Then, navigate into the newly created console application folder.

```bash
cd MLNETMLFlowSampleConsole
```

### Install NuGet Packages

For this solution, you'll need the following NuGet packages:

- [Microsoft.ML](https://www.nuget.org/packages/Microsoft.ML/)
- [Microsoft.ML.Auto](https://www.nuget.org/packages/Microsoft.ML.AutoML/)
- [MLFlow.NET](https://www.nuget.org/packages/MLFlow.NET/1.0.0-CI-20181206-054144)

From the console application directory, enter the following commands into the terminal to install the packages.

```bash
dotnet add package Microsof.ML
dotnet add package Microsoft.ML.AutoML
dotnet add package MLFlow.NET --version 1.0.0-CI-20181206-054144
```

### Get The Data

The data used in this dataset comes from the [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/index.php) and looks like the data below:

```text
5.1,3.5,1.4,0.2,Iris-setosa
4.9,3.0,1.4,0.2,Iris-setosa
4.7,3.2,1.3,0.2,Iris-setosa
4.6,3.1,1.5,0.2,Iris-setosa
```

First, create a directory for the data inside the console application directory:

```bash
mkdir Data
```

Then, download and save the file into the `Data` directory.

```bash
curl -o Data/iris.data https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data
```

Finally, make sure that the data file is copied into your output directory by adding the following section to your console application `csproj` file inside the `Project` tags:

```xml
&lt;ItemGroup&gt;
    &lt;Content Include="Data/iris.data"&gt;
        &lt;CopyToOutputDirectory&gt;PreserveNewest&lt;/CopyToOutputDirectory&gt;
    &lt;/Content&gt;
&lt;/ItemGroup&gt;
```

## Configure MLFlow Service

### MLFlow.NET Settings

MLFlow.NET requires two settings, the base URL where the MLFlow server listens on and the API endpoint. In this case since it will be running locally, the base URL is `http://localhost:5000`. In the console application directory, create a file called `appsettings.json` and add the following content:

```json
{
    "MLFlowConfiguration": {
        "MLFlowServerBaseUrl": "http://localhost:5000",
        "APIBase": "api/2.0/preview/mlflow/"
    }
}
```

To make sure that your `appsettings.json` is copied into your output directory, add the following content to your `csproj` file under the content tags that include the `iris.data` file.

```xml
&lt;Content Include="appsettings.json"&gt;
    &lt;CopyToOutputDirectory&gt;PreserveNewest&lt;/CopyToOutputDirectory&gt;
&lt;/Content&gt;
```

### Register MLFLow.NET Service

In this sample, the MLFlow.NET service is registered and used via dependency injection. However, in order to use dependency injection in our console application it first needs to be configured. In the console application directory, create a new file called `Startup.cs` and add the following code to it:

```csharp
using System;
using Microsoft.Extensions.Configuration;
using Microsoft.Extensions.DependencyInjection;
using MLFlow.NET.Lib;
using MLFlow.NET.Lib.Contract;
using MLFlow.NET.Lib.Model;

namespace MLNETMLFlowSampleConsole
{
    public class Startup
    {
        private readonly IConfiguration Configuration;
        public IServiceProvider Services;

        public Startup()
        {
            Configuration =
                new ConfigurationBuilder()
                    .AddJsonFile("appsettings.json", false)
                    .Build();
        }

        public void ConfigureServices()
        {
            var services = new ServiceCollection();

            // Add and configure MLFlow Service
            services.AddMFlowNet();
            services.Configure&lt;MLFlowConfiguration&gt;(
                Configuration.GetSection(nameof(MLFlowConfiguration))
            );

            Services = services.BuildServiceProvider();
        }
    }
}
```

The `Startup` class loads configuration settings from the `appsettings.json` file in the constructor. Then, the `ConfigureServices` method registers the MLFlow.NET service and configures it using the settings defined in the `appsettings.json` file. Once that this is set up, the service can be used throughout the application.

## Create Data Schema

When working with ML.NET, it often helps to create data models or classes that define the data's schema.

For this sample, there are four columns with float values which will be the input data or features. The last column is the type of iris flower which will be used as the label or the value to predict. 

First, create a new directory called `Domain` inside the console application directory to store the data model classes.

```bash
mkdir Domain
```

Inside the `Domain` directory, create a new file called `IrisData.cs` and add the following contents to the file:

```csharp
using Microsoft.ML.Data;

namespace MLNETMLFlowSample.Domain
{
    public class IrisData
    {
        [LoadColumn(0, 3),
        VectorType(4),
        ColumnName("Features")]
        public float Features { get; set; }

        [LoadColumn(4),
        ColumnName("Label")]
        public string IrisType { get; set; }
    }
}
```

Using attributes in the schema, we define two properties: `Features` and `IrisType`. Data from columns in positions 0-3 will be loaded as a float vector of size four into the `Features` property. ML.NET will then reference that column by the name `Features`. Data in the last column will be loaded into the `IrisType` property and be referenced by the name `Label`. The reason for setting column names is ML.NET algorithms have a default column names and renaming properties at the schema level removes the need to define the feature and label columns in the pipeline.

## Create Progress Handler

By default, running the application won't display progress information. However, a `ProgressHandler` object can be passed into the `Execute` method of an experiment which calls the implemented `Report` method.

Inside the console application directory, create a new file called `ProgressHandler.cs` and add the following code:

```csharp
using System;
using Microsoft.ML.AutoML;
using Microsoft.ML.Data;
using Microsoft.ML.Trainers;

namespace MLNETMLFlowSampleConsole
{
    public class ProgressHandler : IProgress&lt;RunDetail&lt;MulticlassClassificationMetrics&gt;&gt;
    {
        public void Report(RunDetail&lt;MulticlassClassificationMetrics&gt; runDetails)
        {
            Console.WriteLine($"Ran {runDetails.TrainerName} in {runDetails.RuntimeInSeconds:0.##} with Log Loss {runDetails.ValidationMetrics.LogLoss:0.####}");
        }
    }
}
```

The `ProgressHandler` class derives from the `IProgress&lt;T&gt;` interface which requires the implementation of the `Report` method. The object being passed into the `Report` method after each run is an `RunDetail&lt;MulticlassCLassificationMetrics&gt;` object. Each time a run is complete, the `Report` method is called and the code inside it executes.

## Create Experiment

Open the `Program.cs` file and add the following `using` statements.

```csharp
using System;
using System.IO;
using System.Threading.Tasks;
using Microsoft.ML;
using Microsoft.ML.Data;
using Microsoft.ML.AutoML;
using Microsoft.Extensions.DependencyInjection;
using MLNETMLFlowSampleConsole.Domain;
using MLFlow.NET.Lib;
using MLFlow.NET.Lib.Contract;
using MLFlow.NET.Lib.Model;
using MLFlow.NET.Lib.Model.Responses.Experiment;
using MLFlow.NET.Lib.Model.Responses.Run;
```

### Initialize Services

Then, inside of the `Program` class, define the `IMLFlowService`:

```csharp
private readonly static IMLFlowService _mlFlowService;
```

Directly after that, create a constructor which is where `_mlFLowService` will be instantiated.

```csharp
static Program()
{
    // Initialize app configuration
    var appConfig = new Startup();
    appConfig.ConfigureServices();

    // Initialize MLFlow service
    _mlFlowService = appConfig.Services.GetService&lt;IMLFlowService&gt;();
}
```

### Define Experiment Steps

Then, add a method called `RunExperiment` inside the `Program` class that contains the following code:

```csharp
public static async Task RunExperiment()
{
    // 1. Create MLContext
    MLContext ctx = new MLContext();

    // 2. Load data
    IDataView data = ctx.Data.LoadFromTextFile&lt;IrisData&gt;("Data/iris.data", separatorChar: ',');

    // 3. Define Automated ML.NET experiment settings
    var experimentSettings = new MulticlassExperimentSettings();
    experimentSettings.MaxExperimentTimeInSeconds = 30;
    experimentSettings.OptimizingMetric = MulticlassClassificationMetric.LogLoss;

    // 4. Create Automated ML.NET
    var experiment = ctx.Auto().CreateMulticlassClassificationExperiment(experimentSettings);

    // 5. Create experiment in MLFlow
    var experimentName = Guid.NewGuid().ToString();
    var experimentRequest = await _mlFlowService.GetOrCreateExperiment(experimentName);

    // 6. Run Automated ML.NET experiment
    var experimentResults = experiment.Execute(data, progressHandler: new ProgressHandler());

    // 7. Log Best Run
    LogRun(experimentRequest.ExperimentId,experimentResults);

    string savePath = Path.Join("MLModels", $"{experimentName}");
    string modelPath = Path.Join(savePath, "model.zip");

    if (!Directory.Exists(savePath))
    {
        Directory.CreateDirectory(savePath);
    }

    // 8. Save Best Trained Model
    ctx.Model.Save(experimentResults.BestRun.Model, data.Schema, modelPath);
}
```

The `RunExperiment` method does the following:

1. Creates an `MLContext` object.
2. Loads data from the `iris.data` file into an `IDataView`.
3. Configures experiment to run for 30 seconds and optimize the Log Loss metric.
4. Creates a new Automated ML.NET experiment.
5. Creates a new experiment in MLFlow to log information to.
6. Runs the Automated ML.NET experiment and provide an instance of `ProgressHandler` to output progress to the console.
7. Uses the `LogRun` method to log the results of the best run to MLFlow.
8. Creates a directory inside the `MLModels` directory using the name of the experiment and saves the trained model inside it under the `model.zip` file name.

### Log Progress

After the `RunExperiment` method, create the `LogRun` method and add the following code to it:

```csharp
static async void LogRun(int experimentId, ExperimentResult&lt;MulticlassClassificationMetrics&gt; experimentResults)
{
    // Define run
    var runObject = new CreateRunRequest();
    runObject.ExperimentId = experimentId;
    runObject.StartTime = ((DateTimeOffset)DateTime.UtcNow).ToUnixTimeMilliseconds();
    runObject.UserId = Environment.UserName;
    runObject.SourceType = SourceType.LOCAL;

    // Create new run in MLFlow
    var runRequest = await _mlFlowService.CreateRun(runObject);

    // Get information for best run
    var runDetails = experimentResults.BestRun;

    // Log trainer name
    await _mlFlowService.LogParameter(runRequest.Run.Info.RunUuid, nameof(runDetails.TrainerName), runDetails.TrainerName);

    // Log metrics
    await _mlFlowService.LogMetric(runRequest.Run.Info.RunUuid, nameof(runDetails.RuntimeInSeconds), (float)runDetails.RuntimeInSeconds);
    await _mlFlowService.LogMetric(runRequest.Run.Info.RunUuid, nameof(runDetails.ValidationMetrics.LogLoss), (float)runDetails.ValidationMetrics.LogLoss);
    await _mlFlowService.LogMetric(runRequest.Run.Info.RunUuid, nameof(runDetails.ValidationMetrics.MacroAccuracy), (float)runDetails.ValidationMetrics.MacroAccuracy);
    await _mlFlowService.LogMetric(runRequest.Run.Info.RunUuid, nameof(runDetails.ValidationMetrics.MicroAccuracy), (float)runDetails.ValidationMetrics.MicroAccuracy);
}
```

The `LogRun` method takes in the experiment ID and results. Then, it does the following:

1. Configures local `RunRequest` object to log in MLFlow.
2. Creates run in MLFLow using predefined configuration.
3. Logs the name of the machine learning algorithm used to train the best model in MLFlow.
4. Logs the amount of seconds it took to train the model in MLFLow.
5. Logs various performance metrics in MLFlow

### Implement Main Method

Finally, in the `Main` method of the `Program` class, call the `RunExperiment` method.

```csharp
static async Task Main(string[] args)
{
    // Run experiment
    await RunExperiment();
}
```

Since the `Main` method in the `Program` class will be async, you need to use the latest version of C#. To do so, add the following configuration inside the `PropertyGroup` section of your `csproj` file.

```xml
&lt;LangVersion&gt;latest&lt;/LangVersion&gt;
```

## Run The Application

### Start MLFlow Server

In the terminal, from the console application directory, enter the following command to start the MLFlow Server:

```bash
mlflow server
```

Navigate to `http://localhost:5000` in your browser. This will load the MLFLow UI.

![](http://cdn.lqdev.tech/files/images/ml-lifecycle-management-mlflow-automated-ml-net-1.png)

### Train Model

Then, in another terminal, from the console application directory, enter the following command to run the experiment:

```bash
dotnet build
dotnet run
```

As the experiment is running, the progress handler should be posting output to the console after each run.

```text
Ran AveragedPerceptronOva in 1.24 with Log Loss 0.253
Ran SdcaMaximumEntropyMulti in 3.21 with Log Loss 0.0608
Ran LightGbmMulti in 0.64 with Log Loss 0.2224
Ran FastTreeOva in 1.54 with Log Loss 0.3978
Ran LinearSvmOva in 0.25 with Log Loss 0.2874
Ran LbfgsLogisticRegressionOva in 0.36 with Log Loss 0.566
Ran SgdCalibratedOva in 0.78 with Log Loss 0.7224
Ran FastForestOva in 1.28 with Log Loss 0.125
Ran LbfgsMaximumEntropyMulti in 0.25 with Log Loss 0.4537
Ran SdcaMaximumEntropyMulti in 0.19 with Log Loss 0.4576
Ran LightGbmMulti in 0.25 with Log Loss 0.2592
Ran FastForestOva in 1.98 with Log Loss 0.0961
Ran SdcaMaximumEntropyMulti in 0.39 with Log Loss 0.108
```

Navigate to `http://localhost:5000` in your browser. You should then see the results of your experiment and runs there.

![](http://cdn.lqdev.tech/files/images/ml-lifecycle-management-mlflow-automated-ml-net-2.png)

Inspecting the detailed view of the best run for that experiment would look like the image below:

![](http://cdn.lqdev.tech/files/images/ml-lifecycle-management-mlflow-automated-ml-net-3.png)

You'll also notice that two directories were created inside the console application directory. On is an `MLModels` directory, inside of which a nested directory with the name of the experiment contains the trained model. Another called `mlruns`. In the `mlruns` directory are the results of the experiments logged in MLFlow.

## Conclusion

In this writeup, we built an ML.NET classification model using Automated ML. Then, the results of the best run generated by Automated ML were logged to an MLFlow server for later analysis. Note that although some of these tools are still in their nascent stage, as open source software, the opportunities for extensibility and best practice implementations are there. Happy coding!]]&gt;</description>
      <link>https://www.lqdev.me/posts/ml-lifecycle-management-mlflow-automated-ml-net</link>
      <guid>https://www.lqdev.me/posts/ml-lifecycle-management-mlflow-automated-ml-net</guid>
      <pubDate>2019-05-09 19:19:20 -05:00</pubDate>
      <category>machine-learning</category>
      <category>artificial-intelligence</category>
      <category>mlnet</category>
      <category>dotnet</category>
      <category>dotnetcore</category>
      <category>automatedml</category>
    </item>
    <item>
      <title>Transcribing Podcasts with Microsoft Speech API</title>
      <description>&lt;![CDATA[

# Introduction

I enjoy listening to podcasts in a wide range of topics that include but are not limited to politics, software development, history, comedy and true crime. While some of the more entertainment related podcasts are best enjoyed through audio, those that are related to software development or other type of hands-on topics would benefit greatly from having a transcript. Having a transcript allows me to go back after having listened to an interesting discussion and look directly at the content I am interested in without having to listen to the podcast again. This however is not always feasible given that it costs both time and money to produce a transcript. Fortunately, there are tools out there such as Google Cloud Speech and Microsoft Speech API which allow users to convert speech to text. For this writeup, I will be focusing on the Microsoft Speech API. Because podcasts tend to be long-form, I will be using the C# client library because it allows for long audio (greater than 15 seconds) to be transcribed. The purpose of this exercise is to create a console application that takes audio segments, converts them to text and stores the results in a text file with the goal of evaluating how well the Microsoft Speech API works. The source code for the console application can be found on [GitHub](https://github.com/lqdev/PodcastsBingSpeechAPIDemo)

## Prerequisites

- [Visual Studio Community](https://www.visualstudio.com/vs/community/)
- [Windows Subsystem for Linux (Ubuntu)](https://www.microsoft.com/store/productId/9NBLGGH4MSV6)
- [ffmpeg](https://ffmpeg.org/)

## Install/Enable Windows Subsystem for Linux
1. Open Powershell as Administrator and input
```powershell
Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux
```
2. Restart your computer
3. Open the Microsoft Store and install [Ubuntu](https://www.microsoft.com/store/productId/9NBLGGH4MSV6) Linux distribution
4. Once installed, click `Launch`
5. Create your LINUX user account (Keep in mind that this is not the same as your Windows account therefore it can be different).

## Install ffmpeg

Once Ubuntu is installed on your computer and you have created your LINUX user account, it's time to install `ffmpeg`. This will allow us to convert our file from `mp3` which is usually the format podcasts are in to `wav` which is the format accepted by the Microsoft Speech API

```bash
sudo apt install -y ffmpeg
```

## Get Bing Speech API Key

In order to use the Microsoft Speech API, an API key is required. This can be obtained using the following steps.

1. Navigate to the [Azure Cognitive Services](https://azure.microsoft.com/en-us/try/cognitive-services/) page.
2. Select the `Speech` tab
3. Click `Get API Key` and follow the instructions
4. Once you have an API key, make sure to store it somewhere like a text file in your computer for future use.

# File Prep

Before transcribing the files, they need to be converted to `wav` format if they are not already in it. In order to ease processing, they should be split into segments as opposed to having the API process an entire multi megabyte file. To do all this, inside the Ubuntu shell, first navigate to your `Documents` folder and create a new directory for the project.

```bash
cd /mnt/c/Users/&lt;USERNAME&gt;/Documents
mkdir testspeechapi
```

`USERNAME` is your Windows user name. This can be found by typing the following command into the Windows `CMD` prompt

```bash
echo %USERNAME%
```

## Download Audio Files

One of the podcasts I listen to is [Talk Python To Me](https://talkpython.fm/) by [Michael Kennedy](https://twitter.com/mkennedy). For the purpose of this exercise, aside from having great content, all of the episodes are transcribed and a link is provided to the `mp3` file. 

The file I will be using is from episode [#149](https://talkpython.fm/episodes/show/149/4-python-web-frameworks-compared), but it can easily be any of the episodes.

In the Ubuntu shell, download the file into the `testspeechapi` directory that was recently created using `wget`.

```bash
wget https://talkpython.fm/episodes/download/149/4-python-web-frameworks-compared.mp3 -O originalinput.mp3
```

## Download Transcripts

The transcripts can be found in GitHub at this [link](https://github.com/mikeckennedy/talk-python-transcripts/tree/master/transcripts). The original transcript will allow me to compare it to the output of the Microsoft Speech API and evaluate the accuracy.

We can download this file into the `testspeechapi` directory just like the audio file

```bash
wget https://raw.githubusercontent.com/mikeckennedy/talk-python-transcripts/master/transcripts/149.txt -O originaltranscript.txt
```

## Convert MP3 to WAV

Now that we have both the original audio file and transcript, it's time to convert the format from `mp3` to `wav`. To do this, we can use `ffmpeg`. In the Ubuntu shell, enter the following command.

```bash
ffmpeg -i originalinput.mp3 -f wav originalinput.wav
```

## Create Audio Segments

Once we have the proper format, it's time to make the files more manageable for processing. This can be done by splitting them up into equal segments using `ffmpeg`. In this case I'll be splitting it up into sixty second segments and storing them into a directory called `input` with the name `filexxxx.wav`. The `%04d` indicates that there will be 4 digits in the file name. Inside the Ubuntu shell and `testspeechapi` directory enter the following commands.

```bash
mkdir input
ffmpeg -i originalinput.wav -f segment -segment_time 60 -c copy input/file%04d.wav
```

# Building The Console Application

To get started building the console application, we can leverage the [Cognitive-Speech-STT-ServiceLibrary](https://github.com/Azure-Samples/Cognitive-Speech-STT-ServiceLibrary) sample program.

## Download The Sample Program

The first step will be to clone the sample program from GitHub onto your computer. In the Windows `CMD` prompt navigate to the `testspeechapi` folder and enter the following command.

```bash
git clone https://github.com/Azure-Samples/Cognitive-Speech-STT-ServiceLibrary
```

Once the project is on your computer, open the directory and launch the `SpeechClient.sln` solution in the `sample` directory

When the solution launches, open the `Program.cs` file and begin making modifications.

## Reading Files

To read files, we can create a function that will return the list of files in the specified directory.

```csharp
private static string[] GetFiles(string directory)
{
    string[] files = Directory.GetFiles(directory);
    return files;
}
```

## Process Files

Once we have the list of files, we can then process each file individually using the `Run` method. To do so, we need to make a slight modification to our `Main` method so that it iterates over each file and calls the `Run` method on it. To store the responses from the API, we'll also need a `StringBuilder` object which is declared at the top of our `Program.cs` file.

```csharp
finalResponse = new StringBuilder();
string[] files = GetFiles(args[0]);
foreach(var file in files)
{
    p.Run(file,"en-us",LongDictationUrl,args[1]).Wait();
    Console.WriteLine("File {0} processed",file);
}
```

## Transcribe Audio

The `Run` method can be left intact. However, the `Run` method uses the `OnRecognitionResult` method to handle the result of API responses. In the `OnRecognitionResult` method, we can remove almost everything that is originally there and replace it. The response from the API returns various results of potential phrases as well as a confidence value. Generally, most of the phrases are alike and the first value is good enough for our purposes. The code for this part will take the response from the API, append it to a `StringBuilder` object and return when completed.

```csharp
public Task OnRecognitionResult(RecognitionResult args)
{

    var response = args;

    if(response.Phrases != null)
    {
	finalResponse.Append(response.Phrases[0].DisplayText);
	finalResponse.Append("\n");
    }

    return CompletedTask;
}
```

## Output Transcribed Speech

When all the audio files have been processed, we can save the final output to a text file in the `testspeechapi` directory. This can be done with the `SaveOutput` function to which we pass in a file name and the `StringBuilder` object that captured responses from the API.

```csharp
private static void SaveOutput(string filename,StringBuilder content)
{
    StreamWriter writer = new StreamWriter(filename);
    writer.Write(content.ToString());
    writer.Close();
}
```

`SaveOutput` can then be called from our `Main` method like so.

```csharp
string username = Environment.GetEnvironmentVariable("USERNAME", EnvironmentVariableTarget.Process);
SaveOutput(String.Format(@"C:\\Users\\{0}\\Documents\\testspeechapi\\apitranscript.txt",username), finalResponse);
```

The final `Main` method should look similar to the code below

```csharp
public static void Main(string[] args)
{
    // Send a speech recognition request for the audio.
    finalResponse = new StringBuilder();

    string[] files = GetFiles(args[0]);

    var p = new Program();

    foreach (var file in files)
    {
	p.Run(file, "en-us", LongDictationUrl, args[1]).Wait();
	Console.WriteLine("File {0} processed", file);
    }

    string username = Environment.GetEnvironmentVariable("USERNAME", EnvironmentVariableTarget.Process);

    SaveOutput(String.Format(@"C:\\Users\\{0}\\Documents\\testspeechapi\\apitranscript.txt",username), finalResponse);
}
```

# Output

The program will save the output of the `StringBuilder` object `finalResponse` to the file `apitranscript.txt`.

Prior to running the program it needs to be built. In Visual Studio change the Solutions Configurations option from `Debug` to `Release` and build the application.

To run the program, navigate to the `C:\Users\%USERNAME%\Documents\testspeechapi\Cognitive-Speech-STT-ServiceLibrary\sample\SpeechClientSample\bin\Release` directory in the Windows `CMD` prompt and enter the following command and pass in the `input` directory where all the audio segments are stored and your API Key.

```bash
SpeechClientSample.exe C:\\Users\\%USERNAME%\\Documents\\testspeechapi\\input &lt;YOUR-API-KEY&gt;
```
This process may take a while due to the number of files being processed, so be patient.

## Sample Output

Original

&gt; Are you considering getting into web programming? Choosing a web framework like Pyramid, Flask, or Django can be daunting. It would be great to see them all build out the same application and compare the results side-by-side. That's why when I heard what Nicholas Hunt-Walker was up to, I had to have him on the podcast. He and I chat about four web frameworks compared. He built a data-driven web app with Flask, Tornado, Pyramid, and Django and then put it all together in a presentation. We're going to dive into that right now. This is Talk Python To Me, Episode 149, recorded January 30th, 2018. Welcome to Talk Python to Me, a weekly podcast on Python, the language, the libraries, the ecosystem, and the personalities. This is your host, Michael Kennedy, follow me on Twitter where I'm @mkennedy. Keep up with the show and listen to past episodes at talkpython.fm, and follow the show on Twitter via @talkpython. Nick, welcome to Talk Python.

API Response

&gt; Are you considering getting into web programming cheese in the web framework like plaster. Django can be daunting. It would be great to see them. Although that the same application and compare the results side by side. That's Why? When I heard. But Nicholas Hunt. Walker was up to, I had him on the podcast. He night chat about 4 web frameworks, compared he built a data driven web app with last tornado. Peermade Angangueo and then put it all together in a presentation. We have dive into that right now. This is talk by the to me, I was 149 recorded January 30th 2018. Welcome to talk python to me a weekly podcast on Python Language the library ecosystem in the personalities. Did you host Michael Kennedy? Follow me on Twitter where I'm at in Kennedy keep up with the show in the past episodes at talk python. Damn info, the show on Twitter via at Popeyes on. Nick Welcome to talk by phone.

# Conclusion

In this writeup, I converted an `mp3` podcast file to `wav` format and split it into sixty second segments using `ffmpeg`. The segments were then processed by a console application which uses the Microsoft Speech API to convert speech to text and the results were saved to a text file. When compared to the original transcript, the result produced by the API is inconsistent and at times incomprehensible. This does not mean that overall the API is unusable or inaccurate as many things could have contributed to the inaccuracy. However, the results were not as good as I would have hoped for.

###### Sources
- [Windows Subsystem for Linux Install Instructions](https://docs.microsoft.com/en-us/windows/wsl/install-win10)
- [Microsoft Speech API](https://docs.microsoft.com/en-us/azure/cognitive-services/speech/home)
]]&gt;</description>
      <link>https://www.lqdev.me/posts/transcribing-podcasts-microsoft-speech-api</link>
      <guid>https://www.lqdev.me/posts/transcribing-podcasts-microsoft-speech-api</guid>
      <pubDate>2018-02-11 20:34:37 -05:00</pubDate>
      <category>azure</category>
      <category>csharp</category>
      <category>apis</category>
      <category>nlp</category>
      <category>machine-learning</category>
      <category>artificial-intelligence</category>
      <category>microsoft</category>
    </item>
  </channel>
</rss>