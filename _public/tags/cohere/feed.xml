<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>Luis Quintanilla - cohere</title>
    <link>https://www.lqdev.me/tags/cohere</link>
    <description>All content tagged with 'cohere' by Luis Quintanilla</description>
    <lastBuildDate>2025-03-18 20:45 -05:00</lastBuildDate>
    <language>en</language>
    <item>
      <title>Introducing Command A</title>
      <description>&lt;![CDATA[[reshare] &lt;blockquote class="blockquote"&gt;
&lt;p&gt;Today, we’re introducing Command A, a new state-of-the-art generative model optimized for demanding enterprises that require fast, secure, and high-quality AI. Command A delivers maximum performance with minimal hardware costs when compared to leading proprietary and open-weights models, such as GPT-4o and DeepSeek-V3. For private deployments, Command A excels on business-critical agentic and multilingual tasks, while being deployable on just two GPUs, compared to other models that typically require as many as 32.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;Its 256k context length (2x most leading models) can handle much longer enterprise documents. Other key features include Cohere’s advanced retrieval-augmented generation (RAG) with verifiable citations, agentic tool use, enterprise-grade security, and strong multilingual performance.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;The next generation of Cohere models will help power a range of AI applications for customers across industries like finance, healthcare, manufacturing, energy, and the public sector. In particular, they will seamlessly integrate with North, our secure AI agents platform to unlock the full potential of your company data and people with AI agents.&lt;/p&gt;
&lt;/blockquote&gt;
]]&gt;</description>
      <link>https://www.lqdev.me/responses/introducing-command-a-cohere</link>
      <guid>https://www.lqdev.me/responses/introducing-command-a-cohere</guid>
      <pubDate>2025-03-18 20:45 -05:00</pubDate>
      <category>cohere</category>
      <category>ai</category>
      <category>llm</category>
    </item>
    <item>
      <title>Introducing Command R+: A Scalable LLM Built for Business</title>
      <description>&lt;![CDATA[[reshare] &lt;blockquote class="blockquote"&gt;
&lt;p&gt;Command R+ is a state-of-the-art RAG-optimized model designed to tackle enterprise-grade workloads, and is available first on Microsoft Azure&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;Command R+, like our recently launched Command R model, features a 128k-token context window and is designed to offer best-in-class:&lt;br /&gt;
&lt;br&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Advanced Retrieval Augmented Generation (RAG) with citation to reduce hallucinations&lt;/li&gt;
&lt;li&gt;Multilingual coverage in 10 key languages to support global business operations&lt;/li&gt;
&lt;li&gt;Tool Use to automate sophisticated business processes&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
]]&gt;</description>
      <link>https://www.lqdev.me/responses/introducing-cohere-comandr-plus</link>
      <guid>https://www.lqdev.me/responses/introducing-cohere-comandr-plus</guid>
      <pubDate>2024-04-04 22:46 -05:00</pubDate>
      <category>cohere</category>
      <category>llm</category>
      <category>comandr</category>
      <category>azure</category>
      <category>comandrplus</category>
    </item>
  </channel>
</rss>