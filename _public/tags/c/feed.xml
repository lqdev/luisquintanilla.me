<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>Luis Quintanilla - c</title>
    <link>https://www.lqdev.me/tags/c</link>
    <description>All content tagged with 'c' by Luis Quintanilla</description>
    <lastBuildDate>2024-07-29 22:26 -05:00</lastBuildDate>
    <language>en</language>
    <item>
      <title>Tensors from scratch series</title>
      <description>&lt;![CDATA[[star] &lt;p&gt;I've been enjoying reading through this Tensors series.&lt;/p&gt;
&lt;p&gt;If you're interested, here's also the link to &lt;a href="https://maharshi.bearblog.dev/tensors-from-scratch-part-1/"&gt;part 1&lt;/a&gt;.&lt;/p&gt;
]]&gt;</description>
      <link>https://www.lqdev.me/responses/tensors-from-scratch-blog-series</link>
      <guid>https://www.lqdev.me/responses/tensors-from-scratch-blog-series</guid>
      <pubDate>2024-07-29 22:26 -05:00</pubDate>
      <category>tensors</category>
      <category>math</category>
      <category>ai</category>
      <category>c</category>
      <category>machinelearning</category>
      <category>ml</category>
      <category>artificialintelligence</category>
    </item>
    <item>
      <title>Deep Dive into Ownership in Mojo</title>
      <description>&lt;![CDATA[[reshare] &lt;blockquote class="blockquote"&gt;
&lt;p&gt;In the second part of the ownership series in Mojo, we built on the mental model developed in the &lt;a href="http://www.modular.com/blog/what-ownership-is-really-about-a-mental-model-approach"&gt;first part&lt;/a&gt; and provided practical examples to illustrate how ownership works in Mojo. We covered the different kinds of values (BValue, LValue, and RValue) and how they propagate through expressions. We also explained the function argument conventions (borrowed, inout, owned) and demonstrated how these conventions help manage memory safely and efficiently. We concluded with three fundamental rules:&lt;br /&gt;
&lt;br&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Rule 1&lt;/strong&gt;: Owned arguments take RValue on the caller side but are LValue on the callee side.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Rule 2&lt;/strong&gt;: Owned arguments own the type if the transfer operator ^ is used; otherwise, they copy the type if it is Copyable.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Rule 3&lt;/strong&gt;: Copy operations are optimized to move operations if the type is Copyable and Movable and isnâ€™t used anymore, reducing unnecessary overhead.&lt;br /&gt;
&lt;br&gt;
Lastly, we emphasized that the main goals of ownership in Mojo are:&lt;br /&gt;
&lt;br&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Memory Safety&lt;/strong&gt;: Enforcing exclusive ownership and proper lifetimes to prevent memory errors such as use-after-free and double-free.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Performance Optimization&lt;/strong&gt;: Converting unnecessary copy operations into move operations to reduce overhead and enhance performance.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ease of Use&lt;/strong&gt;: Automating memory management through ownership rules and the transfer operator, simplifying development.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Compile-Time Guarantees&lt;/strong&gt;: Providing strong compile-time guarantees through type-checking and dataflow lifetime analysis, catching errors early in the development process.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
]]&gt;</description>
      <link>https://www.lqdev.me/responses/deep-dive-ownership-mojo</link>
      <guid>https://www.lqdev.me/responses/deep-dive-ownership-mojo</guid>
      <pubDate>2024-06-11 21:20 -05:00</pubDate>
      <category>mojo</category>
      <category>python</category>
      <category>c</category>
      <category>cpp</category>
      <category>c++</category>
      <category>pl</category>
      <category>programming</category>
      <category>programminglanguage</category>
    </item>
    <item>
      <title>Reproducing GPT-2 (124M) in llm.c in 90 minutes for $20</title>
      <description>&lt;![CDATA[[reshare] &lt;blockquote class="blockquote"&gt;
&lt;p&gt;...the TLDR is that we're training a 12-layer GPT-2 (124M), from scratch, on 10B tokens of FineWeb, with max sequence length of 1024 tokens.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;The 124M model is the smallest model in the GPT-2 series released by OpenAI in 2019, and is actually quite accessible today, even for the GPU poor. With llm.c, which is quite efficient at up to ~60% model flops utilization, reproducing this model on one 8X A100 80GB SXM node takes ~90 minutes. For example, on Lambda this node goes for ~$14/hr, so the total cost of reproducing this model today is about $20. You can train the model with a single GPU too, it would just take proportionally longer (e.g. ~4-24 hours depending on the GPU).&lt;/p&gt;
&lt;/blockquote&gt;
]]&gt;</description>
      <link>https://www.lqdev.me/responses/repro-gpt-2-llm-c-90-min-20-dollars-karpathy</link>
      <guid>https://www.lqdev.me/responses/repro-gpt-2-llm-c-90-min-20-dollars-karpathy</guid>
      <pubDate>2024-05-28 20:33 -05:00</pubDate>
      <category>ai</category>
      <category>llm</category>
      <category>gpt</category>
      <category>gpt2</category>
      <category>llmc</category>
      <category>c</category>
      <category>slm</category>
    </item>
    <item>
      <title>LLM training in simple, raw C/CUDA </title>
      <description>&lt;![CDATA[[reshare] &lt;blockquote class="blockquote"&gt;
&lt;p&gt;LLM training in simple, pure C/CUDA. There is no need for 245MB of PyTorch or 107MB of cPython. For example, training GPT-2 (CPU, fp32) is ~1,000 lines of clean code in a single file. It compiles and runs instantly, and exactly matches the PyTorch reference implementation. I chose GPT-2 as the first working example because it is the grand-daddy of LLMs, the first time the modern stack was put together.&lt;/p&gt;
&lt;/blockquote&gt;
]]&gt;</description>
      <link>https://www.lqdev.me/responses/llm-c-karpathy</link>
      <guid>https://www.lqdev.me/responses/llm-c-karpathy</guid>
      <pubDate>2024-04-09 22:15 -05:00</pubDate>
      <category>llm</category>
      <category>gpt</category>
      <category>c</category>
      <category>programming</category>
      <category>learning</category>
      <category>tutorial</category>
    </item>
  </channel>
</rss>