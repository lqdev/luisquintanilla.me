<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>Luis Quintanilla - training</title>
    <link>https://www.lqdev.me/tags/training</link>
    <description>All content tagged with 'training' by Luis Quintanilla</description>
    <lastBuildDate>2025-02-19 22:03 -05:00</lastBuildDate>
    <language>en</language>
    <item>
      <title>The Ultra-Scale Playbook: Training LLMs on GPU Clusters</title>
      <description>&lt;![CDATA[[reshare] &lt;p&gt;Gold.&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;All the techniques we'll cover in this book tackle one or several of the following three key challenges, which we'll keep bumping into throughout the book:&lt;/p&gt;
&lt;hr&gt;
  1. **Memory Usage**: it's a hard limitation - if a training step doesn't fit in memory, training cannot proceed  
  2. **Compute Efficiency**: we want our hardware to spend most time computing, so we need to reduce time spent on data transfers or waiting for other GPUs to perform work.  
  3. **Communication overhead**: we want to minimize communication overhead as it keeps GPUs idle. To archieve this we will try to make best use of intra-node (fast) and inter-node (slower) bandwidths as well as overlap communication with compute as much as possible.  
&lt;hr&gt;
In many places we'll see that we can trade one of these (computation, communication, memory) for another (e.g. recomputation or Tensor Parallelism). Finding the right balance is key to scaling training.
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src="https://nanotron-ultrascale-playbook.static.hf.space/dist/files/images/ultra-cheatsheet.svg" class="img-fluid" alt="Ultra-Scale Playbook Cheatsheet" /&gt;&lt;/p&gt;
]]&gt;</description>
      <link>https://www.lqdev.me/responses/ultrascale-playbook-training-llms-gpu-clusters</link>
      <guid>https://www.lqdev.me/responses/ultrascale-playbook-training-llms-gpu-clusters</guid>
      <pubDate>2025-02-19 22:03 -05:00</pubDate>
      <category>ai</category>
      <category>llm</category>
      <category>training</category>
    </item>
    <item>
      <title>Thinking LLMs: General Instruction Following with Thought Generation</title>
      <description>&lt;![CDATA[[reshare] &lt;blockquote class="blockquote"&gt;
&lt;p&gt;LLMs are typically trained to answer user questions or follow instructions similarly to how human experts respond. However, in the standard alignment framework they lack the basic ability of explicit thinking before answering. Thinking is important for complex questions that require reasoning and planning -- but can be applied to any task. We propose a training method for equipping existing LLMs with such thinking abilities for general instruction following without use of additional human data. We achieve this by an iterative search and optimization procedure that explores the space of possible thought generations, allowing the model to learn how to think without direct supervision. For each instruction, the thought candidates are scored using a judge model to evaluate their responses only, and then optimized via preference optimization. We show that this procedure leads to superior performance on AlpacaEval and Arena-Hard, and shows gains from thinking on non-reasoning categories such as marketing, health and general knowledge, in addition to more traditional reasoning &amp;amp; problem-solving tasks.&lt;/p&gt;
&lt;/blockquote&gt;
]]&gt;</description>
      <link>https://www.lqdev.me/responses/thinking-llms-instruction-following-thought-generation</link>
      <guid>https://www.lqdev.me/responses/thinking-llms-instruction-following-thought-generation</guid>
      <pubDate>2024-11-04 21:24 -05:00</pubDate>
      <category>ai</category>
      <category>llm</category>
      <category>research</category>
      <category>meta</category>
      <category>chainofthought</category>
      <category>training</category>
      <category>finetuning</category>
    </item>
    <item>
      <title>Training great LLMs entirely from ground up in the wilderness as a startup</title>
      <description>&lt;![CDATA[[reshare] &lt;blockquote class="blockquote"&gt;
&lt;p&gt;Given that we’ve successfully trained pretty strong multimodal language models at Reka, many people have been particularly curious about the experiences of building infrastructure and training large language &amp;amp; multimodal models from scratch from a completely clean slate.&lt;br /&gt;
&lt;br&gt;
I complain a lot about external (outside Google) infrastructure and code on my social media, leading people to really be curious about what are the things I miss and what I hate/love in the wilderness. So here’s a post (finally). This blogpost sheds light on the challenges and lessons learned.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;Figuring out things in the wilderness was an interesting experience. It was unfortunately not painless. Compute scarcity and also unreliable compute providers made things significantly harder than expected but we’re glad we pulled through with brute technical strength.&lt;br /&gt;
&lt;br&gt;
All in all, this is only a small part of the story of how we started a company, raised some money, bought some chips and matched Gemini pro/GPT 3.5 and outperformed many others in less than a year having to build everything from scratch.&lt;/p&gt;
&lt;/blockquote&gt;
]]&gt;</description>
      <link>https://www.lqdev.me/responses/training-llms-ground-up-wilderness-startup</link>
      <guid>https://www.lqdev.me/responses/training-llms-ground-up-wilderness-startup</guid>
      <pubDate>2024-03-07 21:10 -05:00</pubDate>
      <category>llm</category>
      <category>ai</category>
      <category>startup</category>
      <category>compute</category>
      <category>gpu</category>
      <category>training</category>
    </item>
  </channel>
</rss>