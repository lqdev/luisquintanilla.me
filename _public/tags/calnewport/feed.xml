<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>Luis Quintanilla - calnewport</title>
    <link>https://www.lqdev.me/tags/calnewport</link>
    <description>All content tagged with 'calnewport' by Luis Quintanilla</description>
    <lastBuildDate>2024-11-19 09:56 -05:00</lastBuildDate>
    <language>en</language>
    <item>
      <title>Digital minimalism: A moral duty?</title>
      <description>&lt;![CDATA[[reshare] &lt;p&gt;I saw a reference to this paper yesterday and added it to my Read-It-Later list.&lt;/p&gt;
&lt;p&gt;Here's a link to the original paper: &lt;a href="https://philpapers.org/archive/AYLITA.pdf"&gt;https://philpapers.org/archive/AYLITA.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Chances are, I wasnt going to get to it until way later with the backlog of other things I want to read later.&lt;/p&gt;
&lt;p&gt;Lucky for me, that was the subject of the latest Deep Questions episode. Cal does a nice job breaking down the main arguments of the paper.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=KK9ktzbBDPE" title="A thumbnail of Deep Questions Podcast Episode on Digital Minimalism"&gt;&lt;img src="http://img.youtube.com/vi/KK9ktzbBDPE/0.jpg" class="img-fluid" alt="A thumbnail of Deep Questions Podcast Episode on Digital Minimalism" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The main takeaway for me was, technology is a great tool. However, when it robs you of your rational decision making abilities and pushes you to compulsive behaviors that move you away from the habits and practices that fuel your growth, it's a problem. For example, lets say you want to build a habit of reading or working out. Unfortunately, when you &lt;INSERT TIME SUCKING DISTRACTION OF CHOICE&gt;, time, attention, and energy that would've otherwise been spent on those habits is now diverted towards the distraction. That is irrational and goes against your desire to grow, yet making the rational choice is where most of us struggle. Although the paper focuses on our digital lives, I can see other ways similar arguments can be applied.&lt;/p&gt;
&lt;p&gt;I've also included the audio version as well: &lt;a href="https://www.buzzsprout.com/1121972/episodes/16124495-ep-327-would-kant-use-tiktok"&gt;https://www.buzzsprout.com/1121972/episodes/16124495-ep-327-would-kant-use-tiktok&lt;/a&gt;&lt;/p&gt;
]]&gt;</description>
      <link>https://www.lqdev.me/responses/digital-minimalism-moral-duty-deep-questions</link>
      <guid>https://www.lqdev.me/responses/digital-minimalism-moral-duty-deep-questions</guid>
      <pubDate>2024-11-19 09:56 -05:00</pubDate>
      <category>digitalminimalism</category>
      <category>postcast</category>
      <category>deepquestions</category>
      <category>philosophy</category>
      <category>calnewport</category>
    </item>
    <item>
      <title>Deep Questions - Debunking AI Model Capabilities / Distributed Webs of Trust</title>
      <description>&lt;![CDATA[[reply] &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=OvlfCW3Ec1g" title="Deep Questions Podcast Debunking AI Episode Thumbnail"&gt;&lt;img src="http://img.youtube.com/vi/OvlfCW3Ec1g/0.jpg" class="img-fluid" alt="Deep Questions Podcast Debunking AI Episode Thumbnail" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Nice job by Cal debunking misconceptions about AI model capabilities. The segment highlights a few points I cover in my unpublished &lt;a href="https://github.com/lqdev/luisquintanilla.me/blob/main/_scratch/nolm-not-only-language-models.md"&gt;NoLM - Not Only Language Models&lt;/a&gt; blog post. Specifically the fact that Language Models on their own can't do much and need to be connected to data sources and other systems. Complex AI systems will be built with more specialized roles and leverage various components for their planning and execution. In the end though, models will require integration into existing systems. Those integrations need to be done by people, meaning humans are still in control of the AI-assisted system capabilities.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=OvlfCW3Ec1g&amp;amp;t=4082" title="Deep Questions Podcast Debunking AI Episode Thumbnail"&gt;&lt;img src="http://img.youtube.com/vi/OvlfCW3Ec1g/0.jpg" class="img-fluid" alt="Same Deep Questions Podcast Debunking AI Episode Thumbnail" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Later in the podcast, Cal takes a question about distributed webs of trust. I agree with Cal's point of using existing open standards like RSS for content consumption. It's the reason you often hear the phrase, &amp;quot;or wherever you get your podcasts&amp;quot;. Assuming you have a program that can read an RSS feed, you can follow all types of content. On the topic of discovery, Cal makes the suggestion of using distributed webs of trust. Using domain names and linking as ways of discovering content. While blogrolls were not directly called out, it's one of the benefits a curated set of links provides.&lt;/p&gt;
]]&gt;</description>
      <link>https://www.lqdev.me/responses/deep-questions-debunking-genai-rss-blogroll</link>
      <guid>https://www.lqdev.me/responses/deep-questions-debunking-genai-rss-blogroll</guid>
      <pubDate>2024-06-24 20:40 -05:00</pubDate>
      <category>ai</category>
      <category>deepquestions</category>
      <category>rss</category>
      <category>calnewport</category>
      <category>podcast</category>
      <category>blogroll</category>
      <category>opml</category>
      <category>social</category>
      <category>socialmedia</category>
      <category>distributedweb</category>
    </item>
  </channel>
</rss>