<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>Luis Quintanilla - rwkv</title>
    <link>https://www.lqdev.me/tags/rwkv</link>
    <description>All content tagged with 'rwkv' by Luis Quintanilla</description>
    <lastBuildDate>2024-01-29 20:27 -05:00</lastBuildDate>
    <language>en</language>
    <item>
      <title>Eagle 7B : Soaring past Transformers with 1 Trillion Tokens Across 100+ Languages (RWKV-v5)</title>
      <description>&lt;![CDATA[[bookmark] &lt;blockquote class="blockquote"&gt;
&lt;p&gt;Eagle 7B is a 7.52B parameter model that:&lt;br /&gt;
&lt;br&gt;
Built on the &lt;a href="https://wiki.rwkv.com/"&gt;RWKV-v5 architecture&lt;/a&gt; (a linear transformer with 10-100x+ lower inference cost)&lt;br /&gt;
&lt;br&gt;
Ranks as the &lt;a href="https://blog.rwkv.com/p/the-worlds-greenest-ai-model-rwkvs"&gt;world’s greenest 7B model (per token)&lt;/a&gt;&lt;br /&gt;
&lt;br&gt;
Trained on 1.1 Trillion Tokens across 100+ languages&lt;br /&gt;
&lt;br&gt;
Outperforms all 7B class models in multi-lingual benchmarks&lt;br /&gt;
&lt;br&gt;
Approaches Falcon (1.5T), LLaMA2 (2T), Mistral (&amp;gt;2T?) level of performance in English evals&lt;br /&gt;
&lt;br&gt;
Trade blows with MPT-7B (1T) in English evals&lt;br /&gt;
&lt;br&gt;
&lt;a href="https://www.isattentionallyouneed.com/"&gt;All while being an “Attention-Free Transformer”&lt;/a&gt;&lt;br /&gt;
&lt;br&gt;
Is a foundation model, with a very small instruct tune - further fine-tuning is required for various use cases!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;We are releasing RWKV-v5 Eagle 7B, &lt;a href="https://blog.rwkv.com/p/rwkv-joins-the-linux-foundation-as"&gt;licensed as Apache 2.0 license, under the Linux Foundation&lt;/a&gt;, and can be used personally or commercially without restrictions&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href="https://huggingface.co/RWKV/v5-Eagle-7B/"&gt;Download from HuggingFace&lt;/a&gt;&lt;/p&gt;
]]&gt;</description>
      <link>https://www.lqdev.me/bookmarks/eagle-7b-rkwv</link>
      <guid>https://www.lqdev.me/bookmarks/eagle-7b-rkwv</guid>
      <pubDate>2024-01-29 20:27 -05:00</pubDate>
      <category>ai</category>
      <category>llm</category>
      <category>rwkv</category>
      <category>deeplearning</category>
      <category>neuralnetwork</category>
    </item>
  </channel>
</rss>