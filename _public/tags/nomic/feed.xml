<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>Luis Quintanilla - nomic</title>
    <link>https://www.lqdev.me/tags/nomic</link>
    <description>All content tagged with 'nomic' by Luis Quintanilla</description>
    <lastBuildDate>2025-02-24 20:47 -05:00</lastBuildDate>
    <language>en</language>
    <item>
      <title>Nomic Embed Text V2: An Open Source, Multilingual, Mixture-of-Experts Embedding Model</title>
      <description>&lt;![CDATA[[reshare] &lt;blockquote class="blockquote"&gt;
&lt;p&gt;Today we're excited to announce Nomic Embed Text V2, our next-generation embedding model that brings the Mixture of Experts (MoE) architecture to text embeddings on a new expanded multilingual training dataset.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Personally, I found the part on MoE to be the most interesting about this release.&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;Rather than a dense model which uses all parameters on an input, the MoE architecture dynamically routes to different &amp;quot;experts&amp;quot; - sparse subsets of parameters at each layer - activating, ideally, only the parameters especially needed to process the input. This approach allows for more efficient use of compute when generating embeddings.&lt;br /&gt;
&lt;br&gt;
In our experiments, we found that alternating MoE layers with 8 experts and top-2 routing provides the optimal balance between performance and efficiency. This results in 475M total parameters in the model, but only 305M active during training and inference.&lt;br /&gt;
&lt;br&gt;
Research into embedding model architecture has significant practical implications for working with text embeddings in production:&lt;br /&gt;
&lt;br&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lower latency for high-volume applications of embeddings like retrieval&lt;br /&gt;
&lt;br&gt;&lt;/li&gt;
&lt;li&gt;Reduced deployment costs through more efficient parameter usage&lt;br /&gt;
&lt;br&gt;&lt;/li&gt;
&lt;li&gt;More accessibility to embeddings in settings with constrained compute&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
]]&gt;</description>
      <link>https://www.lqdev.me/responses/nomic-embed-text-v2</link>
      <guid>https://www.lqdev.me/responses/nomic-embed-text-v2</guid>
      <pubDate>2025-02-24 20:47 -05:00</pubDate>
      <category>nomic</category>
      <category>ai</category>
      <category>embeddings</category>
    </item>
  </channel>
</rss>