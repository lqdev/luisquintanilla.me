<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>Luis Quintanilla - neuralnetwork</title>
    <link>https://www.lqdev.me/tags/neuralnetwork</link>
    <description>All content tagged with 'neuralnetwork' by Luis Quintanilla</description>
    <lastBuildDate>2024-08-14 21:51 -05:00</lastBuildDate>
    <language>en</language>
    <item>
      <title>Transformer Explainer: Interactive Learning of Text-Generative Models</title>
      <description>&lt;![CDATA[[bookmark] &lt;blockquote class="blockquote"&gt;
&lt;p&gt;Transformers have revolutionized machine learning, yet their inner workings remain opaque to many. We present Transformer Explainer, an interactive visualization tool designed for non-experts to learn about Transformers through the GPT-2 model. Our tool helps users understand complex Transformer concepts by integrating a model overview and enabling smooth transitions across abstraction levels of mathematical operations and model structures. It runs a live GPT-2 instance locally in the user's browser, empowering users to experiment with their own input and observe in real-time how the internal components and parameters of the Transformer work together to predict the next tokens. Our tool requires no installation or special hardware, broadening the public's education access to modern generative AI techniques. Our open-sourced tool is available at this https URL. A video demo is available at this https URL.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://poloclub.github.io/transformer-explainer/"&gt;Tool&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://youtu.be/ECR4oAwocjs"&gt;Video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
]]&gt;</description>
      <link>https://www.lqdev.me/bookmarks/transformer-explainer-interactive-learning-text-generative-models</link>
      <guid>https://www.lqdev.me/bookmarks/transformer-explainer-interactive-learning-text-generative-models</guid>
      <pubDate>2024-08-14 21:51 -05:00</pubDate>
      <category>ai</category>
      <category>transformer</category>
      <category>neuralnetwork</category>
      <category>learning</category>
      <category>gpt</category>
    </item>
    <item>
      <title>RecurrentGemma - Open weights language model from Google DeepMind, based on Griffin.</title>
      <description>&lt;![CDATA[[reshare] &lt;blockquote class="blockquote"&gt;
&lt;p&gt;RecurrentGemma is a family of open-weights Language Models by Google DeepMind, based on the novel Griffin architecture. This architecture achieves fast inference when generating long sequences by replacing global attention with a mixture of local attention and linear recurrences.&lt;br /&gt;
&lt;br&gt;
This repository contains the model implementation and examples for sampling and fine-tuning. We recommend most users adopt the Flax implementation, which is highly optimized. We also provide an un-optimized PyTorch implementation for reference.&lt;/p&gt;
&lt;/blockquote&gt;
]]&gt;</description>
      <link>https://www.lqdev.me/responses/google-deepmind-recurrent-gemma</link>
      <guid>https://www.lqdev.me/responses/google-deepmind-recurrent-gemma</guid>
      <pubDate>2024-04-10 21:57 -05:00</pubDate>
      <category>ai</category>
      <category>gemma</category>
      <category>google</category>
      <category>llm</category>
      <category>opensource</category>
      <category>slm</category>
      <category>griffin</category>
      <category>neuralnetwork</category>
    </item>
    <item>
      <title>Eagle 7B : Soaring past Transformers with 1 Trillion Tokens Across 100+ Languages (RWKV-v5)</title>
      <description>&lt;![CDATA[[bookmark] &lt;blockquote class="blockquote"&gt;
&lt;p&gt;Eagle 7B is a 7.52B parameter model that:&lt;br /&gt;
&lt;br&gt;
Built on the &lt;a href="https://wiki.rwkv.com/"&gt;RWKV-v5 architecture&lt;/a&gt; (a linear transformer with 10-100x+ lower inference cost)&lt;br /&gt;
&lt;br&gt;
Ranks as the &lt;a href="https://blog.rwkv.com/p/the-worlds-greenest-ai-model-rwkvs"&gt;world’s greenest 7B model (per token)&lt;/a&gt;&lt;br /&gt;
&lt;br&gt;
Trained on 1.1 Trillion Tokens across 100+ languages&lt;br /&gt;
&lt;br&gt;
Outperforms all 7B class models in multi-lingual benchmarks&lt;br /&gt;
&lt;br&gt;
Approaches Falcon (1.5T), LLaMA2 (2T), Mistral (&amp;gt;2T?) level of performance in English evals&lt;br /&gt;
&lt;br&gt;
Trade blows with MPT-7B (1T) in English evals&lt;br /&gt;
&lt;br&gt;
&lt;a href="https://www.isattentionallyouneed.com/"&gt;All while being an “Attention-Free Transformer”&lt;/a&gt;&lt;br /&gt;
&lt;br&gt;
Is a foundation model, with a very small instruct tune - further fine-tuning is required for various use cases!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;We are releasing RWKV-v5 Eagle 7B, &lt;a href="https://blog.rwkv.com/p/rwkv-joins-the-linux-foundation-as"&gt;licensed as Apache 2.0 license, under the Linux Foundation&lt;/a&gt;, and can be used personally or commercially without restrictions&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href="https://huggingface.co/RWKV/v5-Eagle-7B/"&gt;Download from HuggingFace&lt;/a&gt;&lt;/p&gt;
]]&gt;</description>
      <link>https://www.lqdev.me/bookmarks/eagle-7b-rkwv</link>
      <guid>https://www.lqdev.me/bookmarks/eagle-7b-rkwv</guid>
      <pubDate>2024-01-29 20:27 -05:00</pubDate>
      <category>ai</category>
      <category>llm</category>
      <category>rwkv</category>
      <category>deeplearning</category>
      <category>neuralnetwork</category>
    </item>
    <item>
      <title>Web Neural Network API - Working Draft</title>
      <description>&lt;![CDATA[&lt;p&gt;While browsing the interwebs I came across the &lt;a href="https://www.w3.org/TR/webnn/"&gt;Web Neural Network API&lt;/a&gt; spec from the &lt;a href="https://www.w3.org/groups/wg/webmachinelearning"&gt;W3C Web Machine Learning Working Group&lt;/a&gt;. The abstract defines it as &amp;quot;a dedicated low-level API for neural network inference hardware acceleration.&amp;quot;. Although there are already a few frameworks like ONNX &amp;amp; TensorFlow.js that allow you to inference in the browser, this spec looks interesting because it provides an abstraction that allows you to take advantage of hardware acceleration using the framework of your choice. As the &lt;a href="https://github.com/webmachinelearning/webnn/blob/main/explainer.md"&gt;explainer document&lt;/a&gt; mentions, &amp;quot;this architecture allows JavaScript frameworks to tap into cutting-edge machine learning innovations in the operating system and the hardware platform underneath it without being tied to platform-specific capabilities, bridging the gap between software and hardware through a hardware-agnostic abstraction layer.&amp;quot;. It's just a working draft for now but I'm looking forward to how this develops.&lt;/p&gt;
]]&gt;</description>
      <link>https://www.lqdev.me/notes/web-neural-network-api-working-draft</link>
      <guid>https://www.lqdev.me/notes/web-neural-network-api-working-draft</guid>
      <pubDate>10/24/2021 20:36 -05:00</pubDate>
      <category>webnn</category>
      <category>ai</category>
      <category>neuralnetwork</category>
      <category>w3c</category>
      <category>standards</category>
      <category>api</category>
      <category>protocol</category>
    </item>
  </channel>
</rss>