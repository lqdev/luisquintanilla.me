<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>Luis Quintanilla - standards</title>
    <link>https://www.lqdev.me/tags/standards</link>
    <description>All content tagged with 'standards' by Luis Quintanilla</description>
    <lastBuildDate>2025-05-06 20:40 -05:00</lastBuildDate>
    <language>en</language>
    <item>
      <title>Vibe-Specing - From concepts to specification</title>
      <description>&lt;![CDATA[
## Introduction

Code generation is a common use case for AI. What about the design process that comes before implementation? Personally, I've found that AI excels not just at coding, but also helping formalize abstract ideas into concrete specifications. This post explores how I used AI-assisted design to transform a collection of loosely related concepts into a technical specification for a new system made up of those concepts.

## Specifications

Generally, I've had mixed success with vibe-coding (the practice of describing what you want in natural language and having AI generate the corresponding code). However, it's something that I'm constantly working on getting better at. Also, with tooling integrations like MCP, I can ground responses and supplement my prompts using external data.

What I find myself being more successful with is using AI to explore ideas and then formalizing those ideas into a specification. Even in the case of vibe-coding, what you're doing with your prompts is building a specification in real-time. 

I'd like to think that eventually I'll get to the vibe-coding part but before diving straight into the code, I'd like to spend time in the design phase. Personally, this is also the part that I find the most fun because you can throw wild things at the wall. It's not until you implement them that you actually validate whether some of those wild ideas are practical. But I find the design phase a ton of fun.

The result of my latest vibe-specing adventure is what I'm calling the [InterPlanetary Knowledge System (IPKS)](https://github.com/lqdev/IPKS).

## From concept to specification

Lately, I've been thinking a lot about knowledge. Some concepts that have been in my head are those of **non-linear publishing** (creating content that can be accessed in any order with multiple entry points, like wikis or hypertext) and **distributed cognition** (the idea that human knowledge and cognitive processes extend beyond the individual mind to include interactions with other people, tools, and environments).
Related to those concepts, I've also been thinking about how **digital gardens** (personal knowledge bases that blend note-taking, blogging, and knowledge management in a non-linear format) and **Zettelkasten** (a method of note-taking where ideas are captured as atomic notes with unique identifiers and explicit connections) are ways to capture and organize knowledge.

One other thing that I'm amazed by is the powerful concept of a **hyperlink** and how it makes the web open, decentralized, and interoperable. When paired with the **semantic web** (an extension of the web that provides a common framework for data to be shared across applications and enterprises), you have yourself a decentralized knowledgebase containing a lot of the world's knowledge.

At some point, IPFS (InterPlanetary File System, a protocol designed to create a permanent and decentralized method of storing and sharing files) joined this pool of concepts I had in my head.

These were all interesting concepts individually, but I knew there were connections but couldn't cohesively bring them together. That's where AI-assisted specification design came in.

Below is a summary of the collaborative design interaction with Claude Sonnet 3.7 (with web search) that eventually led to the generation of the IPKS specifications. I haven't combed through them in great detail, but what they're proposing seems plausible. 

Overall, I'm fascinated by this interaction. Whether or not IPKS ever becomes a reality, the process of using AI to transform abstract concepts into concrete specifications seems like a valuable and fun design approach that I'll continue to refine and include as part of my vibe-coding sessions. 

---

## Initial Exploration: IPFS and Knowledge Management

Our conversation began with exploring IPFS (InterPlanetary File System) and its fundamental capabilities as a content-addressed, distributed file system. We recognized that while IPFS excels at storing and retrieving files in a decentralized manner, it needed extensions to support knowledge representation, trust, and semantics.

Key insights from this stage:
- IPFS provides an excellent foundation with content addressing through CIDs
- Content addressing enables verification but doesn't inherently provide meaning
- Moving from document-centric to idea-centric systems requires additional layers

## Knowledge Management Concepts

We explored established knowledge management approaches, particularly:

### Zettelkasten
The Zettelkasten method contributed these important principles:
- Atomic units of knowledge (one idea per note)
- Explicit connections between ideas
- Unique identifiers for each knowledge unit
- Emergent structure through relationship networks

### Digital Gardens
The Digital Garden concept provided these insights:
- Knowledge in various stages of development
- Non-linear organization prioritizing connections
- Evolution of ideas over time
- Public visibility of work-in-progress thinking

These personal knowledge management approaches helped us envision how similar principles could work at scale in a distributed system.

## The "K" in IPKS

When we proposed replacing "IPFS" with "IPKS" (changing File â†’ Knowledge), we recognized the need to define what makes knowledge different from files. This led to identifying several key requirements:

1. **Semantic meaning** - Knowledge needs explicit relationships and context
2. **Provenance and trust** - Knowledge requires verifiable sources and expertise
3. **Evolution** - Knowledge changes over time while maintaining continuity
4. **Governance** - Knowledge exists in various trust and privacy contexts

These requirements shaped the layered architecture of the specifications.

## Distributed Cognition and Non-Linear Publishing

Our discussions about distributed cognition highlighted how thinking processes extend beyond individual minds to include:
- Interactions with other people
- Cultural artifacts and tools
- Physical and digital environments
- Social and technological systems

This concept directly influenced the IPKS design by emphasizing:
- Knowledge as a collective, distributed resource
- The need for attribution and expertise verification
- The value of connecting knowledge across boundaries
- The role of tools in extending human cognition

Similarly, non-linear publishing concepts shaped how we approached knowledge relationships and navigation in IPKS, moving away from sequential formats toward interconnected networks of information.

## Web3 Technologies Integration

Our exploration of complementary technologies led to incorporating:

### Decentralized Identifiers (DIDs)
DIDs provided the framework for:
- Self-sovereign identity for knowledge contributors
- Cryptographic verification of authorship
- Persistent identification across systems
- Privacy-preserving selective disclosure

### Verifiable Credentials (VCs)
Verifiable Credentials offered mechanisms for:
- Expertise validation without central authorities
- Domain-specific qualification verification
- Credential-based access control
- Trust frameworks for knowledge contributors

### Semantic Web (RDF/OWL)
Semantic Web standards influenced:
- Relationship types between knowledge nodes
- Ontologies for domain knowledge representation
- Query patterns for knowledge discovery
- Interoperability with existing knowledge systems

## Business Context: Supply Chain Example

Our conversation about supply chain management provided a concrete use case that helped ground the specifications in practical application. This example demonstrated how IPKS could address real-world challenges:

- **Material Provenance**: Using DIDs and verifiable credentials to establish trusted material sources
- **Cross-Organization Collaboration**: Enabling knowledge sharing while respecting organizational boundaries
- **Regulatory Compliance**: Creating verifiable documentation of compliance requirements
- **Expertise Validation**: Ensuring contributors have appropriate qualifications for their roles
- **Selective Disclosure**: Balancing transparency with competitive confidentiality

This business context helped shape the Access Control &amp; Privacy specification in particular, highlighting the need for nuanced governance models.

## Technical Implementation Considerations

As we moved from abstract concepts to specifications, several technical considerations emerged:

1. **Building on IPLD**: Recognizing that InterPlanetary Linked Data (IPLD) already provided foundational components for structured, linked data in content-addressed systems

2. **Modular Specification Design**: Choosing to create multiple specifications rather than a monolithic standard to enable incremental implementation and adoption

3. **Backward Compatibility**: Ensuring IPKS could work with existing IPFS/IPLD infrastructure

4. **Extensibility**: Designing for future enhancements like AI integration, advanced semantic capabilities, and cross-domain knowledge mapping

## The Path Forward

The IPKS specifications represent a synthesis of our conceptual exploration, grounded in:
- Established knowledge management practices
- Decentralized web technologies
- Real-world business requirements
- Technical feasibility considerations

Moving from concept to implementation will require:
1. Reference implementations of the core specifications
2. Developer tools and libraries to simplify adoption
3. Domain-specific extensions for particular use cases
4. Community building around open standards

By building on the combined strengths of IPFS, DIDs, VCs, and semantic web technologies, IPKS creates a framework for distributed knowledge that balances openness with trust, flexibility with verification, and collaboration with governance.
]]&gt;</description>
      <link>https://www.lqdev.me/posts/vibe-specing-prompt-to-spec</link>
      <guid>https://www.lqdev.me/posts/vibe-specing-prompt-to-spec</guid>
      <pubDate>2025-05-06 20:40 -05:00</pubDate>
      <category>dweb</category>
      <category>standards</category>
      <category>ai</category>
      <category>decentralization</category>
      <category>protocol</category>
    </item>
    <item>
      <title>OPML for website feeds</title>
      <description>&lt;![CDATA[&lt;p&gt;While thiking about implementing &lt;a href="https://www.lqdev.me/responses/well-known-feeds/"&gt;&lt;code&gt;.well-known&lt;/code&gt; for RSS feeds on my site&lt;/a&gt;, I had another idea. Since that uses OPML anyways, I remembered recently &lt;a href="https://www.lqdev.me/notes/blogroll-discovery-implemented//"&gt;doing something similar for my blogroll&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The concept is the same, except instead of making my blogroll discoverable, I'm doing it for my feeds. At the end of the day, a blogroll is a collection of feeds, so it should just work for my own feeds.&lt;/p&gt;
&lt;p&gt;The implementation ended up being:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Create an OPML file for&lt;a href="https://www.lqdev.me/feed"&gt; each of the feeds on by website&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-xml"&gt; &amp;lt;opml version=&amp;quot;2.0&amp;quot;&amp;gt;
   &amp;lt;head&amp;gt;
 	&amp;lt;title&amp;gt;Luis Quintanilla Feeds&amp;lt;/title&amp;gt;
 	&amp;lt;ownerId&amp;gt;https://www.luisquintanilla.me&amp;lt;/ownerId&amp;gt;
   &amp;lt;/head&amp;gt;
   &amp;lt;body&amp;gt;
 	&amp;lt;outline title=&amp;quot;Blog&amp;quot; text=&amp;quot;Blog&amp;quot; type=&amp;quot;rss&amp;quot; htmlUrl=&amp;quot;/posts/1&amp;quot; xmlUrl=&amp;quot;/blog.rss&amp;quot; /&amp;gt;
 	&amp;lt;outline title=&amp;quot;Microblog&amp;quot; text=&amp;quot;Microblog&amp;quot; type=&amp;quot;rss&amp;quot; htmlUrl=&amp;quot;/feed&amp;quot; xmlUrl=&amp;quot;/microblog.rss&amp;quot; /&amp;gt;
 	&amp;lt;outline title=&amp;quot;Responses&amp;quot; text=&amp;quot;Responses&amp;quot; type=&amp;quot;rss&amp;quot; htmlUrl=&amp;quot;/feed/responses&amp;quot; xmlUrl=&amp;quot;/responses.rss&amp;quot; /&amp;gt;
 	&amp;lt;outline title=&amp;quot;Mastodon&amp;quot; text=&amp;quot;Mastodon&amp;quot; type=&amp;quot;rss&amp;quot; htmlUrl=&amp;quot;/mastodon&amp;quot; xmlUrl=&amp;quot;/mastodon.rss&amp;quot; /&amp;gt;
 	&amp;lt;outline title=&amp;quot;Bluesky&amp;quot; text=&amp;quot;Bluesky&amp;quot; type=&amp;quot;rss&amp;quot; htmlUrl=&amp;quot;/bluesky&amp;quot; xmlUrl=&amp;quot;/bluesky.rss&amp;quot; /&amp;gt;
 	&amp;lt;outline title=&amp;quot;YouTube&amp;quot; text=&amp;quot;YouTube&amp;quot; type=&amp;quot;rss&amp;quot; htmlUrl=&amp;quot;/youtube&amp;quot; xmlUrl=&amp;quot;/bluesky.rss&amp;quot; /&amp;gt;
   &amp;lt;/body&amp;gt;
 &amp;lt;/opml&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Add a &lt;code&gt;link&lt;/code&gt; tag to the &lt;code&gt;head&lt;/code&gt; element of my website.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-html"&gt; &amp;lt;link rel=&amp;quot;feeds&amp;quot; type=&amp;quot;text/xml&amp;quot; title=&amp;quot;Luis Quintanilla's Feeds&amp;quot; href=&amp;quot;/feed/index.opml&amp;quot;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
]]&gt;</description>
      <link>https://www.lqdev.me/notes/website-feeds-opml</link>
      <guid>https://www.lqdev.me/notes/website-feeds-opml</guid>
      <pubDate>2024-08-01 20:08 -05:00</pubDate>
      <category>rss</category>
      <category>opml</category>
      <category>indieweb</category>
      <category>feeds</category>
      <category>internet</category>
      <category>protocols</category>
      <category>webstandards</category>
      <category>standards</category>
      <category>web</category>
    </item>
    <item>
      <title>.well-known feeds</title>
      <description>&lt;![CDATA[[reply] &lt;p&gt;This is a clever use of &lt;em&gt;.well-known&lt;/em&gt; and OPML.&lt;/p&gt;
&lt;p&gt;Definitely something I want to experiment with and implement on my site even if it's not widely adopted.&lt;/p&gt;
]]&gt;</description>
      <link>https://www.lqdev.me/responses/well-known-feeds</link>
      <guid>https://www.lqdev.me/responses/well-known-feeds</guid>
      <pubDate>2024-07-31 09:01 -05:00</pubDate>
      <category>standards</category>
      <category>feeds</category>
      <category>rss</category>
      <category>web</category>
      <category>indieweb</category>
      <category>smallweb</category>
    </item>
    <item>
      <title>Web Neural Network API - Working Draft</title>
      <description>&lt;![CDATA[&lt;p&gt;While browsing the interwebs I came across the &lt;a href="https://www.w3.org/TR/webnn/"&gt;Web Neural Network API&lt;/a&gt; spec from the &lt;a href="https://www.w3.org/groups/wg/webmachinelearning"&gt;W3C Web Machine Learning Working Group&lt;/a&gt;. The abstract defines it as &amp;quot;a dedicated low-level API for neural network inference hardware acceleration.&amp;quot;. Although there are already a few frameworks like ONNX &amp;amp; TensorFlow.js that allow you to inference in the browser, this spec looks interesting because it provides an abstraction that allows you to take advantage of hardware acceleration using the framework of your choice. As the &lt;a href="https://github.com/webmachinelearning/webnn/blob/main/explainer.md"&gt;explainer document&lt;/a&gt; mentions, &amp;quot;this architecture allows JavaScript frameworks to tap into cutting-edge machine learning innovations in the operating system and the hardware platform underneath it without being tied to platform-specific capabilities, bridging the gap between software and hardware through a hardware-agnostic abstraction layer.&amp;quot;. It's just a working draft for now but I'm looking forward to how this develops.&lt;/p&gt;
]]&gt;</description>
      <link>https://www.lqdev.me/notes/web-neural-network-api-working-draft</link>
      <guid>https://www.lqdev.me/notes/web-neural-network-api-working-draft</guid>
      <pubDate>10/24/2021 20:36 -05:00</pubDate>
      <category>webnn</category>
      <category>ai</category>
      <category>neuralnetwork</category>
      <category>w3c</category>
      <category>standards</category>
      <category>api</category>
      <category>protocol</category>
    </item>
    <item>
      <title>TIL: Canonical HTML tags</title>
      <description>&lt;![CDATA[&lt;p&gt;Today I learned about canonical URLs. While looking into how I can syndicate content from this site, specifically longer form blog posts on other sites like dev.to, I came across canonical tags.&lt;/p&gt;
&lt;p&gt;Basically they're a way of telling the internet, specifically search engines, what version of your content is the main copy or single-source of truth.&lt;/p&gt;
&lt;p&gt;Currently I've configured my site so it's not indexed or crawled. However, for sites I don't own I don't have the same level of control. Check out the &lt;a href="https://moz.com/learn/seo/canonicalization"&gt;canonicalization&lt;/a&gt; and &lt;a href="https://moz.com/blog/rel-canonical"&gt;SEO best practices for canonical URLs&lt;/a&gt; articles from Moz if you're interested in learning more.&lt;/p&gt;
]]&gt;</description>
      <link>https://www.lqdev.me/notes/rel-canonical-tags</link>
      <guid>https://www.lqdev.me/notes/rel-canonical-tags</guid>
      <pubDate>10/21/2021 21:31 -05:00</pubDate>
      <category>html</category>
      <category>til</category>
      <category>canonical</category>
      <category>web</category>
      <category>w3c</category>
      <category>standards</category>
    </item>
  </channel>
</rss>