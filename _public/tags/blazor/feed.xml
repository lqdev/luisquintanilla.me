<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>Luis Quintanilla - blazor</title>
    <link>https://www.lqdev.me/tags/blazor</link>
    <description>All content tagged with 'blazor' by Luis Quintanilla</description>
    <lastBuildDate>2024-10-20 14:01 -05:00</lastBuildDate>
    <language>en</language>
    <item>
      <title>Build your own self-hosted live streaming application with Owncast and .NET Aspire</title>
      <description>&lt;![CDATA[
Platforms come and go. As a result, I'm a strong advocate for [owning your data](https://indieweb.org/own_your_data) (when possible). Self-hosting is a way for you to do that. Owning your data could mean self-hosting [your website](https://buttondown.com/ownyourweb/archive/issue-06/), [password manager](https://bitwarden.com/blog/host-your-own-open-source-password-manager/), [media server](https://jellyfin.org/docs/), or [social media](https://docs.joinmastodon.org/user/run-your-own/). However, self-hosting comes with its own challenges, primarily cost (time and money) and in cases where software isn't provided as an appliance on your hosting provider of choice, some technical knowledge may be required. 

As I got more into self-hosting applications such as my [Mastodon instance](/mastodon), I came across Owncast.   

During peak COVID lockdowns, like many others, live streaming is one of the ways I passed the time. While Twitch and YouTube got the job done, self-hosting was always in the back of my mind.  

It's been a while since I've live-streamed, so I never really went through the process of evaluating the self-hosted route with Owncast. 

While browsing for something on YouTube the other day, I ran into some of my [old live-stream recordings](https://www.youtube.com/playlist?list=PLsdMoYmuvh9ZtgB8U7FECR_8wKMYXJNAm). This got me thinking again, how difficult would it be to put together my own live-streaming setup. 

This post is the result of that exploration. 

In this post, I'll modify a .NET Aspire Starter Application template and show how to set up a self-hosted live-streaming application using Owncast and .NET Aspire.  

You can find the source code in the [lqdev/BYOwncastAspire](/github/BYOwncastAspire) repository.

![BYOwnCastAspire Web Frontend](https://github.com/user-attachments/assets/bdd9f901-8d8f-45be-9e37-4dce8459e481)

## What is Owncast?

The Owncast website describes the project as, "...a free and open source live video and web chat server for use with existing popular broadcasting software."

![Owncast admin server page](https://github.com/user-attachments/assets/769ec2d8-a3d1-4ec3-8271-c2de6e11ddd3)

It goes on to further describe some of the reasons I like Owncast, which are:

- **Self-hosting** - I'm in complete control over the service and my data
- **Open-source** - I can freely use and contribute to the project. Free in this case meaning both as in freedom and pizza.
- **Builds on top of open standards like RMTP** - Software that supports the Real-Time Messaging Protocol (RMTP) like OBS can immediately be leveraged. 
- **Fediverse compatible** - Your content and network federated across [the Fediverse](https://joinfediverse.wiki/What_is_the_Fediverse%3F). 

To learn more, check out the [Owncast website](https://owncast.online/). 

## What is .NET Aspire?

The .NET Aspire documentation describes it as, "...an opinionated, cloud ready stack for building observable, production ready, distributed applications.â€‹ .NET Aspire is delivered through a collection of NuGet packages that handle specific cloud-native concerns."

Personally, the parts of .NET Aspire that matter to me are:

- **App composition** - The .NET Aspire programming model makes it easy to define and compose a variety of resources such as .NET projects, containers, and much more in a single place. In many cases, for commonly used services, these resources are exposed in the form of [integrations](https://learn.microsoft.com/dotnet/aspire/fundamentals/integrations-overview). These integrations further simplify the composition of applications.  
- **Tooling (Dashboard)** - .NET Aspire provides a set of tools and templates. However, my favorite is the dashboard. The dashboard provides me with a single place to view my resources, their configurations, and logs. 

Although in this post, I don't cover deployment, there is also the provisioning component provided by .NET Aspire which in many cases can [simplify your application deployments](https://learn.microsoft.com/dotnet/aspire/deployment/overview). 

To learn more, check out the [.NET Aspire documentation](https://learn.microsoft.com/dotnet/aspire/get-started/aspire-overview). 

## Build your application

This application makes a few modifications to the [.NET Aspire Starter Application template](https://learn.microsoft.com/dotnet/aspire/fundamentals/setup-tooling?tabs=linux&amp;pivots=dotnet-cli#net-aspire-project-templates). 

The application consists of a few projects:

- **BYOwncastAspire.AppHost** - This project is the entrypoint for .NET Aspire applications. This is where we'll configure the Owncast server as a container resource. 
- **BYOwncastAspire.Web** - Blazor web application. Although Owncast provides its own page where viewers can tune into your stream, by having a separate web application, preferably your own personal website, you can further enrich and customize how and where you publish content. 
- **BYOwncastAspire.ServiceDefaults** - This project contains default configurations for telemetry, health checks, resiliency, etc. No changes or updates required here. 

### Configure Owncast

There are many ways to host an Owncast server, with one of them being a container. 

In the context of Aspire which has built-in container support, you can easily add Owncast as a resource in your application. 

From the [Owncast documentation](https://owncast.online/quickstart/container/), once you've pulled the Owncast container image, you can start it with the following command.

```bash
docker run -v `pwd`/data:/app/data -p 8080:8080 -p 1935:1935 owncast/owncast:latest
```

This translates to the following in the *Program.cs* of the *BYOwncastAspire.AppHost* project.

```csharp
var owncast = builder
    .AddContainer(name: "owncast", image:"owncast/owncast")
    .WithBindMount("./data","/app/data")
    .WithHttpEndpoint(port:8080,targetPort:8080,name:"admin")
    .WithHttpEndpoint(port:1935,targetPort:1935,name:"streaming")
    .WithExternalHttpEndpoints();
```

This code:

- Adds the owncast container image
- Mounts a local *data* directory to the */app/data* directory in the container
- Maps port `8080` for the Owncast admin server and `1935` for RMTP server.
- Exposes the endpoints publicly

### Embed your stream

Owncast provides the ability to [embed your video stream onto a website](https://owncast.online/docs/embed/). 

Although we don't need a frontend because one is already provided by Owncast, by embedding your stream on your website you can provide a single place for your viewers to consume your content. 

In this case, we can treat the *BYOwncastAspire.Web* project as our website. 

To embed your stream to the website, add the following code to your *Home.razor* page.

```csharp
&lt;iframe
  src="http://localhost:8080/embed/video"
  title="Owncast"
  height="350px" width="550px"
  referrerpolicy="origin"
  allowfullscreen&gt;
&lt;/iframe&gt;
```

In this case, we're pointing to the endpoint listening on port `8080` of our `localhost`. When you deploy the application, you'd replace `src` with your domain. 

## Start your application

That's all there is in terms of configuration. 

To start the application:

1. Open the terminal 
2. Navigate to the *BYOwncastAspire.AppHost* project and run the following command.

    ```bash
    dotnet run
    ```

This will launch you into the .NET Aspire dashboard. At this point, you can further customize your Owncast server as well as the website.  

![BYOwncastAspire .NET Aspire Dashboard Resource Page](https://github.com/user-attachments/assets/c20d84d8-925a-4f80-9058-622466cb08e9)

## What next?

Now that you have your application running, in its current form, this application is only meant to serve as a sample of what you can do with Owncast and .NET Aspire. 

Some next steps might include:

- [Change your admin password and customize your Owncast server](https://owncast.online/docs/configuration/)
- [Configure object storage](https://owncast.online/docs/storage/)
- [Set up your steaming software](https://owncast.online/docs/broadcasting/obs/)
- [Deploy your application](https://learn.microsoft.com/dotnet/aspire/deployment/azure/aca-deployment)
- [Extend the app's functionality by building custom plugins and extensions](https://owncast.online/thirdparty/)

The plugins and extensions are particularly interesting to me because there may even be opportunities to experiment and insert AI capabilities at various layers such as moderation, translation, accessibility, show notes, chat summaries, etc. 

## Conclusion

In this post, I showed how you can combine the powerful live-steaming features of Owncast with the app orchestration and tooling in .NET Aspire to create rich self-hosted live-steaming applications.

If you use this sample as a starting point for your own live-streaming or self-hosting explorations, [send me a message](/contact). I'd love to hear about it.  
]]&gt;</description>
      <link>https://www.lqdev.me/posts/build-your-own-live-streaming-app-owncast-dotnet-aspire</link>
      <guid>https://www.lqdev.me/posts/build-your-own-live-streaming-app-owncast-dotnet-aspire</guid>
      <pubDate>2024-10-20 14:01 -05:00</pubDate>
      <category>owncast</category>
      <category>dotnet</category>
      <category>indieweb</category>
      <category>fediverse</category>
      <category>aspire</category>
      <category>livestreaming</category>
      <category>twitch</category>
      <category>youtube</category>
      <category>blazor</category>
    </item>
    <item>
      <title>Deploy ML.NET Machine Learning Model in Blazor WebAssembly Static Website</title>
      <description>&lt;![CDATA[
## Introduction

There are many ways of deploying machine learning models. The most common way to do so is by exposing models as a web service through APIs or serverless functions. One of the considerations when deploying a model as a web service is latency and performance. The process of making predictions over HTTP using a model involves accepting the user input, loading the serialized version of the model from a file, using the model to make a prediction, and returning the prediction back to the user. Since models are typically just static files, another way of deploying a model is as a static asset over the web, just like any other HTML, CSS, or JavaScript file. This deployment method is similar to that of TensorFlow.js. Deploying in this way has several advantages. One advantage is that there is no longer a web service just to serve the model, making it more cost-efficient. Another advantage is that once the model has been downloaded onto the user's PC, the resources used at that point are those of the user's PC rather than the server the model would otherwise be hosted in. Finally, because the model is a static file, it can be distributed via CDNs. 

One of the challenges with this is that machine learning models are usually built using languages other than JavaScript. This makes using the same code / library the model was built difficult or nearly impossible. WebAssembly is changing that by allowing Rust, C++, C# and other languages to run natively inside the browser. Having that ability, the code / logic to load the model and make predictions is much easier and almost comparable to that of a native platform. Blazor WebAssembly provides users the ability to create modern component-based web applications completely in C#. Additionally, Blazor WebAssembly allows users to publish and deploy their applications as static websites in an easy and cost-efficient way. ML.NET is an open-source, cross-platform framework that allows developers to create machine learning models using .NET. In this post, I'll show how to train a multiclass classification machine learning model that predicts iris flower species. Then, I'll take that model and deploy it alongside a Blazor WebAssembly static website to Azure Storage. The full code for this application may be found at the [MLNETBlazorWASMSample repository on GitHub](https://github.com/lqdev/MLNETBlazorWASMSample).

## Prerequisites

This project was built on a Windows PC but should work cross platform on Mac and Linux.

- [.NET Core SDK 3.1](https://dotnet.microsoft.com/download/dotnet-core/3.1)
- [Blazor WebAssembly Template](https://www.nuget.org/packages/Microsoft.AspNetCore.Blazor.Templates/3.2.0-preview1.20073.1)
- [Azure Subscription](http://aka.ms/amlFree)
- [Azure Storage Explorer](https://azure.microsoft.com/en-us/features/storage-explorer/)

## Set up the solution

The solution built in this post contains three projects:

- SchemaLibrary: C# .NET Standard 2.0 class library that contains the schema definition classes of the data used to train the model as well as the prediction output generated by the model.
- TrainingConsole: C# .NET Core 3.1 console application used to train the machine learning model.
- BlazorWebApp: Blazor WebAssembly web application to make predictions using machine learning model trained by TrainingConsole application.

### Install Blazor WebAssembly Template

Use the .NET CLI to run the following command in the command prompt:

```powershell
dotnet new -i Microsoft.AspNetCore.Blazor.Templates::3.2.0-preview1.20073.1
```

### Create the solution

Create a new directory for the solution called *MLNETBlazorWASMSample*.

```powershell
mkdir MLNETBlazorWASMSample
```

Navigate to the newly created solution directory and create a solution:

```powershell
cd MLNETBlazorWASMSample
dotnet new sln
```

### Create schema class library

The data schema for the model input and output are shared during training as well as when making predictions. To share resources, create a class library that's shared by the `ConsoleTraining` and `BlazorWebApp` projects. In the solution directory, enter the following command:

```powershell
dotnet new classlib -o SchemaLibrary
```

Install the *Microsoft.ML* NuGet package (This solution is built with version 1.4.0). The *Microsoft.ML* package is used throughout the entire solution.

```powershell
dotnet add SchemaLibrary package Microsoft.ML
```

Add the library project to the solution.

```powershell
dotnet sln add SchemaLibrary
```

### Create the training console application

The console application contains the series of data transformations and algorithms used to train the model. In the solution directory, create a new console application.

```powershell
dotnet new console -o TrainingConsole
```

Add the console application to the solution.

```powershell
dotnet sln add TrainingConsole
```

Reference the *SchemaLibrary* project.

```powershell
dotnet add TrainingConsole reference SchemaLibrary
```

### Create the Blazor WebAssembly web application

The web application contains a few input elements so users can provide new data that the model then uses to make predictions. In the solution directory, create a new Blazor WebAssembly application.

```powershell
dotnet new blazorwasm -o BlazorWebApp
```

Add the web application project to the solution.

```powershell
dotnet sln add BlazorWebApp
```

Reference the *SchemaLibrary* project.

```powershell
dotnet add BlazorWebApp reference SchemaLibrary
```

## Define the schema

### Understand the data

The data used to train the model comes from the [iris dataset](https://archive.ics.uci.edu/ml/datasets/Iris). It contains four numerical columns which are sepal and petal measurements and one numerical column for the species of iris flower. This is a sample of the data.

|Sepal length (cm)  |Sepal width (cm)  |Petal length (cm)  |Petal width (cm)  |Class (iris species)  |
|---------|---------|---------|---------|---------|
|5.1|3.5|1.4|0.2|Iris-setosa|
|7.0|3.2|4.7|1.4|Iris-versicolor|
|6.3|3.3|6.0|2.5|Iris-virginica|

### Define model input schema

In the *SchemaLibrary* project, create a class called `ModelInput` to model the data used for training and as model input.

```powershell
ni ModelInput.cs
```

The `ModelInput` class should look like the following:

```csharp
using Microsoft.ML.Data;

namespace SchemaLibrary
{
    public class ModelInput
    {
        [LoadColumn(0)]
        public float SepalLength { get; set; }

        [LoadColumn(1)]
        public float SepalWidth { get; set; }

        [LoadColumn(2)]
        public float PetalLength { get; set; }

        [LoadColumn(3)]
        public float PetalWidth { get; set; }

        [LoadColumn(4)]
        public string Label { get; set; }
    }
}
```

Notice that the `Class` column is now a property called `Label`. This is for two reasons:

1. Avoid using the `class` keyword.
2. In ML.NET, the default column name of the column to predict expected by algorithms is `Label`.

Also notice the `LoadColumn` attributes at the top of each property. This is used to tell the loader the index of the column where the data for the respective property is.

### Define model output schema

Similar to the input schema, there's a schema for the output of the model. The type of model used in this solution is a multiclass classification model since there are more than two categories to choose from for iris flower species. Multiclass classification models output a column called `PredictedLabel` which contains the name of the predicted category. In the *SchemaLibrary* project, create a class called `ModelOutput` to model the predictions made by the model.

```powershell
ni ModelOutput.cs
```

The `ModelOutput` class should look like the following:

```csharp
namespace SchemaLibrary
{
    public class ModelOutput
    {
        public string PredictedLabel { get; set; }
    }
}
```

## Train the model

Now it's time to create the application that trains the model.

### Get the data

Download the data and save it inside the *TrainingConsole* project directory.

```powershell
curl https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data -o iris.data
```

### Define the data preparation and training steps

In the *TrainingConsole* project, open the *Program.cs* file and add the following using statements at the top:

```csharp
using System;
using System.Linq;
using Microsoft.ML;
using SchemaLibrary;
```

Then, delete the contents inside the `Main` method and replace it with the following.

```csharp
// 1. Initialize MLContext
MLContext mlContext = new MLContext();

// 2. Load the data
IDataView data = mlContext.Data.LoadFromTextFile&lt;ModelInput&gt;("iris.data", separatorChar:',');

// 3. Shuffle the data
IDataView shuffledData = mlContext.Data.ShuffleRows(data);

// 3. Define the data preparation and training pipeline.
IEstimator&lt;ITransformer&gt; pipeline = 
    mlContext.Transforms.Concatenate("Features","SepalLength","SepalWidth","PetalLength","PetalWidth")
        .Append(mlContext.Transforms.NormalizeMinMax("Features"))
        .Append(mlContext.Transforms.Conversion.MapValueToKey("Label"))
        .Append(mlContext.MulticlassClassification.Trainers.NaiveBayes())
        .Append(mlContext.Transforms.Conversion.MapKeyToValue("PredictedLabel"));

// 4. Train with cross-validation
var cvResults = mlContext.MulticlassClassification.CrossValidate(shuffledData, pipeline);

// 5. Get the highest performing model and its accuracy
(ITransformer, double) model = 
    cvResults
        .OrderByDescending(fold =&gt; fold.Metrics.MacroAccuracy)
        .Select(fold =&gt; (fold.Model, fold.Metrics.MacroAccuracy))
        .First();

Console.WriteLine($"Top performing model's macro-accuracy: {model.Item2}");

// 6. Save the model
mlContext.Model.Save(model.Item1, data.Schema, "model.zip");

Console.WriteLine("Model trained");
```

The training application loads the data from the `iris.data` file and applies a series of transformations. First, all of the individual numerical columns are combined into a single vector and stored in a new column called `Features`. The `Features` column is then normalized and the `MapValueToKey` transform is used to convert the text in the `Label` column to a number. Then, the transformed data is used to train a model using the `NaiveBayes` algorithm. **Note that at the time of this writing, for multiclass classification problems, only Naive Bayes has been confirmed to work with Blazor WebAssembly**. Finally, the `PredictedLabel` is stored as a number so it has to be converted back into text.

Using the `Fit` method, the data is applied to the pipeline. Because the dataset is small, a technique called cross-validation is used to build a more robust model. Once the model is trained, the model with the top performance is then serialized and saved to a file called *model.zip* for later use in the web application.

The final *Program.cs* file should look like the content below:

```csharp
using System;
using System.Linq;
using Microsoft.ML;
using SchemaLibrary;

namespace TrainingConsole
{
    class Program
    {
        static void Main(string[] args)
        {
            // 1. Initialize MLContext
            MLContext mlContext = new MLContext();

            // 2. Load the data
            IDataView data = mlContext.Data.LoadFromTextFile&lt;ModelInput&gt;("iris.data", separatorChar:',');

            // 3. Shuffle the data
            IDataView shuffledData = mlContext.Data.ShuffleRows(data);

            // 3. Define the data preparation and training pipeline.
            IEstimator&lt;ITransformer&gt; pipeline = 
                mlContext.Transforms.Concatenate("Features","SepalLength","SepalWidth","PetalLength","PetalWidth")
                    .Append(mlContext.Transforms.NormalizeMinMax("Features"))
                    .Append(mlContext.Transforms.Conversion.MapValueToKey("Label"))
                    .Append(mlContext.MulticlassClassification.Trainers.NaiveBayes())
                    .Append(mlContext.Transforms.Conversion.MapKeyToValue("PredictedLabel"));

            // 4. Train with cross-validation
            var cvResults = mlContext.MulticlassClassification.CrossValidate(shuffledData, pipeline);

            // 5. Get the highest performing model and its accuracy
            (ITransformer, double) model = 
                cvResults
                    .OrderByDescending(fold =&gt; fold.Metrics.MacroAccuracy)
                    .Select(fold =&gt; (fold.Model, fold.Metrics.MacroAccuracy))
                    .First();

            Console.WriteLine($"Top performing model's macro-accuracy: {model.Item2}");

            // 6. Save the model
            mlContext.Model.Save(model.Item1, data.Schema, "model.zip");

            Console.WriteLine("Model trained");
        }
    }
}
```

### Run the application

In the *TrainConsole* project directory, use the following command to run the application and train the model:

```powershell
dotnet run
```

## Host the model

Once you have the model saved, use the Azure Portal to create an Azure Storage account.

![Create Azure Storage Account](http://cdn.lqdev.tech/files/images/deploy-machine-learning-mlnet-model-blazor-webassembly1.png)

Then, navigate to your newly created storage account resource and create a blob container called `models`.

![Create Blob Container](http://cdn.lqdev.tech/files/images/deploy-machine-learning-mlnet-model-blazor-webassembly2.png)

Once your container is created, navigate to it and upload the *model.zip* file.

![Upload Model](http://cdn.lqdev.tech/files/images/deploy-machine-learning-mlnet-model-blazor-webassembly3.png)

## Create prediction web page

To make predictions, create a web page to take in user input. Then, provide the user input to the model and display the prediction to the user.

### Set up imports

In the *BlazorWebApp* project directory, open the *_Imports.razor* file. This contains the using statements for the pages and components in your application. Add the following using statements:

```razor
@using System.IO
@using Microsoft.ML
@using SchemaLibrary
```

### Create user input page

In the *BlazorWebApp* project, create a new razor page called *Prediction.razor* inside the *Pages* directory.

```powershell
ni Prediction.razor
```

Add the following content to it:

```razor
@page "/prediction"
@inject HttpClient _client

&lt;label&gt;Sepal Length: &lt;/label&gt;
&lt;input type="text" @bind="_sepalLength"&gt;&lt;br&gt;
&lt;label&gt;Sepal Width: &lt;/label&gt;
&lt;input type="text" @bind="_sepalWidth"&gt;&lt;br&gt;
&lt;label&gt;Petal Length: &lt;/label&gt;
&lt;input type="text" @bind="_petalLength"&gt;&lt;br&gt;
&lt;label&gt;Petal Width: &lt;/label&gt;
&lt;input type="text" @bind="_petalWidth"&gt;&lt;br&gt;
&lt;button @onclick="GetPrediction"&gt;Make prediction&lt;/button&gt;
@if(@ModelPrediction == null)
{
    &lt;p&gt;Enter data to get a prediction&lt;/p&gt;
} else
{
    &lt;p&gt;@ModelPrediction&lt;/p&gt;
}


@code {
    private PredictionEngine&lt;ModelInput,ModelOutput&gt; _predictionEngine;
    private string _sepalLength, _sepalWidth, _petalLength, _petalWidth, ModelPrediction;

    protected override async Task OnInitializedAsync()
    {
        Stream savedModel = await _client.GetStreamAsync("&lt;YOUR-MODEL-ENDPOINT&gt;");
        MLContext mlContext = new MLContext();
        ITransformer _model = mlContext.Model.Load(savedModel,out DataViewSchema schema);
        _predictionEngine = mlContext.Model.CreatePredictionEngine&lt;ModelInput,ModelOutput&gt;(_model);
    }

    private void GetPrediction()
    {
        ModelInput input = new ModelInput
        {
            SepalLength=float.Parse(_sepalLength),
            SepalWidth=float.Parse(_sepalWidth),
            PetalLength=float.Parse(_petalLength),
            PetalWidth=float.Parse(_petalWidth)
        };

        ModelOutput prediction = _predictionEngine.Predict(input);

        ModelPrediction = prediction.PredictedLabel;
    }
}
```

The *Predict.razor* page contains a text input element for each of the columns the model was original trained on. When the page is initialized, the model is loaded from Azure Storage and a `PredictionEngine` is created. **Make sure to replace `&lt;YOUR-MODEL-ENDPOINT&gt;` with the URL of the blob that contains your `model.zip`**. A `PredictionEngine` is a convenience API to make a single prediction. Traditionally when models are served as a web service, it is recommended to use the `PredictionEnginePool` service because it's thread-safe and more performant in multi-threaded application. However, in this case since the model is downloaded onto the individual user's browser, it's okay to use `PredictionEngine`. After a user enters input values and clicks the "Make Prediction" button, the `GetPrediction` method executes by taking the user input and making a prediction using the `PredictionEngine`. The prediction is then displayed in the browser.

### Add to navigation menu

In the *BlazorWebApp* project, open the *NavMenu.razor* file in the *Shared* directory.

Add the following list item to the `&lt;ul&gt;` element.

```html
&lt;li class="nav-item px-3"&gt;
    &lt;NavLink class="nav-link" href="prediction"&gt;
        &lt;span class="oi oi-list-rich" aria-hidden="true"&gt;&lt;/span&gt; Prediction
    &lt;/NavLink&gt;
&lt;/li&gt;
```

The final *NavMenu.razor* page should look like the following:

```razor
&lt;div class="top-row pl-4 navbar navbar-dark"&gt;
    &lt;a class="navbar-brand" href=""&gt;BlazorWebApp&lt;/a&gt;
    &lt;button class="navbar-toggler" @onclick="ToggleNavMenu"&gt;
        &lt;span class="navbar-toggler-icon"&gt;&lt;/span&gt;
    &lt;/button&gt;
&lt;/div&gt;

&lt;div class="@NavMenuCssClass" @onclick="ToggleNavMenu"&gt;
    &lt;ul class="nav flex-column"&gt;
        &lt;li class="nav-item px-3"&gt;
            &lt;NavLink class="nav-link" href="" Match="NavLinkMatch.All"&gt;
                &lt;span class="oi oi-home" aria-hidden="true"&gt;&lt;/span&gt; Home
            &lt;/NavLink&gt;
        &lt;/li&gt;
        &lt;li class="nav-item px-3"&gt;
            &lt;NavLink class="nav-link" href="counter"&gt;
                &lt;span class="oi oi-plus" aria-hidden="true"&gt;&lt;/span&gt; Counter
            &lt;/NavLink&gt;
        &lt;/li&gt;
        &lt;li class="nav-item px-3"&gt;
            &lt;NavLink class="nav-link" href="fetchdata"&gt;
                &lt;span class="oi oi-list-rich" aria-hidden="true"&gt;&lt;/span&gt; Fetch data
            &lt;/NavLink&gt;
        &lt;/li&gt;
        &lt;li class="nav-item px-3"&gt;
            &lt;NavLink class="nav-link" href="prediction"&gt;
                &lt;span class="oi oi-list-rich" aria-hidden="true"&gt;&lt;/span&gt; Prediction
            &lt;/NavLink&gt;
        &lt;/li&gt;
    &lt;/ul&gt;
&lt;/div&gt;

@code {
    private bool collapseNavMenu = true;

    private string NavMenuCssClass =&gt; collapseNavMenu ? "collapse" : null;

    private void ToggleNavMenu()
    {
        collapseNavMenu = !collapseNavMenu;
    }
}
```

## Configure the web application

The web application will he hosted as a static site on Azure Storage.

In the Azure Portal, navigate to the storage account resource where you are hosting your model.

### Enable static website

Enable a static website for the storage account and set the index document name and error document path to *index.html*.

![Enable Static Website](http://cdn.lqdev.tech/files/images/deploy-machine-learning-mlnet-model-blazor-webassembly4.png)

At this point, a new container called *$web* is created in your storage account. This is where all your site's static files will reside. Additionally, a primary endpoint is created. This is the URL you will use to access your application

### Configure CORS

The storage account has some default CORS settings. In order to download and use your model from your application, you'll have to configure them.

![Configure CORS](http://cdn.lqdev.tech/files/images/deploy-machine-learning-mlnet-model-blazor-webassembly5.png)

For "Allowed origins", enter your primary endpoint.

## Publish and deploy the web application

To publish your application, run the following command:

```powershell
dotnet publish -c Release
```

This generates all the files you'll need to host your web application as a static site in the *bin/Release/netstandard2.1/publish/BlazorWebApp/dist* directory of your *BlazorWebApp* project.

To deploy your application, use Azure Storage Explorer to copy all of the files in the *dist* directory into the *$web* container of your Azure Storage Account.

![Copy files into web container](http://cdn.lqdev.tech/files/images/deploy-machine-learning-mlnet-model-blazor-webassembly6.png)

## Test the application

In your browser, navigate to your static website's primary endpoint and select the Prediction page. Input data and click "Make prediction". The page should look as follows. 

![Test the application](http://cdn.lqdev.tech/files/images/deploy-machine-learning-mlnet-model-blazor-webassembly7.png)

**You may note that performance of Naive Bayes on this dataset is not the best so some of the predictions may not be as accurate. I am okay with this at the moment because this is a proof-of-concept to show how these technologies might work together. Perhaps using a better dataset may yield better results.**

## Conclusion

In this post, I went over how to deploy an ML.NET multiclass classification model alongside a Blazor WebAssembly static website to Azure Storage. While more limited than other methods of deployment due to the early stages of WebAssembly and Blazor WebAssembly, this shows the possibilities for the technologies. Deploying in this manner reduces the amount of resources required to deploy these models and shifts processing from a server or web service to the client's browser making deployment and distribution of machine learning models more efficient, scalable and cost-efficient.
]]&gt;</description>
      <link>https://www.lqdev.me/posts/deploy-machine-learning-mlnet-models-blazor-webassembly</link>
      <guid>https://www.lqdev.me/posts/deploy-machine-learning-mlnet-models-blazor-webassembly</guid>
      <pubDate>2020-03-01 19:21:04 -05:00</pubDate>
      <category>azure</category>
      <category>staticwebsites</category>
      <category>machinelearning</category>
      <category>ai</category>
      <category>artifificalintelligence</category>
      <category>ml</category>
      <category>dotnet</category>
      <category>dotnetcore</category>
      <category>webassembly</category>
      <category>webdevelopment</category>
      <category>mldotnet</category>
      <category>mlnet</category>
      <category>blazor</category>
    </item>
  </channel>
</rss>