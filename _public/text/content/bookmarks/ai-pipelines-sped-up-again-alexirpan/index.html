<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="stylesheet" href="/text/assets/text-only.css"><meta name="description" content="Text-only accessible version of Luis Quintanilla&#39;s website"><meta name="robots" content="noindex, nofollow"><title>My AI Timelines Have Sped Up (Again) - Text-Only Site</title></head><body><a href="#main-content" class="skip-link">Skip to main content</a><header role="banner"><h1><a href="/text/">Luis Quintanilla</a></h1><p>Text-Only Accessible Website</p></header><nav role="navigation" aria-label="Main navigation"><ul><li><a href="/text/">Home</a></li><li><a href="/text/about/">About</a></li><li><a href="/text/contact/">Contact</a></li><li><a href="/text/content/">All Content</a></li><li><a href="/text/feeds/">RSS Feeds</a></li><li><a href="/text/help/">Help</a></li></ul></nav><main role="main" id="main-content"><div><h1>My AI Timelines Have Sped Up (Again)</h1><div class="content-meta"><div class="content-type">bookmarks</div><time datetime="2024-01-11">January 11, 2024</time><p>Tags: ai, predictions, agi, data, llm, technology, ml, computervision</p></div><p><a href="/text/">← Home</a> | <a href="/text/content/bookmarks/">← All bookmarks</a> | <a href="https://www.lqdev.me/bookmarks/ai-pipelines-sped-up-again-alexirpan">View Full Version</a></p><div class="content"><article class="response-card h-entry" ><h2><a href="/bookmarks/ai-pipelines-sped-up-again-alexirpan/" >My AI Timelines Have Sped Up (Again)</a></h2><div class="response-target" >→ <a href="https://www.alexirpan.com/2024/01/10/ai-timelines-2024.html" >https://www.alexirpan.com/2024/01/10/ai-timelines-2024.html</a></div><div class="response-content" ><blockquote class="blockquote">
<p>...computers are useful, ML models are useful, and even if models fail to scale, people will want to fit GPT-4 sized models on their phone. It seems reasonable to assume the competing factions will figure something out.</p>
</blockquote>
<blockquote class="blockquote">
<p>Data seems like the harder question. (Or at least the one I feel qualified talking about.) We have already crossed the event horizon of trying to train on everything on the Internet. It’s increasingly difficult for labs to differentiate themselves on publicly available data. Differentiation is instead coming from non-public high-quality data to augment public low-quality data.</p>
</blockquote>
<blockquote class="blockquote">
<p>All the scaling laws have followed power laws so far, including dataset size. Getting more data by hand doesn’t seem good enough to cross to the next thresholds. We need better means to get good data.</p>
</blockquote>
<blockquote class="blockquote">
<p>A long time ago, when OpenAI still did RL in games / simulation, they were very into self-play. You run agents against copies of themselves, score their interactions, and update the models towards interactions with higher reward. Given enough time, they learn complex strategies through competition.</p>
</blockquote>
<blockquote class="blockquote">
<p>I think it’s possible we’re at the start of a world where self-play or self-play-like ideas work to improve LLM capabilities. Drawing an analogy, the environment is the dialogue, actions are text generated from an LLM, and the reward is from whatever reward model you have. Instead of using ground truth data, our models may be at a point where they can generate data that’s good enough to train on.</p>
</blockquote>
</div></article></div></div></main><footer role="contentinfo"><hr><p><a href="/">Full Site</a> | <a href="/text/accessibility/">Accessibility</a></p></footer></body></html>