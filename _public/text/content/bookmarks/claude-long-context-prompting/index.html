<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="stylesheet" href="/text/assets/text-only.css"><meta name="description" content="Text-only accessible version of Luis Quintanilla&#39;s website"><meta name="robots" content="noindex, nofollow"><title>Long context prompting for Claude 2.1 - Text-Only Site</title></head><body><a href="#main-content" class="skip-link">Skip to main content</a><header role="banner"><h1><a href="/text/">Luis Quintanilla</a></h1><p>Text-Only Accessible Website</p></header><nav role="navigation" aria-label="Main navigation"><ul><li><a href="/text/">Home</a></li><li><a href="/text/about/">About</a></li><li><a href="/text/contact/">Contact</a></li><li><a href="/text/content/">All Content</a></li><li><a href="/text/feeds/">RSS Feeds</a></li><li><a href="/text/help/">Help</a></li></ul></nav><main role="main" id="main-content"><div><h1>Long context prompting for Claude 2.1</h1><div class="content-meta"><div class="content-type">bookmarks</div><time datetime="2023-12-07">December 7, 2023</time><p>Tags: prompts, ai, llm</p></div><p><a href="/text/">← Home</a> | <a href="/text/content/bookmarks/">← All bookmarks</a> | <a href="https://www.lqdev.me/bookmarks/claude-long-context-prompting">View Full Version</a></p><div class="content"><article class="response-card h-entry" ><h2><a href="/bookmarks/claude-long-context-prompting/" >Long context prompting for Claude 2.1</a></h2><div class="response-target" >→ <a href="https://www.anthropic.com/index/claude-2-1-prompting" >https://www.anthropic.com/index/claude-2-1-prompting</a></div><div class="response-content" ><blockquote class="blockquote">
<ul>
<li>Claude 2.1 recalls information very well across its 200,000 token context window</li>
<li>However, the model can be reluctant to answer questions based on an individual sentence in a document, especially if that sentence has been injected or is out of place</li>
<li>A minor prompting edit removes this reluctance and results in excellent performance on these tasks</li>
</ul>
</blockquote>
<blockquote class="blockquote">
<p>What can users do if Claude is reluctant to respond to a long context retrieval question? We’ve found that a minor prompt update produces very different outcomes in cases where Claude is capable of giving an answer, but is hesitant to do so. When running the same evaluation internally, adding just one sentence to the prompt resulted in near complete fidelity throughout Claude 2.1’s 200K context window</p>
</blockquote>
<blockquote class="blockquote">
<p>We achieved significantly better results on the same evaluation by adding the sentence “Here is the most relevant sentence in the context:” to the start of Claude’s response. This was enough to raise Claude 2.1’s score from 27% to 98% on the original evaluation.</p>
</blockquote>
</div></article></div></div></main><footer role="contentinfo"><hr><p><a href="/">Full Site</a> | <a href="/text/accessibility/">Accessibility</a></p></footer></body></html>