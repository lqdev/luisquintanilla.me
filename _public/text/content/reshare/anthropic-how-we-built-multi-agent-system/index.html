<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="stylesheet" href="/text/assets/text-only.css"><meta name="description" content="Text-only accessible version of Luis Quintanilla&#39;s website"><meta name="robots" content="noindex, nofollow"><title>How we built our multi-agent research system - Anthropic - Text-Only Site</title></head><body><a href="#main-content" class="skip-link">Skip to main content</a><header role="banner"><h1><a href="/text/">Luis Quintanilla</a></h1><p>Text-Only Accessible Website</p></header><nav role="navigation" aria-label="Main navigation"><ul><li><a href="/text/">Home</a></li><li><a href="/text/about/">About</a></li><li><a href="/text/contact/">Contact</a></li><li><a href="/text/content/">All Content</a></li><li><a href="/text/feeds/">RSS Feeds</a></li><li><a href="/text/help/">Help</a></li></ul></nav><main role="main" id="main-content"><div><h1>How we built our multi-agent research system - Anthropic</h1><div class="content-meta"><div class="content-type">reshare</div><time datetime="2025-06-16">June 16, 2025</time><p>Tags: agent, ai, anthropic, engineering</p></div><p><a href="/text/">← Home</a> | <a href="/text/content/reshare/">← All reshare</a> | <a href="https://www.lqdev.me/responses/anthropic-how-we-built-multi-agent-system">View Full Version</a></p><div class="content"><article class="response-card h-entry" ><h2><a href="/responses/anthropic-how-we-built-multi-agent-system/" >How we built our multi-agent research system - Anthropic</a></h2><div class="response-target" >→ <a href="https://www.anthropic.com/engineering/built-multi-agent-research-system" >https://www.anthropic.com/engineering/built-multi-agent-research-system</a></div><div class="response-content" ><p>Great article.</p>
<p>TLDR: These are largely engineering problems.</p>
<blockquote class="blockquote">
<p>The journey of this multi-agent system from prototype to production taught us critical lessons about system architecture, tool design, and prompt engineering. A multi-agent system consists of multiple agents (<strong>LLMs autonomously using tools in a loop</strong>) working together. Our Research feature involves an agent that plans a research process based on user queries, and then uses tools to create parallel agents that search for information simultaneously. Systems with multiple agents introduce new challenges in agent coordination, evaluation, and reliability.</p>
</blockquote>
<h2>Benefits of a multi-agent system</h2>
<blockquote class="blockquote">
<p>The essence of search is compression: distilling insights from a vast corpus. <strong>Subagents facilitate compression by operating in parallel</strong> with their own context windows, exploring different aspects of the question simultaneously before condensing the most important tokens for the lead research agent. Each subagent also provides <strong>separation of concerns</strong>—distinct tools, prompts, and exploration trajectories—which reduces path dependency and enables thorough, independent investigations.</p>
</blockquote>
<blockquote class="blockquote">
<p>Once intelligence reaches a threshold, multi-agent systems become a vital way to scale performance. For instance, although individual humans have become more intelligent in the last 100,000 years, human societies have become exponentially more capable in the information age because of our collective intelligence and ability to coordinate. Even generally-intelligent agents face limits when operating as individuals; <strong>groups of agents can accomplish far more</strong>.</p>
</blockquote>
<blockquote class="blockquote">
<p>Our internal evaluations show that multi-agent research systems excel especially for breadth-first queries that involve pursuing multiple independent directions simultaneously.</p>
</blockquote>
<blockquote class="blockquote">
<p>Multi-agent systems work mainly because they help spend enough tokens to solve the problem...Multi-agent architectures effectively scale token usage for tasks that exceed the limits of single agents.</p>
</blockquote>
<blockquote class="blockquote">
<p>We’ve found that multi-agent systems excel at valuable tasks that involve heavy parallelization, information that exceeds single context windows, and interfacing with numerous complex tools.</p>
</blockquote>
<h2>Architecture overview</h2>
<blockquote class="blockquote">
<p>Our Research system uses a multi-agent architecture with an orchestrator-worker pattern, where a lead agent coordinates the process while delegating to specialized subagents that operate in parallel.</p>
</blockquote>
<blockquote class="blockquote">
<p>Traditional approaches using Retrieval Augmented Generation (RAG) use static retrieval. That is, they fetch some set of chunks that are most similar to an input query and use these chunks to generate a response. In contrast, our architecture uses a <strong>multi-step search that dynamically finds relevant information, adapts to new findings, and analyzes results to formulate high-quality answers</strong>.</p>
</blockquote>
<h2>Prompt engineering and evaluations for research agents</h2>
<blockquote class="blockquote">
<p><strong>Think like your agents.</strong> To iterate on prompts, you must understand their effects. To help us do this, we built simulations using our Console with the exact prompts and tools from our system, then watched agents work step-by-step.</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>Teach the orchestrator how to delegate.</strong> In our system, the lead agent decomposes queries into subtasks and describes them to subagents. Each subagent needs an <strong>objective</strong>, an <strong>output format</strong>, <strong>guidance on the tools and sources to use</strong>, and <strong>clear task boundaries</strong>. Without detailed task descriptions, agents duplicate work, leave gaps, or fail to find necessary information.</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>Scale effort to query complexity.</strong> Agents struggle to judge appropriate effort for different tasks, so we embedded scaling rules in the prompts...</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>Tool design and selection are critical.</strong> Agent-tool interfaces are as critical as human-computer interfaces. Using the right tool is efficient—often, it’s strictly necessary...Bad tool descriptions can send agents down completely wrong paths, so each tool needs a distinct purpose and a clear description.</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>Let agents improve themselves.</strong>...When given a prompt and a failure mode, they are able to diagnose why the agent is failing and suggest improvements.</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>Start wide, then narrow down.</strong> Search strategy should mirror expert human research: explore the landscape before drilling into specifics.</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>Guide the thinking process.</strong>...Our testing showed that extended thinking improved instruction-following, reasoning, and efficiency. Subagents also plan, then use interleaved thinking after tool results to evaluate quality, identify gaps, and refine their next query. This makes subagents more effective in adapting to any task.</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>Parallel tool calling transforms speed and performance.</strong>...For speed, we introduced two kinds of parallelization: (1) the lead agent spins up 3-5 subagents in parallel rather than serially; (2) the subagents use 3+ tools in parallel.</p>
</blockquote>
<blockquote class="blockquote">
<p>Our prompting strategy focuses on instilling <strong>good heuristics rather than rigid rules</strong>. We studied how skilled humans approach research tasks and encoded these strategies in our prompts—strategies like <strong>decomposing difficult questions into smaller tasks</strong>, <strong>carefully evaluating the quality of sources</strong>, <strong>adjusting search approaches based on new information</strong>, and <strong>recognizing when to focus on depth (investigating one topic in detail) vs. breadth (exploring many topics in parallel)</strong>.</p>
</blockquote>
<h2>Effective evaluation of agents</h2>
<blockquote class="blockquote">
<p>...evaluating multi-agent systems presents unique challenges...Because we don’t always know what the right steps are, we usually can't just check if agents followed the “correct” steps we prescribed in advance. Instead, we need flexible evaluation methods that judge whether agents achieved the right outcomes while also following a reasonable process.</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>Start evaluating immediately with small samples.</strong>...it’s best to start with small-scale testing right away with a few examples, rather than delaying until you can build more thorough evals.</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>LLM-as-judge evaluation scales when done well.</strong>...We used an LLM judge that evaluated each output against criteria in a rubric: <strong>factual accuracy</strong> (do claims match sources?), <strong>citation accuracy</strong> (do the cited sources match the claims?), <strong>completeness</strong> (are all requested aspects covered?), <strong>source quality</strong> (did it use primary sources over lower-quality secondary sources?), and <strong>tool efficiency</strong> (did it use the right tools a reasonable number of times?)...[we] found that a single LLM call with a single prompt outputting scores from 0.0-1.0 and a pass-fail grade was the most consistent and aligned with human judgements.</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>Human evaluation catches what automation misses.</strong>...Adding source quality heuristics to our prompts helped resolve this issue. Even in a world of automated evaluations, manual testing remains essential.</p>
</blockquote>
<blockquote class="blockquote">
<p>the best prompts for these agents are not just strict instructions, but <strong>frameworks for collaboration</strong> that define the <strong>division of labor</strong>, <strong>problem-solving approaches</strong>, and <strong>effort budgets</strong>. Getting this right relies on <strong>careful prompting and tool design</strong>, <strong>solid heuristics</strong>, <strong>observability</strong>, and <strong>tight feedback loops</strong>.</p>
</blockquote>
<h2>Production reliability and engineering challenges</h2>
<blockquote class="blockquote">
<p><strong>Agents are stateful and errors compound.</strong>...Agents can run for long periods of time, maintaining state across many tool calls. This means we need to <strong>durably execute code and handle errors along the way</strong>. Without effective mitigations, minor system failures can be catastrophic for agents. When errors occur, we can't just restart from the beginning...We combine the adaptability of AI agents built on Claude with deterministic safeguards like retry logic and regular checkpoints.</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>Debugging benefits from new approaches</strong>...Adding full production tracing let us diagnose why agents failed and fix issues systematically. Beyond standard observability, we monitor agent decision patterns and interaction structures—all without monitoring the contents of individual conversations, to maintain user privacy.</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>Deployment needs careful coordination</strong>...we use rainbow deployments to avoid disrupting running agents, by gradually shifting traffic from old to new versions while keeping both running simultaneously.</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>Synchronous execution creates bottlenecks.</strong> Currently, our lead agents execute subagents synchronously, waiting for each set of subagents to complete before proceeding. This simplifies coordination, but creates bottlenecks in the information flow between agents. Asynchronous execution would enable additional parallelism: agents working concurrently and creating new subagents when needed. But this asynchronicity adds challenges in result coordination, state consistency, and error propagation across the subagents. As models can handle longer and more complex research tasks, we expect the performance gains will justify the complexity.</p>
</blockquote>
<h2>Conclusion</h2>
<blockquote class="blockquote">
<p>For all the reasons described in this post, the gap between prototype and production is often wider than anticipated.</p>
</blockquote>
<blockquote class="blockquote">
<p>Multi-agent research systems can operate reliably at scale with <strong>careful engineering</strong>, <strong>comprehensive testing</strong>, <strong>detail-oriented prompt and tool design</strong>, <strong>robust operational practices</strong>, and <strong>tight collaboration between research, product, and engineering teams</strong> who have a strong understanding of current agent capabilities.</p>
</blockquote>
</div></article>
</div></div></main><footer role="contentinfo"><hr><p><a href="/">Full Site</a> | <a href="/text/accessibility/">Accessibility</a></p></footer></body></html>