<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="stylesheet" href="/text/assets/text-only.css"><meta name="description" content="Text-only accessible version of Luis Quintanilla&#39;s website"><meta name="robots" content="noindex, nofollow"><title>Reproducing GPT-2 (124M) in llm.c in 90 minutes for $20 - Text-Only Site</title></head><body><a href="#main-content" class="skip-link">Skip to main content</a><header role="banner"><h1><a href="/text/">Luis Quintanilla</a></h1><p>Text-Only Accessible Website</p></header><nav role="navigation" aria-label="Main navigation"><ul><li><a href="/text/">Home</a></li><li><a href="/text/about/">About</a></li><li><a href="/text/contact/">Contact</a></li><li><a href="/text/content/">All Content</a></li><li><a href="/text/feeds/">RSS Feeds</a></li><li><a href="/text/help/">Help</a></li></ul></nav><main role="main" id="main-content"><div><h1>Reproducing GPT-2 (124M) in llm.c in 90 minutes for $20</h1><div class="content-meta"><div class="content-type">reshare</div><time datetime="2024-05-29">May 29, 2024</time><p>Tags: ai, llm, gpt, gpt2, llmc, c, slm</p></div><p><a href="/text/">← Home</a> | <a href="/text/content/reshare/">← All reshare</a> | <a href="https://www.lqdev.me/responses/repro-gpt-2-llm-c-90-min-20-dollars-karpathy">View Full Version</a></p><div class="content"><article class="response-card h-entry" ><h2><a href="/responses/repro-gpt-2-llm-c-90-min-20-dollars-karpathy/" >Reproducing GPT-2 (124M) in llm.c in 90 minutes for $20</a></h2><div class="response-target" >→ <a href="https://github.com/karpathy/llm.c/discussions/481" >https://github.com/karpathy/llm.c/discussions/481</a></div><div class="response-content" ><blockquote class="blockquote">
<p>...the TLDR is that we're training a 12-layer GPT-2 (124M), from scratch, on 10B tokens of FineWeb, with max sequence length of 1024 tokens.</p>
</blockquote>
<blockquote class="blockquote">
<p>The 124M model is the smallest model in the GPT-2 series released by OpenAI in 2019, and is actually quite accessible today, even for the GPU poor. With llm.c, which is quite efficient at up to ~60% model flops utilization, reproducing this model on one 8X A100 80GB SXM node takes ~90 minutes. For example, on Lambda this node goes for ~$14/hr, so the total cost of reproducing this model today is about $20. You can train the model with a single GPU too, it would just take proportionally longer (e.g. ~4-24 hours depending on the GPU).</p>
</blockquote>
</div></article>
</div></div></main><footer role="contentinfo"><hr><p><a href="/">Full Site</a> | <a href="/text/accessibility/">Accessibility</a></p></footer></body></html>