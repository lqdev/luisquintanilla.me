<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="stylesheet" href="/text/assets/text-only.css"><meta name="description" content="Text-only accessible version of Luis Quintanilla&#39;s website"><meta name="robots" content="noindex, nofollow"><title>Announcing DBRX: A new standard for efficient open source LLMs - Text-Only Site</title></head><body><a href="#main-content" class="skip-link">Skip to main content</a><header role="banner"><h1><a href="/text/">Luis Quintanilla</a></h1><p>Text-Only Accessible Website</p></header><nav role="navigation" aria-label="Main navigation"><ul><li><a href="/text/">Home</a></li><li><a href="/text/about/">About</a></li><li><a href="/text/contact/">Contact</a></li><li><a href="/text/content/">All Content</a></li><li><a href="/text/feeds/">RSS Feeds</a></li><li><a href="/text/help/">Help</a></li></ul></nav><main role="main" id="main-content"><div><h1>Announcing DBRX: A new standard for efficient open source LLMs</h1><div class="content-meta"><div class="content-type">reshare</div><time datetime="2024-04-01">April 1, 2024</time><p>Tags: databricks, ai, llm, opensource</p></div><p><a href="/text/">← Home</a> | <a href="/text/content/reshare/">← All reshare</a> | <a href="https://www.lqdev.me/responses/announcing-dbrx-llm">View Full Version</a></p><div class="content"><article class="response-card h-entry" ><h2><a href="/responses/announcing-dbrx-llm/" >Announcing DBRX: A new standard for efficient open source LLMs</a></h2><div class="response-target" >→ <a href="https://www.databricks.com/blog/announcing-dbrx-new-standard-efficient-open-source-customizable-llms" >https://www.databricks.com/blog/announcing-dbrx-new-standard-efficient-open-source-customizable-llms</a></div><div class="response-content" ><blockquote class="blockquote">
<p>Today, we are excited to advance our mission by open sourcing DBRX, a general purpose large language model (LLM) built by our Mosaic Research team that outperforms all established open source models on standard benchmarks. We believe that pushing the boundary of open source models enables generative AI for all enterprises that is customizable and transparent.</p>
</blockquote>
<blockquote class="blockquote">
<p>We are excited about DBRX for three distinct reasons. First, it handily beats open source models, such as, LLaMA2-70B, Mixtral, and Grok-1 on language understanding, programming, math, and logic...<br />
<br>
Second, DBRX beats GPT-3.5 on most benchmarks...<br />
<br>
Third, DBRX is a Mixture-of-Experts (MoE) model built on the MegaBlocks research and open source project, making the model extremely fast in terms of tokens/second.</p>
</blockquote>
</div></article>
</div></div></main><footer role="contentinfo"><hr><p><a href="/">Full Site</a> | <a href="/text/accessibility/">Accessibility</a></p></footer></body></html>