<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="stylesheet" href="/text/assets/text-only.css"><meta name="description" content="Text-only accessible version of Luis Quintanilla&#39;s website"><meta name="robots" content="noindex, nofollow"><title>Self-Adapting Language Models (SEAL) - Text-Only Site</title></head><body><a href="#main-content" class="skip-link">Skip to main content</a><header role="banner"><h1><a href="/text/">Luis Quintanilla</a></h1><p>Text-Only Accessible Website</p></header><nav role="navigation" aria-label="Main navigation"><ul><li><a href="/text/">Home</a></li><li><a href="/text/about/">About</a></li><li><a href="/text/contact/">Contact</a></li><li><a href="/text/content/">All Content</a></li><li><a href="/text/feeds/">RSS Feeds</a></li><li><a href="/text/help/">Help</a></li></ul></nav><main role="main" id="main-content"><div><h1>Self-Adapting Language Models (SEAL)</h1><div class="content-meta"><div class="content-type">reshare</div><time datetime="2025-06-17">June 17, 2025</time><p>Tags: agent, ai, llm, mit, research</p></div><p><a href="/text/">‚Üê Home</a> | <a href="/text/content/reshare/">‚Üê All reshare</a> | <a href="https://www.lqdev.me/responses/self-adapting-language-models-seal">View Full Version</a></p><div class="content"><article class="response-card h-entry" ><h2><a href="/responses/self-adapting-language-models-seal/" >Self-Adapting Language Models (SEAL)</a></h2><div class="response-target" >‚Üí <a href="https://jyopari.github.io/posts/seal" >https://jyopari.github.io/posts/seal</a></div><div class="response-content" ><blockquote class="blockquote">
<p>Large language models (LLMs) are powerful but static; they lack mechanisms to adapt their weights in response to new tasks, knowledge, or examples. <strong>We introduce Self-Adapting LLMs (SEAL) ü¶≠, a framework that enables LLMs to self-adapt by generating their own finetuning data and update directives.</strong> Given a new input, the model produces a self-edit ‚Äî a generation that may restructure the information in different ways, specify optimization hyperparameters, or invoke tools for data augmentation and gradient-based updates. Through supervised finetuning (SFT), these self-edits result in persistent weight updates, enabling lasting adaptation. To train the model to produce effective self-edits, we use a reinforcement learning loop, using the downstream performance of the updated model as the reward signal. Unlike prior approaches that rely on separate adaptation modules or auxiliary networks, SEAL directly uses the model's generation to parameterize and control its own adaptation process. Experiments on knowledge incorporation and few-shot generalization show that SEAL is a promising step toward language models capable of self-directed adaptation in response to new data.</p>
</blockquote>
<blockquote class="blockquote">
<p>We demonstrate SEAL in two domains: (1) <strong>Knowledge Incorporation</strong>, where the model integrates new factual information by generating logical implications as synthetic data, and (2) <strong>Few-Shot Learning</strong>, where the model autonomously selects data augmentations and training hyperparameters to adapt to new abstract reasoning tasks.</p>
</blockquote>
<ul>
<li><a href="https://github.com/Continual-Intelligence">Code</a></li>
<li><a href="https://arxiv.org/abs/2506.10943">Paper</a></li>
</ul>
</div></article>
</div></div></main><footer role="contentinfo"><hr><p><a href="/">Full Site</a> | <a href="/text/accessibility/">Accessibility</a></p></footer></body></html>