<!DOCTYPE html>
<html lang="en"><head><link rel="stylesheet" href="/css/bootstrap.min.css"><link rel="stylesheet" href="/css/highlight-dark.min.css"><link rel="stylesheet" href="/css/main.css"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta property="og:title" content="Train an image classifier using F# and ML .NET"><meta property="og:type" content="website"><meta property="og:image" content="/favicon.ico"><meta property="og:site_name" content="Luis Quintanilla Personal Website"><meta property="og:locale" content="en_US"><meta name="robots" content="noindex,nofollow,nosnippet"><title>Train an image classifier using F# and ML .NET</title></head><body><nav class="navbar navbar-expand-md navbar-dark fixed-top bg-dark"><a class="navbar-brand" href="#">Luis Quintanilla</a><button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarCollapse"><ul class="navbar-nav mr-auto"><li class="nav-item active"><a class="nav-link" href="/">Home</a></li><li class="nav-item"><a class="nav-link" href="/about.html">About</a></li><li class="nav-item"><a class="nav-link" href="/contact.html">Contact</a></li><li class="nav-item"><a class="nav-link" href="/posts/1">Blog</a></li><li class="nav-item"><a class="nav-link" href="/events.html">Events</a></li></ul></div></nav><main role="main" class="container"><div class="mr-auto"><h1>Introduction</h1>
<p>This post is part of F# Advent 2020. Thank you to <a href="https://twitter.com/sergey_tihon">Sergey Tihon</a> for organizing this and the rest of the contributors for producing high-quality content. Make sure to check out the rest of the <a href="https://sergeytihon.com/2020/10/22/f-advent-calendar-in-english-2020/">F# Advent 2020 content</a>.</p>
<p>When picking who's on the naughty or nice list, I often wonder how Santa decides. I took a shot at answering this question by training an image classifier using the ML.NET image classification API and images of Disney heroes and villains to tell whether they're naughty or nice. You shouldn't judge someone by the way they look (even if they are the Evil Queen), so it's safe to say, don't try this at home or with your neighbors ðŸ˜‰. This sample is just for demo purposes. You can find the full code on <a href="https://gist.github.com/lqdev/0c4dc9eea93b7b8541f31ddd429afb53">GitHub</a>.</p>
<h2>Prerequisites</h2>
<p>This sample was built on a Windows 10 PC, but should work on Mac / Linux PCs</p>
<ul>
<li><a href="https://dotnet.microsoft.com/download">.NET 5 SDK</a></li>
</ul>
<h2>The data</h2>
<p>The dataset contains images of Disney characters, both real and animated. They were obtained from the <a href="https://disney.fandom.com/wiki/The_Disney_Wiki">Disney Fandom Wiki</a>. The characters are split into two categories, <a href="https://disney.fandom.com/wiki/Category:Villains">villains</a> and <a href="https://disney.fandom.com/wiki/Category:Protagonists">heroes</a>. For the purpose of this sample, we'll label heroes as nice and villains as naughty. The dataset used to train this model contains 2400 villain (naughty) and 675 hero (nice) images stored in top-level directories with the naughty/nice names. This means that the dataset is unbalanced and may skew predictions as it can be seen when making predictions.</p>
<h2>Install  NuGet packages</h2>
<p>Use the <code>#r</code> convention to install the necessary NuGet packages used in this sample.</p>
<pre><code class="language-fsharp">#r &quot;nuget:Microsoft.ML&quot;
#r &quot;nuget:Microsoft.ML.Vision&quot;
#r &quot;nuget:Microsoft.ML.ImageAnalytics&quot;
#r &quot;nuget:SciSharp.TensorFlow.Redist&quot; 
</code></pre>
<p>Then, import the packages.</p>
<pre><code class="language-fsharp">open System
open System.IO
open Microsoft.ML
open Microsoft.ML.Data
open Microsoft.ML.Vision
</code></pre>
<h2>Define data types</h2>
<p>Start off by defining the data types containing your input and output schema. You can do this by creating two records, <code>ImageData</code> and <code>ImagePrediction</code>. <code>ImageData</code> is the input which contains the path to image file and the category it belongs to and the <code>ImagePrediction</code> contains the prediction generated by the model.</p>
<pre><code class="language-fsharp">[&lt;CLIMutable&gt;]
type ImageData = {
    ImagePath: string
    Label: string
}

[&lt;CLIMutable&gt;]
type ImagePrediction = {
    PredictedLabel: string
}
</code></pre>
<h2>Training</h2>
<p>The training process loads a set of training images, preprocesses them, and uses the ML.NET image classification API to train an image classification model.</p>
<h3>Initialize MLContext</h3>
<p>Once you've defined the data type, initialize the <code>MLContext</code>. <code>MLContext</code> is the entrypoint for ML.NET applications.</p>
<pre><code class="language-fsharp">let ctx = new MLContext()
</code></pre>
<h3>Load training data</h3>
<p>Then, load the data using the helper function <code>loadImagesFromDirectory</code> and point it to the top-level directory containing the subdirectories of images in the nice and naughty categories.</p>
<pre><code class="language-fsharp">let imageData = loadImagesFromDirectory &quot;C:/Datasets/fsadvent2020/Train&quot; true
</code></pre>
<p>The <code>loadImagesFromDirectory</code> function looks like the following:</p>
<pre><code class="language-fsharp">let loadImagesFromDirectory (path:string) (useDirectoryAsLabel:bool) = 

    let files = Directory.GetFiles(path, &quot;*&quot;,searchOption=SearchOption.AllDirectories)

    files
    |&gt; Array.filter(fun file -&gt; 
        (Path.GetExtension(file) = &quot;.jpg&quot;) ||
        (Path.GetExtension(file) = &quot;.png&quot;))
    |&gt; Array.map(fun file -&gt; 
        let mutable label = Path.GetFileName(file)
        if useDirectoryAsLabel then
            label &lt;-  Directory.GetParent(file).Name
        else
            let mutable brk = false
            for index in 0..label.Length do
                while not brk do
                    if not (label.[index] |&gt; Char.IsLetter) then
                        label &lt;- label.Substring(0,index)
                        brk &lt;- true

        {ImagePath=file; Label=label}
    )
</code></pre>
<p>Then, create an <code>IDataView</code> for the training images. An <code>IDataView</code> is the way data is represented in ML.NET.</p>
<pre><code class="language-fsharp">let imageIdv = ctx.Data.LoadFromEnumerable&lt;ImageData&gt;(imageData)
</code></pre>
<h3>Define training pipeline</h3>
<p>Once your data is is loaded into an <code>IDataView</code>, set the classifier options by using <code>ImageClassificationTrainer.Options</code>. Use it to define the name of the network architecture, input and output columns, and some additional parameters. The network architecture used in this case is <a href="https://www.paperswithcode.com/method/inception-resnet-v2"><code>ResNet V2</code></a>.</p>
<pre><code class="language-fsharp">let classifierOptions = ImageClassificationTrainer.Options()
classifierOptions.FeatureColumnName &lt;- &quot;Image&quot; 
classifierOptions.LabelColumnName &lt;- &quot;LabelKey&quot; 
classifierOptions.TestOnTrainSet &lt;- true  
classifierOptions.Arch &lt;- ImageClassificationTrainer.Architecture.ResnetV2101
classifierOptions.MetricsCallback &lt;- Action&lt;ImageClassificationTrainer.ImageClassificationMetrics&gt;(fun x -&gt; printfn &quot;%s&quot; (x.ToString()))
</code></pre>
<p>Define the preprocessing steps, image classification trainer (along with the previously defined options) and postprocessing steps.</p>
<pre><code class="language-fsharp">let pipeline = 
    EstimatorChain()
        .Append(ctx.Transforms.LoadRawImageBytes(&quot;Image&quot;,null,&quot;ImagePath&quot;))
        .Append(ctx.Transforms.Conversion.MapValueToKey(&quot;LabelKey&quot;,&quot;Label&quot;))
        .Append(ctx.MulticlassClassification.Trainers.ImageClassification(classifierOptions))
        .Append(ctx.Transforms.Conversion.MapKeyToValue(&quot;PredictedLabel&quot;))
</code></pre>
<p>The ML.NET image classification API leverages a technique known as transfer learning. Transfer learning uses pretrained models (usually neural networks) and retrains the last few layers using new data. This significantly cuts down the amount of time, resources, and data you need to train deep learning models. ML .NET is able to do this with the help of <a href="https://github.com/SciSharp/TensorFlow.NET">TensorFlow .NET</a>, a set of .NET bindings for the TensorFlow deep learning framework. Although transfer learning usually makes the process of training a deep learning models less resource intensive, the TensorFlow API is usually low level and still requires a significant amount of code. See this <a href="https://github.com/SciSharp/SciSharp-Stack-Examples/blob/master/src/TensorFlowNET.Examples/ImageProcessing/TransferLearningWithInceptionV3.cs">transfer learning example</a> from TensorFlow.NET to see how you'd do it in TensorFlow.NET. Although the low-level nature of the TensorFlow API gives you control over what you're building, many times you don't need that level of control. ML.NET through the image classification trainer greatly simplifies this process by providing a high-level API for achieving the same task.</p>
<p>To train the model, use the <code>Fit</code> method on the training image <code>IDataView</code>.</p>
<pre><code class="language-fsharp">let model = pipeline.Fit(imageIdv)
</code></pre>
<p>Throughout the training process, you should see output similar to the following:</p>
<pre><code class="language-console">Phase: Bottleneck Computation, Dataset used:      Train, Image Index: 279
Phase: Bottleneck Computation, Dataset used:      Train, Image Index: 280
Phase: Bottleneck Computation, Dataset used: Validation, Image Index:   1
</code></pre>
<p>With the model trained, it's time to use it to make predictions. Optionally, you can save it for use in other applications.</p>
<pre><code class="language-fsharp">ctx.Model.Save(model,imageIdv.Schema,&quot;fsadvent2020-model.zip&quot;)
</code></pre>
<h2>Make predictions</h2>
<p>Load the test images and create an <code>IDataView</code> for them. The test images used are of Jack Skellington and The Grinch.</p>
<pre><code class="language-fsharp">let testImages = 
    Directory.GetFiles(&quot;C:/Datasets/fsadvent2020/Test&quot;)
    |&gt; Array.map(fun file -&gt; {ImagePath=file; Label=&quot;&quot;})

let testImageIdv = ctx.Data.LoadFromEnumerable&lt;ImageData&gt;(testImages)
</code></pre>
<p><img src="https://www.khwiki.com/images/thumb/f/ff/Jack_Skellington_KHII.png/180px-Jack_Skellington_KHII.png" alt="The grinch" /></p>
<p>Then, use the model to make predictions.</p>
<pre><code class="language-fsharp">let predictionIdv = model.Transform(testImageIdv)
</code></pre>
<p>One of the easiest ways to access the predictions is to create an <code>IEnumerable</code>. To do so, use the <code>CreateEnumerable</code> method.</p>
<pre><code class="language-fsharp">let predictions = ctx.Data.CreateEnumerable&lt;ImagePrediction&gt;(predictionIdv,false)
</code></pre>
<p>Then, use the built-in F# sequence operations to display the predictions</p>
<pre><code class="language-fsharp">predictions |&gt; Seq.iter(fun pred -&gt; 
    printfn &quot;%s is %s&quot; (Path.GetFileNameWithoutExtension(pred.ImagePath)) pred.PredictedLabel)
</code></pre>
<p>The output should look like the following:</p>
<pre><code class="language-console">grinch is Naughty
jack is Naughty
</code></pre>
<h2>Conclusion</h2>
<p>In this post, I showed how you can use the ML.NET and TensorFlow.NET to train an image classification model to classify Disney characters as naughty or nice. Depending on the level of control you need, you might choose to use TensorFlow.NET or if you want a high-level API for training an image classifier, you can use the ML.NET. Most importantly, we figured out that Jack Skellington and The Grinch are naughty, so I guess no gifts for them this year? Happy coding!</p>
<h3>Call to Action</h3>
<p>Originally, I had planned on writing this article using <a href="https://github.com/SciSharp/TensorFlow.NET">TensorFlow.Keras</a>, which is part of the SciSharp TensorFlow.NET project. TensorFlow.Keras provides .NET bindings for Keras. Keras provides a high-level API for TensorFlow which makes the process of building custom neural networks much simpler than working with the TensorFlow API. Unfortunately, while trying to adapt my scenario to an <a href="https://github.com/SciSharp/SciSharp-Stack-Examples/blob/master/src/TensorFlowNET.Examples/ImageProcessing/ImageClassificationKeras.cs">existing sample</a>, I ran into an <a href="https://github.com/SciSharp/SciSharp-Stack-Examples/issues/23">issue</a>.  This is not something I would have been able to resolve in time to publish this post, so I defaulted to using ML.NET.</p>
<p>I'm a big fan of the work being done by the SciSharp community and the machine learning and data science capabilities it brings to the .NET ecosystem. The work and efforts are all community driven, and as such, there's plenty of opportunities to contribute. Here are just some examples of ways to contribute, especially from an F# perspective. From my end, I plan on eventually converting this sample to use TensorFlow.Keras. See you in the SciSharp repos! ðŸ™‚</p>
<p><img src="https://user-images.githubusercontent.com/11130940/102030239-f4ac3700-3d7f-11eb-9898-f18990a56326.png" alt="FsLab SciSharp contribute" /></p>
</div></main><script src="/js/jquery.slim.min.js"></script><script src="/js/bootstrap.min.js"></script><script src="/js/highlight.min.js"></script><script src="/js/highlight.fsharp.min.js"></script><script type="application/javascript">hljs.initHighlightingOnLoad();</script></body></html>