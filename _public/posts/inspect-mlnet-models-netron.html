<!DOCTYPE html>
<html lang="en"><head><link rel="stylesheet" href="/css/bootstrap.min.css"><link rel="stylesheet" href="/css/bootstrap-icons-1.5.0/bootstrap-icons.css"><link rel="stylesheet" href="/css/highlight-dark.min.css"><link rel="stylesheet" href="/css/main.css"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta property="og:title" content="Inspect ML.NET models with Netron - Luis Quintanilla"><meta property="og:type" content="website"><meta property="og:image" content="https://www.luisquintanilla.me/avatar.png"><meta property="og:image:secure_url" content="https://www.luisquintanilla.me/avatar.png"><meta property="og:image:type" content="image/png"><meta property="og:image:width" content="200"><meta property="og:image:height" content="200"><meta property="og:site_name" content="Luis Quintanilla Personal Website"><meta property="og:locale" content="en_US"><meta property="twitter:image" content="https://www.luisquintanilla.me/avatar.png"><meta name="robots" content="noindex,nofollow,nosnippet"><title>Inspect ML.NET models with Netron - Luis Quintanilla</title></head><body><nav class="navbar navbar-expand-md navbar-dark fixed-top bg-dark"><a class="navbar-brand" href="/"><img src="/avatar.png" height="32" width="32" class="d-inline-block align-top rounded-circle" style="margin-right:5px">Luis Quintanilla</a><button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarCollapse"><ul class="navbar-nav mr-auto"><li class="nav-item active"><a class="nav-link" href="/">Home</a></li><li class="nav-item"><a class="nav-link" href="/about.html">About</a></li><li class="nav-item"><a class="nav-link" href="/contact.html">Contact</a></li><li class="nav-item"><a class="nav-link" href="/posts/1">Blog</a></li><li class="nav-item"><a class="nav-link" href="/events.html">Events</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Feeds</a><div class="dropdown-menu" aria-labelledby="navbarDropdown"><a class="dropdown-item" href="/feed/index.html">Main</a><a class="dropdown-item" href="/feed/notes.html">Notes</a><a class="dropdown-item" href="/feed/videos.html">Videos</a><div class="dropdown-divider"></div><a class="dropdown-item" href="/feed/blogroll.html">Blogroll</a></div></li></ul><a href="/feed.rss"><svg class="bi bi-rss text-secondary" fill="currentColor" viewBox="0 0 16 16" height="32" width="32"><path d="M14 1a1 1 0 0 1 1 1v12a1 1 0 0 1-1 1H2a1 1 0 0 1-1-1V2a1 1 0 0 1 1-1h12zM2 0a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V2a2 2 0 0 0-2-2H2z"></path><path d="M5.5 12a1.5 1.5 0 1 1-3 0 1.5 1.5 0 0 1 3 0zm-3-8.5a1 1 0 0 1 1-1c5.523 0 10 4.477 10 10a1 1 0 1 1-2 0 8 8 0 0 0-8-8 1 1 0 0 1-1-1zm0 4a1 1 0 0 1 1-1 6 6 0 0 1 6 6 1 1 0 1 1-2 0 4 4 0 0 0-4-4 1 1 0 0 1-1-1z"></path></svg></a></div></nav><main role="main" class="container"><div class="mr-auto"><h2>Introduction</h2>
<p>Once you've trained a machine learning model, you typically serialize it and save it to a file. This serialized file contains information such as the model inputs and output schema (names, data types), the transformations and algorithms used by the model,  weights / coefficients, hyperparameters, and all other sorts of information about the model. The model file is then embedded in an end-user application such as a web API which deserializes the contents of the file and uses the model to make predictions on new data.</p>
<p>How the model is serialized depends on the framework you use to train your model. To standardize model serialization and interoperability, you can use something like Open Neural Network Exchange (ONNX) to represent your models if supported by the framework you're using. That's beyond the scope of this post though.</p>
<p>Regardless of which framework or serialization format is used, if you were to open up the model file, the contents of the model file are often not human readable or difficult to interpret. When the person who trains the model is also putting it into production, they know the format input data needs to be in to make predictions. That's not often the case though. As a result, the people putting models into production need the ability to inspect a model to get a sense of how they need to collect and preprocess input data before making predictions. That's where Netron comes in. <a href="https://github.com/lutzroeder/Netron">Netron</a> is a &quot;visualizer for neural network, deep learning, and machine learning models&quot;. In this post, I'll show how you can use Netron to inspect ML.NET models and use that information to define the model input and output schemas.</p>
<h2>Inspecting an ML.NET model</h2>
<p>ML.NET models are typically serialized and saved to files with the <em>.zip</em> file extension. Using the <em>.zip</em> file extension is standard convention. However, the extension can be whatever makes the most sense to you.</p>
<p>A common question is, what's in the <em>zip</em> file? The easy but vague answer to that question is, a serialized version of the model. Using Netron, you can go deeper and see exactly what is inside the <em>zip</em> file.</p>
<p>In this post, I'm using a pretrained ML.NET model that classifies sentiment. The model can be found in the <a href="https://github.com/dotnet/samples/blob/main/machine-learning/models/sentimentanalysis/sentiment_model.zip">dotnet/samples</a> repo. The same concept applies to any other ML.NET model.</p>
<p>To inspect the ML.NET model using Netron:</p>
<ol>
<li><p><a href="https://github.com/dotnet/samples/raw/main/machine-learning/models/sentimentanalysis/sentiment_model.zip">Download the model</a></p>
</li>
<li><p>Navigate to <a href="https://netron.app/">https://netron.app</a>. Alternatively, if you'd prefer to use Netron offline, you can also <a href="https://github.com/lutzroeder/netron/releases">download the latest version of Netron</a> for your operating system (Windows, Mac, or Linux). In this post, I use the web app.</p>
</li>
<li><p>Select <strong>Open Model...</strong> and use the file browser to select your ML.NET model. In this case, our model is <em>sentiment_model.zip</em>.</p>
</li>
<li><p>After a few seconds, a graph describing you model appears. How long it takes for your model depends on its size. The larger your model, the longer it takes to load. The nodes in the graph represent the model inputs, transformations, algorithm, and outputs.</p>
</li>
<li><p>Usually the top nodes represent the model inputs and the last node represents the algorithm or trainer. Click on any of the top nodes to display more information about the inputs.</p>
<p><img src="https://user-images.githubusercontent.com/11130940/130704589-61ebb612-d65f-4364-b275-bd0d4991d3cf.png" alt="Sentiment Classification ML.NET model in netron" /></p>
<p>For this model, we see that there are 3 input properties or columns:</p>
<ul>
<li>SentimentText (string)</li>
<li>Label (boolean)</li>
<li>SamplingKeyColumn (float32)</li>
</ul>
<p>Using this information, we can represent the model inputs as a Plain-Old-CLR-Object (POCO) in our end-user application.</p>
<pre><code class="language-csharp">public class ModelInput
{
    public string SentimentText {get;set;}
    public bool Label {get;set;}
    public float SamplingKeyColumn {get;set;} 
}
</code></pre>
<p><img src="https://user-images.githubusercontent.com/11130940/130705880-0baea2f7-7b45-408a-b60c-16acceb54079.png" alt="ML.NET Netron Binary Predictor" /></p>
<p>Looking at the last node <code>BinaryPredXfer</code>, we see that the algorithm used is for binary classification or predictions. Looking at the <a href="https://docs.microsoft.com/dotnet/machine-learning/resources/tasks#binary-classification-inputs-and-outputs">ML.NET tasks documentation</a>, we expect to get at least two columns in the prediction output:</p>
<ul>
<li>Score (Single)</li>
<li>PredictedLabel (boolean)</li>
</ul>
<p>Like the input, we can also represent model outputs or predictions as follows:</p>
<pre><code class="language-csharp">public class ModelOutput
{
    public float Score {get;set;}
    public bool PredictedLabel {get;set;}
}
</code></pre>
<p>Keep in mind that the name of the class can be anything so long as the properties or column names and types match with those expected by the model.</p>
</li>
</ol>
<p>Once you have your model inputs and outputs defined in your end-user application, you can follow the standard process of <a href="https://docs.microsoft.com/dotnet/machine-learning/how-to-guides/machine-learning-model-predictions-ml-net">loading your model and using it to make predictions</a>.</p>
<h2>Conclusion</h2>
<p>Inspecting ML.NET models can be difficult since their serialized version is not human readable. When making predictions with ML.NET models but you're not familiar with what the input and output data should look like, use Netron to inspect the model. Then, use the information about the input data names and types, machine learning task, and algorithm to define model input and output schema classes in your end-user application. Once you've defined your model input and output, you can use the model to make predictions on new data.</p>
</div></main><script src="/js/jquery.slim.min.js"></script><script src="/js/bootstrap.min.js"></script><script src="/js/highlight.min.js"></script><script src="/js/highlight.fsharp.min.js"></script><script type="application/javascript">hljs.initHighlightingOnLoad();</script></body><footer><a rel="me" href="https://toot.lqdev.tech/@lqdev"></a></footer></html>