<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link rel="stylesheet" href="/css/bootstrap.min.css"><link rel="stylesheet" href="/css/bootstrap-icons-1.5.0/bootstrap-icons.css"><link rel="stylesheet" href="/css/highlight.github-dark-dimmed.min.css"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/css/customthemes.css"><meta property="og:title" content="llm - Tags - Luis Quintanilla"><meta property="og:type" content="website"><meta property="og:image" content="https://www.luisquintanilla.me/avatar.png"><meta property="og:image:secure_url" content="https://www.luisquintanilla.me/avatar.png"><meta property="og:image:type" content="image/png"><meta property="og:image:width" content="200"><meta property="og:image:height" content="200"><meta property="og:site_name" content="Luis Quintanilla Personal Website"><meta property="og:locale" content="en_US"><meta property="twitter:image" content="https://www.luisquintanilla.me/avatar.png"><meta property="fediverse:creator" content="@lqdev@toot.lqdev.tech"><link rel="alternate" type="application/rss+xml" title="Luis Quintanilla Blog RSS Feed" href="/blog.rss"><link rel="alternate" type="application/rss+xml" title="Luis Quintanilla Microblog RSS Feed" href="/microblog.rss"><link rel="alternate" type="application/rss+xml" title="Luis Quintanilla Response RSS Feed" href="/responses.rss"><link rel="webmention" title="Luis Quintanilla Webmention Endpoint" href="https://webmentions.lqdev.tech/api/inbox"><link rel="feeds" type="text/xml" title="Luis Quintanilla&#39;s Feeds" href="/feed/index.opml"><link rel="blogroll" type="text/xml" title="Luis Quintanilla&#39;s Blogroll" href="/feed/blogroll/index.opml"><link rel="podroll" type="text/xml" title="Luis Quintanilla&#39;s Podroll" href="/feed/podroll/index.opml"><link rel="youtuberoll" type="text/xml" title="Luis Quintanilla&#39;s YouTube Roll" href="/feed/youtube/index.opml"><meta name="robots" content="nosnippet"><title>llm - Tags - Luis Quintanilla</title></head><body><nav class="navbar navbar-expand-md navbar-dark fixed-top bg-dark"><a class="navbar-brand" href="/"><img src="/avatar.png" height="32" width="32" class="d-inline-block align-top rounded-circle" style="margin-right:5px" loading="lazy">Luis Quintanilla</a><button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarCollapse"><ul class="navbar-nav mr-auto"><li class="nav-item active"><a class="nav-link" href="/">Home</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href="#" id="aboutDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">About</a><div class="dropdown-menu" aria-labelledby="aboutDropdown"><a class="dropdown-item" href="/about">Profile</a><a class="dropdown-item" href="/contact">Contact</a><a class="dropdown-item" href="/uses">Uses</a><a class="dropdown-item" href="/colophon">Colophon</a></div></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href="#" id="feedDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Feeds</a><div class="dropdown-menu" aria-labelledby="feedDropdown"><a class="dropdown-item" href="/feed">Main</a><a class="dropdown-item" href="/feed/responses">Responses</a><a class="dropdown-item" href="/posts/1">Blog</a><div class="dropdown-divider"></div><a class="dropdown-item" href="/subscribe">Subscribe</a><div class="dropdown-divider"></div><a class="dropdown-item" href="/feed/starter">Starter Packs</a><div class="dropdown-divider"></div><a class="dropdown-item" href="/feed/blogroll">Blogroll</a><a class="dropdown-item" href="/feed/podroll">Podroll</a><a class="dropdown-item" href="/feed/forums">Forums</a><a class="dropdown-item" href="/feed/youtube">YouTube</a></div></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href="#" id="collectionDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Collections</a><div class="dropdown-menu" aria-labelledby="collectionDropdown"><a class="dropdown-item" href="/radio">Radio</a><a class="dropdown-item" href="/library">Books</a><a class="dropdown-item" href="/tags">Tags</a></div></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href="#" id="kbDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Knowledgebase</a><div class="dropdown-menu" aria-labelledby="kbDropdown"><a class="dropdown-item" href="/snippets">Snippets</a><a class="dropdown-item" href="/wiki">Wiki</a><a class="dropdown-item" href="/presentations">Presentations</a></div></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href="#" id="liveDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Live</a><div class="dropdown-menu" aria-labelledby="liveDropdown"><a class="dropdown-item" href="/live">Stream</a><a class="dropdown-item" href="/streams">Recordings</a></div></li><li class="nav-item"><a class="nav-link" href="/events">Events</a></li></ul><a href="/subscribe"><svg class="bi bi-rss text-secondary" fill="currentColor" viewBox="0 0 16 16" height="32" width="32"><path d="M14 1a1 1 0 0 1 1 1v12a1 1 0 0 1-1 1H2a1 1 0 0 1-1-1V2a1 1 0 0 1 1-1h12zM2 0a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V2a2 2 0 0 0-2-2H2z"></path><path d="M5.5 12a1.5 1.5 0 1 1-3 0 1.5 1.5 0 0 1 3 0zm-3-8.5a1 1 0 0 1 1-1c5.523 0 10 4.477 10 10a1 1 0 1 1-2 0 8 8 0 0 0-8-8 1 1 0 0 1-1-1zm0 4a1 1 0 0 1 1-1 6 6 0 0 1 6 6 1 1 0 1 1-2 0 4 4 0 0 0-4-4 1 1 0 0 1-1-1z"></path></svg></a></div></nav><main role="main" class="container"><div class="mr-auto"><h2>llm</h2><p>A list of posts tagged llm</p><h3>Blogs</h3><ul><li><a href="/posts/install-ollama-vscode-devcontainer">Configure Ollama on Dev Containers and VS Code</a></li><li><a href="/posts/getting-started-ollama-windows">Getting started with Ollama on Windows</a></li><li><a href="/posts/generative-ai-spotify-clips">Using Generative AI to produce Spotify Clips</a></li></ul><h3>Notes</h3><ul><li><a href="/feed/ollama-adds-support-mistral-small-3-1">Ollama Adds Mistral 3.1 Support</a></li><li><a href="/feed/love-plain-text-org-mode-clocktable">Clock Tables - Org Mode, Plain Text, and AI</a></li><li><a href="/feed/slm-too-big">These models are too damn big!</a></li><li><a href="/feed/genai-spotify-clips-instrumental">What about instrumentals? AI Generated Spotify Clips Addendum</a></li><li><a href="/feed/ai-abundance-scarcity-cycle-repeats-rss-enclosure-use-case">AI abundance after scarcity cycles</a></li></ul><h3>Responses</h3><ul><li><a href="/feed/self-adapting-language-models-seal">Self-Adapting Language Models (SEAL)</a></li><li><a href="/feed/zero-search-alibaba">ZeroSearch - Incentivize the Search Capability of LLMs without Searching</a></li><li><a href="/feed/llama-4-herd">The Llama 4 herd: The beginning of a new era of natively multimodal AI innovation</a></li><li><a href="/feed/introducing-command-a-cohere">Introducing Command A</a></li><li><a href="/feed/willison-tools-colophon">Simon Willison's AI-Generated Tools Colophon</a></li><li><a href="/feed/mercury-first-commercial-scale-llm">Introducing Mercury, the first commercial-scale diffusion large language model</a></li><li><a href="/feed/ultrascale-playbook-training-llms-gpu-clusters">The Ultra-Scale Playbook: Training LLMs on GPU Clusters</a></li><li><a href="/feed/illustrated-deepseek-r1">The Illustrated DeepSeek-R1</a></li><li><a href="/feed/langchain-state-of-ai-2024">LangChain State of AI 2024 Report</a></li><li><a href="/feed/introducing-drift-search">Microsoft Research: Introducing DRIFT Search</a></li><li><a href="/feed/thinking-llms-instruction-following-thought-generation">Thinking LLMs: General Instruction Following with Thought Generation</a></li><li><a href="/feed/meta-bringing-llama-3-to-life">Bringing Llama 3 to life</a></li><li><a href="/feed/gpt4o-system-card">GPT-4o System Card</a></li><li><a href="/feed/longrope-extending-llm-context-2m-tokens">LongROPE: Extending LLM Context Window Beyond 2 Million Tokens</a></li><li><a href="/feed/home-cooked-software-barefoot-developers-appleton">Home-Cooked Software and Barefoot Developers</a></li><li><a href="/feed/meta-llm-compiler">Meta Large Language Model Compiler: Foundation Models of Compiler Optimization</a></li><li><a href="/feed/mapping-mind-large-language-model-anthropic">Mapping the Mind of a Large Language Model</a></li><li><a href="/feed/ultravox-multimodal-llm">Ultravox - An open, fast, and extensible multimodal LLM</a></li><li><a href="/feed/repro-gpt-2-llm-c-90-min-20-dollars-karpathy">Reproducing GPT-2 (124M) in llm.c in 90 minutes for $20</a></li><li><a href="/feed/snowflake-arctic-enterprise-ai-llm">Introducing Snowflake Arctic</a></li><li><a href="/feed/introducing-phi-3">Introducing Phi-3</a></li><li><a href="/feed/introducing-llama-3">Introducing Llama 3</a></li><li><a href="/feed/griffin-mix-linear-recurrence-local-attention-language-models">Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models</a></li><li><a href="/feed/decop-detecting-copyright-llm-training-data">DE-COP: Detecting Copyrighted Content in Language Models Training Data</a></li><li><a href="/feed/llm-text-to-sql-right-candidates">Using LLM to select the right SQL Query from candidates</a></li><li><a href="/feed/google-deepmind-recurrent-gemma">RecurrentGemma - Open weights language model from Google DeepMind, based on Griffin.</a></li><li><a href="/feed/allen-ai-olmo-llm">Hello OLMo: A truly open LLM</a></li><li><a href="/feed/llm-c-karpathy">LLM training in simple, raw C/CUDA </a></li><li><a href="/feed/aragog-advanced-rag-output-grading">ARAGOG: Advanced RAG Output Grading</a></li><li><a href="/feed/openai-introducing-fine-tuning-improvements">OpenAI - Introducing improvements to the fine-tuning API and expanding our custom models program</a></li><li><a href="/feed/introducing-cohere-comandr-plus">Introducing Command R+: A Scalable LLM Built for Business</a></li><li><a href="/feed/llm-time-series-forecasting">Large Language Models Are Zero-Shot Time Series Forecasters</a></li><li><a href="/feed/intel-ipex-llm">IPEX-LLM</a></li><li><a href="/feed/start-using-chatgpt-seamlessly-no-signup">Start using ChatGPT instantly</a></li><li><a href="/feed/announcing-dbrx-llm">Announcing DBRX: A new standard for efficient open source LLMs</a></li><li><a href="/feed/mamba-linear-time-sequence-selective-state-spaces">Mamba: Linear-Time Sequence Modeling with Selective State Spaces</a></li><li><a href="/feed/common-corpus-llm-training-dataset">Releasing Common Corpus: the largest public domain dataset for training LLMs</a></li><li><a href="/feed/demistifying-embedding-spaces-llms">Demystifying Embedding Spaces using Large Language Models</a></li><li><a href="/feed/mm1-multimodal-llm-pretraining">MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training</a></li><li><a href="/feed/ollama-supports-amd-gpus">Ollama now supports AMD graphics cards</a></li><li><a href="/feed/answer-ai-train-70b-llm-at-home">You can now train a 70b language model at home</a></li><li><a href="/feed/levels-of-complexity-rag-applications">Levels of Complexity: RAG Applications</a></li><li><a href="/feed/inflection-2-5">Inflection-2.5: meet the world's best personal AI</a></li><li><a href="/feed/training-llms-ground-up-wilderness-startup">Training great LLMs entirely from ground up in the wilderness as a startup</a></li><li><a href="/feed/gemma-pytorch">Gemma PyTorch</a></li><li><a href="/feed/announcing-claude-3-model-family">Introducing the next generation of Claude</a></li><li><a href="/feed/gguf-long-way-around">GGUF, the long way around</a></li><li><a href="/feed/predictive-human-preference-model-ranking-routing">Predictive Human Preference: From Model Ranking to Model Routing</a></li><li><a href="/feed/era-1-bit-llms">The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits</a></li><li><a href="/feed/announcing-mistral-large">Announcing Mistral Large</a></li><li><a href="/feed/gpt-500-lines-sql">GPT in 500 lines of SQL</a></li><li><a href="/feed/gemma-google-ai-models">Gemma: Introducing new state-of-the-art open models</a></li><li><a href="/feed/cosmopedia-ai-synthetic-dataset">Cosmopedia v0.1</a></li><li><a href="/feed/ollama-windows-preview">Ollama - Windows Preview</a></li><li><a href="/feed/ms-research-graphrag">GraphRAG: Unlocking LLM discovery on narrative private data </a></li><li><a href="/feed/nvidia-chat-rtx">NVIDIA Chat with RTX</a></li><li><a href="/feed/openai-chatgpt-memory">Memory and new controls for ChatGPT</a></li><li><a href="/feed/eagle-7b-rkwv">Eagle 7B : Soaring past Transformers with 1 Trillion Tokens Across 100+ Languages (RWKV-v5)</a></li><li><a href="/feed/google-cloud-huggingface-deal">Googleâ€™s Hugging Face deal puts â€˜supercomputerâ€™ power behind open-source AI</a></li><li><a href="/feed/new-openai-text-embedding-models-3">New OpenAI embedding models and API updates</a></li><li><a href="/feed/nightshade-ai-model-poisoning-tool">NightShade</a></li><li><a href="/feed/introducing-stable-lm-2-1-6B">Introducing Stable LM 2 1.6B</a></li><li><a href="/feed/stable-code-3b-stability">Stable Code 3B - Coding on the Edge</a></li><li><a href="/feed/sampling-text-generation-huyen">Sampling for Text Generation</a></li><li><a href="/feed/talking-open-source-llms-oxide-friends-willison">Talking about Open Source LLMs on Oxide and Friends</a></li><li><a href="/feed/lefoverlocals-llm-responses-leaked-gpu-memory">LeftoverLocals: Listening to LLM responses through leaked GPU local memory</a></li><li><a href="/feed/ai-for-economists-prompts">AI for economists - prompts and resources</a></li><li><a href="/feed/perplexity-ai-pivots-open-source">More than an OpenAI Wrapper: Perplexity Pivots to Open Source</a></li><li><a href="/feed/ai-pipelines-sped-up-again-alexirpan">My AI Timelines Have Sped Up (Again)</a></li><li><a href="/feed/apple-ml-ferret">Ferret: Refer and Ground Anything Anywhere at Any Granularity</a></li><li><a href="/feed/langchain-state-of-ai-2023">LangChain State of AI 2023</a></li><li><a href="/feed/llm-flash-inference-limited-memory">LLM in a flash: Efficient Large Language Model Inference with Limited Memory</a></li><li><a href="/feed/openai-prompting-guide">OpenAI - Prompt engineering</a></li><li><a href="/feed/llamafile-llm-oneliners-tunney">Bash One-Liners for LLMs</a></li><li><a href="/feed/microsoft-phi-2">Phi-2: The surprising power of small language models</a></li><li><a href="/feed/introducing-stable-lm-zephyr-3b">Introducing Stable LM Zephyr 3B</a></li><li><a href="/feed/geometry-of-truth-data-explorer">The Geometry of Truth: Dataexplorer</a></li><li><a href="/feed/memgpt-llm-operating-system">MemGPT - Towards LLMs as Operating Systems</a></li><li><a href="/feed/best-practices-rag-application-evaluation-databricks">Best Practices for LLM Evaluation of RAG Applications</a></li><li><a href="/feed/mlflow-2-8-llm-as-judge-rag-evaluation">MLflow 2.8 with LLM-as-a-judge metrics and Best Practices for LLM Evaluation of RAG Applications</a></li><li><a href="/feed/openagents-platform-language-agents">OpenAgents: An Open Platform for Language Agents in the Wild</a></li><li><a href="/feed/mixtral-of-experts">Mixtral of experts</a></li><li><a href="/feed/claude-long-context-prompting">Long context prompting for Claude 2.1</a></li><li><a href="/feed/introducing-llamafile">Introducing llamafile</a></li><li><a href="/feed/chain-of-verification-prompting-technique">Chain-of-Verification Reduces Hallucination in Large Language Models</a></li><li><a href="/feed/scaffolded-llms-natural-language-computers">Scaffolded LLMs as natural language computers</a></li><li><a href="/feed/mistral-ai">Mistral 7B Model</a></li><li><a href="/feed/distilling-step-x-step-outperforming-large-models-small-data">Distilling step-by-step: Outperforming larger language models with less training data and smaller model sizes</a></li><li><a href="/feed/vim-llm-hacks-thacker">vim + llm = ðŸ”¥</a></li><li><a href="/feed/chatgpt-voice-image-capabilities">ChatGPT can now see, hear, and speak</a></li><li><a href="/feed/dall-e-3">DALLÂ·E 3</a></li><li><a href="/feed/optimizing-llm-production-hf">Optimizing your LLM in production </a></li><li><a href="/feed/point-llm-point-clouds">PointLLM: Empowering Large Language Models to Understand Point Clouds</a></li><li><a href="/feed/falcon-180b-announcement">Spread Your Wings: Falcon 180B is here </a></li><li><a href="/feed/generative-ai-dotnet-pt-2-powell">Generative AI and .NET - Part 2 SDK</a></li><li><a href="/feed/perplexity-interactive-llm-visualizations">Perplexity: Interactive LLM visualization</a></li><li><a href="/feed/can-llms-learn-single-example">Can LLMs learn from a single example?</a></li><li><a href="/feed/generative-ai-dotnet-pt-1-powell">Generative AI and .NET - Part 1 Intro</a></li><li><a href="/feed/web-llm-llama-2">Llama 2 7B/13B are now available in Web LLM</a></li><li><a href="/feed/supporting-open-source-ai-community-az">Supporting the Open Source AI Community</a></li><li><a href="/feed/making-llms-work-for-you-willison">Making Large Language Models Work For You</a></li><li><a href="/feed/meta-code-llama">Introducing Code Llama, a state-of-the-art large language model for coding</a></li><li><a href="/feed/llm-semantic-search-deeplearningai-course">Large Language Models with Semantic Search</a></li><li><a href="/feed/patterns-for-building-llm-systems-products-yan">Patterns for Building LLM-based Systems and Products</a></li><li><a href="/feed/open-challenges-llm-research-huyen">Open challenges in LLM research</a></li><li><a href="/feed/gpt-4-ga">GPT-4 API general availability</a></li><li><a href="/feed/gorilla-apis-llm">Gorilla: Large Language Model Connected with Massive APIs</a></li><li><a href="/feed/microsoft-lora-llm">LoRA: Low-Rank Adaptation of Large Language Models</a></li><li><a href="/feed/large-language-models-explain-neural-network-neurons">Language models can explain neurons in language models</a></li><li><a href="/feed/free-dolly-llm">Free Dolly</a></li><li><a href="/feed/llm-generative-agents">Generative Agents: Interactive Simulacra of Human Behavior</a></li><li><a href="/feed/koala-dialogue-model">Koala: A Dialogue Model for Academic Research</a></li></ul></div></main><script src="/lib/jquery/jquery.slim.min.js"></script><script src="/lib/boostrap/bootstrap.min.js"></script><script src="/lib/highlight/highlight.min.js"></script><script src="/lib/highlight/highlight.fsharp.min.js"></script><script src="/lib/highlight/highlight.nix.min.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script><script type="application/javascript">mermaid.initialize({startOnLoad:true});</script><script type="application/javascript">hljs.initHighlightingOnLoad();</script></body><footer><a rel="me" href="https://toot.lqdev.tech/@lqdev"></a><a rel="me" href="https://github.com/lqdev"></a><a rel="me" href="https://twitter.com/ljquintanilla"></a><a rel="me" href="https://www.linkedin.com/in/lquintanilla01/"></a><a rel="me" href="mailto:lqdev@outlook.com"></a></footer></html>