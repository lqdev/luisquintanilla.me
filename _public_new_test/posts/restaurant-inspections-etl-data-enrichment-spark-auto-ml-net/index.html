<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link rel="stylesheet" href="/css/bootstrap.min.css"><link rel="stylesheet" href="/css/bootstrap-icons-1.5.0/bootstrap-icons.css"><link rel="stylesheet" href="/css/highlight.github-dark-dimmed.min.css"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/css/customthemes.css"><meta property="og:title" content="Restaurant Inspections ETL &amp; Data Enrichment with Spark.NET and ML.NET Automated (Auto) ML - Luis Quintanilla"><meta property="og:type" content="website"><meta property="og:image" content="https://www.luisquintanilla.me/avatar.png"><meta property="og:image:secure_url" content="https://www.luisquintanilla.me/avatar.png"><meta property="og:image:type" content="image/png"><meta property="og:image:width" content="200"><meta property="og:image:height" content="200"><meta property="og:site_name" content="Luis Quintanilla Personal Website"><meta property="og:locale" content="en_US"><meta property="twitter:image" content="https://www.luisquintanilla.me/avatar.png"><meta property="fediverse:creator" content="@lqdev@toot.lqdev.tech"><link rel="alternate" type="application/rss+xml" title="Luis Quintanilla Blog RSS Feed" href="/blog.rss"><link rel="alternate" type="application/rss+xml" title="Luis Quintanilla Microblog RSS Feed" href="/microblog.rss"><link rel="alternate" type="application/rss+xml" title="Luis Quintanilla Response RSS Feed" href="/responses.rss"><link rel="webmention" title="Luis Quintanilla Webmention Endpoint" href="https://webmentions.lqdev.tech/api/inbox"><link rel="feeds" type="text/xml" title="Luis Quintanilla&#39;s Feeds" href="/feed/index.opml"><link rel="blogroll" type="text/xml" title="Luis Quintanilla&#39;s Blogroll" href="/feed/blogroll/index.opml"><link rel="podroll" type="text/xml" title="Luis Quintanilla&#39;s Podroll" href="/feed/podroll/index.opml"><link rel="youtuberoll" type="text/xml" title="Luis Quintanilla&#39;s YouTube Roll" href="/feed/youtube/index.opml"><meta name="robots" content="nosnippet"><title>Restaurant Inspections ETL & Data Enrichment with Spark.NET and ML.NET Automated (Auto) ML - Luis Quintanilla</title></head><body><nav class="navbar navbar-expand-md navbar-dark fixed-top bg-dark"><a class="navbar-brand" href="/"><img src="/avatar.png" height="32" width="32" class="d-inline-block align-top rounded-circle" style="margin-right:5px" loading="lazy">Luis Quintanilla</a><button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarCollapse"><ul class="navbar-nav mr-auto"><li class="nav-item active"><a class="nav-link" href="/">Home</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href="#" id="aboutDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">About</a><div class="dropdown-menu" aria-labelledby="aboutDropdown"><a class="dropdown-item" href="/about">Profile</a><a class="dropdown-item" href="/contact">Contact</a><a class="dropdown-item" href="/uses">Uses</a><a class="dropdown-item" href="/colophon">Colophon</a></div></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href="#" id="feedDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Feeds</a><div class="dropdown-menu" aria-labelledby="feedDropdown"><a class="dropdown-item" href="/feed">Main</a><a class="dropdown-item" href="/feed/responses">Responses</a><a class="dropdown-item" href="/posts/1">Blog</a><div class="dropdown-divider"></div><a class="dropdown-item" href="/subscribe">Subscribe</a><div class="dropdown-divider"></div><a class="dropdown-item" href="/feed/starter">Starter Packs</a><div class="dropdown-divider"></div><a class="dropdown-item" href="/feed/blogroll">Blogroll</a><a class="dropdown-item" href="/feed/podroll">Podroll</a><a class="dropdown-item" href="/feed/forums">Forums</a><a class="dropdown-item" href="/feed/youtube">YouTube</a></div></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href="#" id="collectionDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Collections</a><div class="dropdown-menu" aria-labelledby="collectionDropdown"><a class="dropdown-item" href="/radio">Radio</a><a class="dropdown-item" href="/library">Books</a><a class="dropdown-item" href="/tags">Tags</a></div></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href="#" id="kbDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Knowledgebase</a><div class="dropdown-menu" aria-labelledby="kbDropdown"><a class="dropdown-item" href="/snippets">Snippets</a><a class="dropdown-item" href="/wiki">Wiki</a><a class="dropdown-item" href="/presentations">Presentations</a></div></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href="#" id="liveDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Live</a><div class="dropdown-menu" aria-labelledby="liveDropdown"><a class="dropdown-item" href="/live">Stream</a><a class="dropdown-item" href="/streams">Recordings</a></div></li><li class="nav-item"><a class="nav-link" href="/events">Events</a></li></ul><a href="/subscribe"><svg class="bi bi-rss text-secondary" fill="currentColor" viewBox="0 0 16 16" height="32" width="32"><path d="M14 1a1 1 0 0 1 1 1v12a1 1 0 0 1-1 1H2a1 1 0 0 1-1-1V2a1 1 0 0 1 1-1h12zM2 0a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V2a2 2 0 0 0-2-2H2z"></path><path d="M5.5 12a1.5 1.5 0 1 1-3 0 1.5 1.5 0 0 1 3 0zm-3-8.5a1 1 0 0 1 1-1c5.523 0 10 4.477 10 10a1 1 0 1 1-2 0 8 8 0 0 0-8-8 1 1 0 0 1-1-1zm0 4a1 1 0 0 1 1-1 6 6 0 0 1 6 6 1 1 0 1 1-2 0 4 4 0 0 0-4-4 1 1 0 0 1-1-1z"></path></svg></a></div></nav><main role="main" class="container"><div class="mr-auto"><h1>Restaurant Inspections ETL & Data Enrichment with Spark.NET and ML.NET Automated (Auto) ML</h1><h2>Introduction</h2>
<p>Apache Spark is an open-source, distributed, general-purpose analytics engine. For years, it has been a staple in the Big Data ecosystem for batch and real-time processing on large datasets. Although native support for the platform is limited to the JVM set of languages, other languages typically used for data processing and analytics like Python and R have plugged into Spark's Interop layer to make use of its functionality. Around the Build 2019 conference, Microsoft announced Spark.NET. Spark.NET provides bindings written for the Spark Interop layer that allow you to work with components like Spark SQL and Spark Streaming inside your .NET applications. Because Spark.NET is .NET Standard 2.0 compliant, it can run operating systems like Windows, Mac and Linux. Spark.NET is an evolution of the Mobius project which provided .NET bindings for Spark.</p>
<p>This sample takes a restaurant violation dataset from the NYC Open Data portal and processes it using Spark.NET. Then, the processed data is used to train a machine learning model that attempts to predict the grade an establishment will receive after an inspection. The model will be trained using ML.NET, an open-source, cross-platform machine learning framework. Finally, data for which no grade currently exists will be enriched using the trained model to assign an expected grade.</p>
<p>The source code for this sample can be found in the <a href="https://github.com/lqdev/RestaurantInspectionsSparkMLNET">lqdev/RestaurantInspectionsSparkMLNET
GitHub repo</a>.</p>
<h2>Pre-requisites</h2>
<p>This project was built using Ubuntu 18.04 but should work on Windows and Mac devices.</p>
<ul>
<li><a href="https://dotnet.microsoft.com/download/dotnet-core/2.1">.NET Core 2.1 SDK</a></li>
<li><a href="https://www.java.com/en/download/">Java 8</a></li>
<li><a href="https://archive.apache.org/dist/spark/spark-2.4.1/">Apache Spark 2.4.1 with Hadoop 2.7</a></li>
<li><a href="https://github.com/dotnet/spark/releases">.NET Spark Worker 0.4.0</a></li>
</ul>
<h3>Install Java</h3>
<p>Since Spark runs on the JVM, you'll need Java on your PC. The minimum version required is version 8. To install and Java, enter the following command into the terminal:</p>
<pre><code class="language-bash">sudo apt install openjdk-8-jdk openjdk-8-jre
</code></pre>
<p>Then, make sure that the recently installed version is the default</p>
<pre><code class="language-bash">sudo update-alternatives --config java
</code></pre>
<h3>Download and configure Spark</h3>
<p>Download Spark 2.4.1 with Hadoop 2.7 onto your computer. In this case, I'm placing it into my <em>Downloads</em> folder.</p>
<pre><code class="language-bash">wget https://archive.apache.org/dist/spark/spark-2.4.1/spark-2.4.1-bin-hadoop2.7.tgz -O ~/Downloads/spark-2.4.1-bin-hadoop2.7.tgz
</code></pre>
<p>Extract the contents of the recently downloaded file into the <em>/usr/bin/local</em> directory.</p>
<pre><code class="language-bash">sudo tar -xvf ~/Downloads/spark-2.4.1-bin-hadoop2.7.tgz --directory /usr/local/bin
</code></pre>
<h3>Download and configure .NET Spark Worker</h3>
<p>Download the .NET Spark worker onto your computer. In this case, I'm placing it into the <em>Downloads</em> folder.</p>
<pre><code class="language-bash">wget https://github.com/dotnet/spark/releases/download/v0.4.0/Microsoft.Spark.Worker.netcoreapp2.1.linux-x64-0.4.0.tar.gz -O ~/Downloads/Microsoft.Spark.Worker.netcoreapp2.1.linux-x64-0.4.0.tar.gz
</code></pre>
<p>Extract the contents of the recently downloaded file into the <em>/usr/bin/local</em> directory.</p>
<pre><code class="language-bash">sudo tar -xvf ~/Downloads/Microsoft.Spark.Worker.netcoreapp2.1.linux-x64-0.4.0.tar.gz --directory /usr/local/bin
</code></pre>
<p>Finally, raise the permissions on the <code>Microsoft.Spark.Worker</code> program. This is required to execute User-Defined Functions (UDF).</p>
<pre><code class="language-bash">sudo chmod +x /usr/local/bin/Microsoft.Spark.Worker-0.4.0/Microsoft.Spark.Worker
</code></pre>
<h3>Configure environment variables</h3>
<p>Once you download and configure the pre-requisites, configure their locations in the system as environment variables. Open the <em>~/.bashrc</em> file and add the following content at the end of the file.</p>
<pre><code class="language-bash">export SPARK_PATH=/usr/local/bin/spark-2.4.1-bin-hadoop2.7
export PATH=$SPARK_PATH/bin:$PATH
export HADOOP_HOME=$SPARK_PATH
export SPARK_HOME=$SPARK_PATH
export DOTNET_WORKER_DIR=/usr/local/bin/Microsoft.Spark.Worker-0.4.0
</code></pre>
<h2>Solution description</h2>
<h3>Understand the data</h3>
<p>The dataset used in this solution is the <a href="https://data.cityofnewyork.us/Health/DOHMH-New-York-City-Restaurant-Inspection-Results/43nn-pn8j"><em>DOHMH New York City Restaurant Inspection Results</em></a> and comes from the NYC Open Data portal. It is updated daily and contains assigned and pending inspection results and violation citations for restaurants and college cafeterias. The dataset excludes establishments that have gone out of business. Although the dataset contains several columns, only a subset of them are used in this solution. For a detailed description of the dataset, visit the dataset website.</p>
<h3>Understand the solution</h3>
<p>This solution is made up of four different .NET Core applications:</p>
<ul>
<li><em>RestaurantInspectionsETL</em>: .NET Core Console application that takes raw data and uses Spark.NET to clean and transform the data into a format that is easier to use as input for training and making predictions with a machine learning model built with ML.NET.</li>
<li><em>RestaurantInspectionsML</em>: .NET Core Class Library that defines the input and output schema of the ML.NET machine learning model. Additionally, this is where the trained model is saved to.</li>
<li><em>RestaurantInspectionsTraining</em>: .NET Core Console application that uses the graded data generated by the <em>RestaurantInspectionsETL</em> application to train a multiclass classification machine learning model using ML.NET's Auto ML.</li>
<li><em>RestaurantInspectionsEnrichment</em>: .NET Core Console application that uses the ungraded data generated by the <em>RestaurantInspectionsETL</em> application as input for the trained ML.NET machine learning model which predicts what grade an establishment is most likely to receive based on the violations found during inspection.</li>
</ul>
<h2>Set up the solution</h2>
<h3>Create solution directory</h3>
<p>Create a new directory for your projects called <em>RestaurantInspectionsSparkMLNET</em> and navigate to it with the following command.</p>
<pre><code class="language-bash">mkdir RestaurantInspectionsSparkMLNET &amp;&amp; cd RestaurantInspectionsSparkMLNET
</code></pre>
<p>Then, create a solution using the <code>dotnet cli</code>.</p>
<pre><code class="language-bash">dotnet new sln
</code></pre>
<p>To ensure that the 2.1 version of the .NET Core SDK is used as the target framework, especially if you have multiple versions of the .NET SDK installed, create a file called <em>globals.json</em> in the <em>RestaurantInspectionsSparkMLNET</em> solution directory.</p>
<pre><code class="language-bash">touch global.json
</code></pre>
<p>In the <em>global.json</em> file, add the following content. Make sure to use the specific version of the SDK installed on your computer. In this case, I have version <code>2.1.801</code> installed on my computer. You can use the <code>dotnet --list-sdks</code> command to list the installed SDK versions.</p>
<pre><code class="language-json">{
  &quot;sdk&quot;: {
    &quot;version&quot;: &quot;2.1.801&quot;
  }
}
</code></pre>
<h3>Create and configure the ETL project</h3>
<p>The ETL project is responsible for taking the raw source data and using Spark to apply a series of transformations to prepare the data to train the machine learning model as well as to enrich data with missing grades.</p>
<p>Inside the <em>RestaurantInspectionsSparkMLNET</em> solution directory, create a new console application called <em>RestaurantInspectionsETL</em> using the <code>dotnet cli</code>.</p>
<pre><code class="language-bash">dotnet new console -o RestaurantInspectionsETL
</code></pre>
<p>Add the newly created project to the solution with the <code>dotnet cli</code>.</p>
<pre><code class="language-bash">dotnet sln add ./RestaurantInspectionsETL/
</code></pre>
<p>Since this project uses the <code>Microsoft.Spark</code> NuGet package, use the <code>dotnet cli</code> to install it.</p>
<pre><code class="language-bash">dotnet add ./RestaurantInspectionsETL/ package Microsoft.Spark --version 0.4.0
</code></pre>
<h3>Create and configure the ML model project</h3>
<p>The ML model class library will contain the domain model that defines the schema of model inputs and outputs as well as the trained model itself.</p>
<p>Inside the <em>RestaurantInspectionsSparkMLNET</em> solution directory, create a new class library called <em>RestaurantInspectionsML</em> using the <code>dotnet cli</code>.</p>
<pre><code class="language-bash">dotnet new classlib -o RestaurantInspectionsML
</code></pre>
<p>Add the newly created project to the solution with the <code>dotnet cli</code>.</p>
<pre><code class="language-bash">dotnet sln add ./RestaurantInspectionsML/
</code></pre>
<p>Since this project uses the <code>Microsoft.ML</code> NuGet package, use the <code>dotnet cli</code> to install it.</p>
<pre><code class="language-bash">dotnet add ./RestaurantInspectionsML/ package Microsoft.ML --version 1.3.1
</code></pre>
<h3>Create and configure the ML training project</h3>
<p>The purpose of the training project is to use the pre-processed graded data output by the <em>RestaurantInspectionsETL</em> project as input to train a multiclass classification model with ML.NET's Auto ML API. The trained model will then be saved in the <em>RestaurantInspectionsML</em> directory.</p>
<p>Inside the <em>RestaurantInspectionsSparkMLNET</em> solution directory, create a new console application called <em>RestaurantInspectionsTraining</em> using the <code>dotnet cli</code>.</p>
<pre><code class="language-bash">dotnet new console -o RestaurantInspectionsTraining
</code></pre>
<p>Add the newly created project to the solution with the <code>dotnet cli</code>.</p>
<pre><code class="language-bash">dotnet sln add ./RestaurantInspectionsTraining/
</code></pre>
<p>This project depends on the domain model created in the <em>RestaurantInspectionsML</em> project, so you need to add a reference to it.</p>
<pre><code class="language-bash">dotnet add ./RestaurantInspectionsTraining/ reference ./RestaurantInspectionsML/
</code></pre>
<p>Since this project uses the <code>Microsoft.Auto.ML</code> NuGet package, use the <code>dotnet cli</code> to install it.</p>
<pre><code class="language-bash">dotnet add ./RestaurantInspectionsTraining/ package Microsoft.ML.AutoML --version 0.15.1
</code></pre>
<h3>Create and configure the data enrichment project</h3>
<p>The data enrichment application uses the trained machine learning model created by the <em>RestaurantInspectionsTraining</em> application and use it on the pre-processed ungraded data created by the <em>RestaurantInspectionsETL</em> application to predict what grade that establishment is most likely to receive based on the violations found during inspection.</p>
<p>Inside the <em>RestaurantInspectionsSparkMLNET</em> solution directory, create a new console application called <em>RestaurantInspectionsEnrichment</em> using the <code>dotnet cli</code>.</p>
<pre><code class="language-bash">dotnet new console -o RestaurantInspectionsEnrichment
</code></pre>
<p>Add the newly created project to the solution with the <code>dotnet cli</code>.</p>
<pre><code class="language-bash">dotnet sln add ./RestaurantInspectionsEnrichment/
</code></pre>
<p>This project depends on the domain model created in the <em>RestaurantInspectionsML</em> project, so you need to add a reference to it.</p>
<pre><code class="language-bash">dotnet add ./RestaurantInspectionsEnrichment/ reference ./RestaurantInspectionsML/
</code></pre>
<p>This uses the following NuGet packages:</p>
<ul>
<li>Microsoft.Spark</li>
<li>Microsoft.ML.LightGBM (This is not required but predictions may fail if the final model is a LightGBM model).</li>
</ul>
<p>Install the packages with the following commands:</p>
<pre><code class="language-bash">dotnet add ./RestaurantInspectionsEnrichment/ package Microsoft.Spark --version 0.4.0
dotnet add ./RestaurantInspectionsEnrichment/ package Microsoft.ML.LightGBM --version 1.3.1
</code></pre>
<h2>Build ETL application</h2>
<p>The first step is to prepare the data. To do so, apply a set of transformations using Spark.NET.</p>
<h3>Download the data</h3>
<p>Navigate to the <em>RestaurantInspectionsETL</em> project and create a <em>Data</em> directory.</p>
<pre><code class="language-bash">mkdir Data
</code></pre>
<p>Then, download the data into the newly created <em>Data</em> directory.</p>
<pre><code class="language-bash">wget https://data.cityofnewyork.us/api/views/43nn-pn8j/rows.csv?accessType=DOWNLOAD -O Data/NYC-Restaurant-Inspections.csv
</code></pre>
<h3>Build the ETL pipeline</h3>
<p>Add the following usings to the <em>Program.cs</em> file.</p>
<pre><code class="language-csharp">using System;
using System.IO;
using Microsoft.Spark.Sql;
using static Microsoft.Spark.Sql.Functions;
</code></pre>
<p>Not all of the columns are relevant. Inside the <code>Main</code> method of the <em>Program.cs</em> file, define the columns to be removed.</p>
<pre><code class="language-csharp">string[] dropCols = new string[]
{
    &quot;CAMIS&quot;,
    &quot;CUISINE DESCRIPTION&quot;,
    &quot;VIOLATION DESCRIPTION&quot;,
    &quot;BORO&quot;,
    &quot;BUILDING&quot;,
    &quot;STREET&quot;,
    &quot;ZIPCODE&quot;,
    &quot;PHONE&quot;,
    &quot;ACTION&quot;,
    &quot;GRADE DATE&quot;,
    &quot;RECORD DATE&quot;,
    &quot;Latitude&quot;,
    &quot;Longitude&quot;,
    &quot;Community Board&quot;,
    &quot;Council District&quot;,
    &quot;Census Tract&quot;,
    &quot;BIN&quot;,
    &quot;BBL&quot;,
    &quot;NTA&quot;
};
</code></pre>
<p>The entrypoint of Spark applications is the <code>SparkSession</code>. Create <code>SparkSession</code> inside the <code>Main</code> method of the <em>Program.cs</em> file.</p>
<pre><code class="language-csharp">var sc =
    SparkSession
        .Builder()
        .AppName(&quot;Restaurant_Inspections_ETL&quot;)
        .GetOrCreate();
</code></pre>
<p>Then, load the data stored in the <em>NYC-Restaurant-Inspections.csv</em> file into a <code>DataFrame</code>.</p>
<pre><code class="language-csharp">DataFrame df =
    sc
    .Read()
    .Option(&quot;header&quot;, &quot;true&quot;)
    .Option(&quot;inferSchema&quot;, &quot;true&quot;)
    .Csv(&quot;Data/NYC-Restaurant-Inspections.csv&quot;);
</code></pre>
<p><code>DataFrames</code> can be thought of as tables in a database or sheets in Excel. Spark has various ways of representing data but <code>DataFrames</code> are the format supported by Spark.NET. Additionally, the <code>DataFrame</code> API is higher-level and easier to work with.</p>
<p>Once the data is loaded, get rid of the data that are not needed by creating a new <code>DataFrame</code> that excludes the <code>dropCols</code> as well as missing values.</p>
<pre><code class="language-csharp">DataFrame cleanDf =
    df
        .Drop(dropCols)
        .WithColumnRenamed(&quot;INSPECTION DATE&quot;,&quot;INSPECTIONDATE&quot;)
        .WithColumnRenamed(&quot;INSPECTION TYPE&quot;,&quot;INSPECTIONTYPE&quot;)
        .WithColumnRenamed(&quot;CRITICAL FLAG&quot;,&quot;CRITICALFLAG&quot;)
        .WithColumnRenamed(&quot;VIOLATION CODE&quot;,&quot;VIOLATIONCODE&quot;)
        .Na()
        .Drop();
</code></pre>
<p>Typically, machine learning models expect values to be numerical, so in the ETL step try to convert as many values as possible into numerical values. The <code>CRITICALFLAG</code> column contains &quot;Y&quot;/&quot;N&quot; values that can be encoded as 0 and 1.</p>
<pre><code class="language-csharp">DataFrame labeledFlagDf =
    cleanDf
        .WithColumn(&quot;CRITICALFLAG&quot;,
            When(Functions.Col(&quot;CRITICALFLAG&quot;) == &quot;Y&quot;,1)
            .Otherwise(0));
</code></pre>
<p>This dataset contains one violation per row which correspond to different inspections. Therefore, all of the violations need to be aggregated by business and inspection.</p>
<pre><code class="language-csharp">DataFrame groupedDf =
    labeledFlagDf
        .GroupBy(&quot;DBA&quot;, &quot;INSPECTIONDATE&quot;, &quot;INSPECTIONTYPE&quot;, &quot;CRITICALFLAG&quot;, &quot;SCORE&quot;, &quot;GRADE&quot;)
        .Agg(Functions.CollectSet(Functions.Col(&quot;VIOLATIONCODE&quot;)).Alias(&quot;CODES&quot;))
        .Drop(&quot;DBA&quot;, &quot;INSPECTIONDATE&quot;)
        .WithColumn(&quot;CODES&quot;, Functions.ArrayJoin(Functions.Col(&quot;CODES&quot;), &quot;,&quot;))
        .Select(&quot;INSPECTIONTYPE&quot;, &quot;CODES&quot;, &quot;CRITICALFLAG&quot;, &quot;SCORE&quot;, &quot;GRADE&quot;);  
</code></pre>
<p>Now that the data is in the format used to train and make predictions, split the cleaned <code>DataFrame</code> into two new <code>DataFrames</code>, graded and ungraded. The graded dataset is the data used for training the machine learning model. The ungraded data will be used for enrichment.</p>
<pre><code class="language-csharp">DataFrame gradedDf =
    groupedDf
    .Filter(
        Col(&quot;GRADE&quot;) == &quot;A&quot; |
        Col(&quot;GRADE&quot;) == &quot;B&quot; |
        Col(&quot;GRADE&quot;) == &quot;C&quot; );

DataFrame ungradedDf =
    groupedDf
    .Filter(
        Col(&quot;GRADE&quot;) != &quot;A&quot; &amp;
        Col(&quot;GRADE&quot;) != &quot;B&quot; &amp;
        Col(&quot;GRADE&quot;) != &quot;C&quot; );  
</code></pre>
<p>Take the <code>DataFrames</code> and save them as csv files for later use.</p>
<pre><code class="language-csharp">var timestamp = ((DateTimeOffset) DateTime.UtcNow).ToUnixTimeSeconds().ToString();

var saveDirectory = Path.Join(&quot;Output&quot;,timestamp);

if(!Directory.Exists(saveDirectory))
{
    Directory.CreateDirectory(saveDirectory);
}

gradedDf.Write().Csv(Path.Join(saveDirectory,&quot;Graded&quot;));

ungradedDf.Write().Csv(Path.Join(saveDirectory,&quot;Ungraded&quot;));
</code></pre>
<h3>Publish and run the ETL application</h3>
<p>The final <em>Program.cs</em> file should look as follows:</p>
<pre><code class="language-csharp">using System;
using System.IO;
using Microsoft.Spark.Sql;
using static Microsoft.Spark.Sql.Functions;

namespace RestaurantInspectionsETL
{
    class Program
    {
        static void Main(string[] args)
        {
            // Define columns to remove
            string[] dropCols = new string[]
            {
                &quot;CAMIS&quot;,
                &quot;CUISINE DESCRIPTION&quot;,
                &quot;VIOLATION DESCRIPTION&quot;,
                &quot;BORO&quot;,
                &quot;BUILDING&quot;,
                &quot;STREET&quot;,
                &quot;ZIPCODE&quot;,
                &quot;PHONE&quot;,
                &quot;ACTION&quot;,
                &quot;GRADE DATE&quot;,
                &quot;RECORD DATE&quot;,
                &quot;Latitude&quot;,
                &quot;Longitude&quot;,
                &quot;Community Board&quot;,
                &quot;Council District&quot;,
                &quot;Census Tract&quot;,
                &quot;BIN&quot;,
                &quot;BBL&quot;,
                &quot;NTA&quot;
            };

            // Create SparkSession
            var sc =
                SparkSession
                    .Builder()
                    .AppName(&quot;Restaurant_Inspections_ETL&quot;)
                    .GetOrCreate();

            // Load data
            DataFrame df =
                sc
                .Read()
                .Option(&quot;header&quot;, &quot;true&quot;)
                .Option(&quot;inferSchema&quot;, &quot;true&quot;)
                .Csv(&quot;Data/NYC-Restaurant-Inspections.csv&quot;);

            //Remove columns and missing values
            DataFrame cleanDf =
                df
                    .Drop(dropCols)
                    .WithColumnRenamed(&quot;INSPECTION DATE&quot;,&quot;INSPECTIONDATE&quot;)
                    .WithColumnRenamed(&quot;INSPECTION TYPE&quot;,&quot;INSPECTIONTYPE&quot;)
                    .WithColumnRenamed(&quot;CRITICAL FLAG&quot;,&quot;CRITICALFLAG&quot;)
                    .WithColumnRenamed(&quot;VIOLATION CODE&quot;,&quot;VIOLATIONCODE&quot;)
                    .Na()
                    .Drop();

            // Encode CRITICAL FLAG column
            DataFrame labeledFlagDf =
                cleanDf
                    .WithColumn(&quot;CRITICALFLAG&quot;,
                        When(Functions.Col(&quot;CRITICALFLAG&quot;) == &quot;Y&quot;,1)
                        .Otherwise(0));

             // Aggregate violations by business and inspection
            DataFrame groupedDf =
                labeledFlagDf
                    .GroupBy(&quot;DBA&quot;, &quot;INSPECTIONDATE&quot;, &quot;INSPECTIONTYPE&quot;, &quot;CRITICALFLAG&quot;, &quot;SCORE&quot;, &quot;GRADE&quot;)
                    .Agg(Functions.CollectSet(Functions.Col(&quot;VIOLATIONCODE&quot;)).Alias(&quot;CODES&quot;))
                    .Drop(&quot;DBA&quot;, &quot;INSPECTIONDATE&quot;)
                    .WithColumn(&quot;CODES&quot;, Functions.ArrayJoin(Functions.Col(&quot;CODES&quot;), &quot;,&quot;))
                    .Select(&quot;INSPECTIONTYPE&quot;, &quot;CODES&quot;, &quot;CRITICALFLAG&quot;, &quot;SCORE&quot;, &quot;GRADE&quot;);

            // Split into graded and ungraded DataFrames
            DataFrame gradedDf =
                groupedDf
                .Filter(
                    Col(&quot;GRADE&quot;) == &quot;A&quot; |
                    Col(&quot;GRADE&quot;) == &quot;B&quot; |
                    Col(&quot;GRADE&quot;) == &quot;C&quot; );

            DataFrame ungradedDf =
                groupedDf
                    .Filter(
                        Col(&quot;GRADE&quot;) != &quot;A&quot; &amp;
                        Col(&quot;GRADE&quot;) != &quot;B&quot; &amp;
                        Col(&quot;GRADE&quot;) != &quot;C&quot; );

            // Save DataFrames
            var timestamp = ((DateTimeOffset) DateTime.UtcNow).ToUnixTimeSeconds().ToString();

            var saveDirectory = Path.Join(&quot;Output&quot;,timestamp);

            if(!Directory.Exists(saveDirectory))
            {
                Directory.CreateDirectory(saveDirectory);
            }

            gradedDf.Write().Csv(Path.Join(saveDirectory,&quot;Graded&quot;));

            ungradedDf.Write().Csv(Path.Join(saveDirectory,&quot;Ungraded&quot;));
        }
    }
}
</code></pre>
<p>Publish the application with the following command.</p>
<pre><code class="language-bash">dotnet publish -f netcoreapp2.1 -r ubuntu.18.04-x64
</code></pre>
<p>Run the application with <code>spark-submit</code>.</p>
<pre><code class="language-bash">spark-submit --class org.apache.spark.deploy.dotnet.DotnetRunner --master local bin/Debug/netcoreapp2.1/ubuntu.18.04-x64/publish/microsoft-spark-2.4.x-0.4.0.jar dotnet bin/Debug/netcoreapp2.1/ubuntu.18.04-x64/publish/RestaurantInspectionsETL.dll
</code></pre>
<h2>Build ML Domain</h2>
<h3>Define the model input schema</h3>
<p>Navigate to the <em>RestaurantInspectionsTraining</em> project directory and create a new file called <em>ModelInput.cs</em>.</p>
<pre><code class="language-bash">touch ModelInput.cs
</code></pre>
<p>Open the <em>ModelInput.cs</em> file and add the following code.</p>
<pre><code class="language-csharp">using Microsoft.ML.Data;

namespace RestaurantInspectionsML
{
    public class ModelInput
    {
        [LoadColumn(0)]
        public string InspectionType { get; set; }

        [LoadColumn(1)]
        public string Codes { get; set; }

        [LoadColumn(2)]
        public float CriticalFlag { get; set; }

        [LoadColumn(3)]
        public float InspectionScore { get; set; }

        [LoadColumn(4)]
        [ColumnName(&quot;Label&quot;)]
        public string Grade { get; set; }
    }
}
</code></pre>
<p>Using attributes in the schema, five properties are defined:</p>
<ul>
<li>InspectionType: The type of inspection performed.</li>
<li>Codes: Violation codes found during inspection.</li>
<li>CriticalFlag: Indicates if any of the violations during the inspection were critical (contribute to food-borne illness).</li>
<li>InspectionScore: Score assigned after inspection.</li>
<li>Grade: Letter grade assigned after inspection</li>
</ul>
<p>The <code>LoadColumn</code> attribute defines the position of the column in the file. Data in the last column is assigned to the <code>Grade</code> property but is then referenced as <code>Label</code> in the <code>IDataView</code>. The reason for using the <code>ColumnName</code> attribute is ML.NET algorithms have default column names and renaming properties at the schema class level removes the need to define the feature and label columns as parameters in the training pipeline.</p>
<h3>Define the model output schema</h3>
<p>In the <em>RestaurantInspectionsTraining</em> project directory and create a new file called <em>ModelOutput.cs</em>.</p>
<pre><code class="language-bash">touch ModelOutput.cs
</code></pre>
<p>Open the <em>ModelOutput.cs</em> file and add the following code.</p>
<pre><code class="language-csharp">namespace RestaurantInspectionsML
{
    public class ModelOutput
    {
        public float[] Scores { get; set; }
        public string PredictedLabel { get; set; }
    }
}
</code></pre>
<p>For the output schema, the <code>ModelOutput</code> class uses properties with the default column names of the outputs generated by the model training process:</p>
<ul>
<li>Scores: A float vector containing the probabilties for all the predicted classes.</li>
<li>PredictedLabel: The value of the prediction. In this case, the <code>PredictedLabel</code> is the predicted grade expected to be assigned after inspection given the set of features for that inspection.</li>
</ul>
<h2>Build the model training application</h2>
<p>The application trains a multiclass classification algorithm. Finding the &quot;best&quot; algorithm with the right parameters requires experimentation. Fortunately, ML.NET's Auto ML does this for you given you provide it with the type of algorithm you want to train.</p>
<h3>Load the graded data</h3>
<p>Navigate to the <em>RestaurantInspectionsTraining</em> project directory and add the following using statements to the <em>Program.cs</em> class.</p>
<pre><code class="language-csharp">using System;
using System.IO;
using System.Linq;
using Microsoft.ML;
using static Microsoft.ML.DataOperationsCatalog;
using Microsoft.ML.AutoML;
using RestaurantInspectionsML;
</code></pre>
<p>Inside the <code>Main</code> method of the <em>Program.cs</em> file, define the path where the data files are stored.</p>
<pre><code class="language-csharp">string solutionDirectory = &quot;/home/lqdev/Development/RestaurantInspectionsSparkMLNET&quot;;
string dataLocation = Path.Combine(solutionDirectory,&quot;RestaurantInspectionsETL&quot;,&quot;Output&quot;);
</code></pre>
<p>The entrypoint of an ML.NET application is the <code>MLContext</code>. Initialize an <code>MLContext</code> instance.</p>
<pre><code class="language-csharp">MLContext mlContext = new MLContext();
</code></pre>
<p>Next, get the paths of the data files. The output generated by the <em>RestaurantInspectionsETL</em> application contains both the csv files as well as files containing information about the partitions that created them. For training, only the csv files are needed.</p>
<pre><code class="language-csharp">var latestOutput =
    Directory
        .GetDirectories(dataLocation)
        .Select(directory =&gt; new DirectoryInfo(directory))
        .OrderBy(directoryInfo =&gt; directoryInfo.Name)
        .Select(directory =&gt; Path.Join(directory.FullName,&quot;Graded&quot;))
        .First();

var dataFilePaths =
    Directory
        .GetFiles(latestOutput)
        .Where(file =&gt; file.EndsWith(&quot;csv&quot;))
        .ToArray();
</code></pre>
<p>Then, load the data into an <code>IDataView</code>. An <code>IDataView</code> is similar to a <code>DataFrame</code> in that it is a way to represent data as rows, columns and their schema.</p>
<pre><code class="language-csharp">var dataLoader = mlContext.Data.CreateTextLoader&lt;ModelInput&gt;(separatorChar:',', hasHeader:false, allowQuoting:true, trimWhitespace:true);

IDataView data = dataLoader.Load(dataFilePaths);
</code></pre>
<p>It's good practice to split the data into training and test sets for evaluation. Split the data into 80% training and 20% test sets.</p>
<pre><code class="language-csharp">TrainTestData dataSplit = mlContext.Data.TrainTestSplit(data,testFraction:0.2);
IDataView trainData = dataSplit.TrainSet;
IDataView testData = dataSplit.TestSet;
</code></pre>
<h3>Create the experiment</h3>
<p>Auto ML takes the data and runs experiments using different models and hyper-parameters in search of the &quot;best&quot; model. Define the settings for your experiment. In this case, the model will run for 600 seconds or 10 minutes and will try to find the model with the lowest log loss metric.</p>
<pre><code class="language-csharp">var experimentSettings = new MulticlassExperimentSettings();
experimentSettings.MaxExperimentTimeInSeconds = 600;
experimentSettings.OptimizingMetric = MulticlassClassificationMetric.LogLoss;
</code></pre>
<p>Then, create the experiment.</p>
<pre><code class="language-csharp">var experiment = mlContext.Auto().CreateMulticlassClassificationExperiment(experimentSettings);
</code></pre>
<p>After creating the experiment, run it.</p>
<pre><code class="language-csharp">var experimentResults = experiment.Execute(data, progressHandler: new ProgressHandler());
</code></pre>
<p>By default, running the application wonâ€™t display progress information. However, a <code>ProgressHandler</code> object can be passed into the <code>Execute</code> method of an experiment which calls the implemented <code>Report</code> method.</p>
<p>Inside the <em>RestaurantInspectionsTraining</em> project directory, create a new file called <em>ProgressHandler.cs</em>.</p>
<pre><code class="language-bash">touch ProgressHandler.cs
</code></pre>
<p>Then, add the following code:</p>
<pre><code class="language-csharp">using System;
using Microsoft.ML.Data;
using Microsoft.ML.AutoML;

namespace RestaurantInspectionsTraining
{
    public class ProgressHandler : IProgress&lt;RunDetail&lt;MulticlassClassificationMetrics&gt;&gt;
    {
        public void Report(RunDetail&lt;MulticlassClassificationMetrics&gt; run)
        {
            Console.WriteLine($&quot;Trained {run.TrainerName} with Log Loss {run.ValidationMetrics.LogLoss:0.####} in {run.RuntimeInSeconds:0.##} seconds&quot;);
        }
    }
}
</code></pre>
<p>The ProgressHandler class derives from the <code>IProgress&lt;T&gt;</code> interface which requires the implementation of the <code>Report</code> method. The object being passed into the Report method after each run is an <code>RunDetail&lt;MulticlassClassificationMetrics&gt;</code> object. Each time a run is complete, the <code>Report</code> method is called and the code inside it executes.</p>
<h3>Evaluate the results</h3>
<p>Once the experiment has finished running, get the model from the best run. Add the following code to the <code>Main</code> method of the <em>Program.cs</em>.</p>
<pre><code class="language-csharp">var bestModel = experimentResults.BestRun.Model;
</code></pre>
<p>Evaluate the performance of the model using the test dataset and measure it's Micro-Accuracy metric.</p>
<pre><code class="language-csharp">IDataView scoredTestData = bestModel.Transform(testData);  
var metrics = mlContext.MulticlassClassification.Evaluate(scoredTestData);
Console.WriteLine($&quot;MicroAccuracy: {metrics.MicroAccuracy}&quot;);
</code></pre>
<h3>Save the trained model</h3>
<p>Finally, save the trained model to the <em>RestaurantInspectionsML</em> project.</p>
<pre><code class="language-csharp">string modelSavePath = Path.Join(solutionDirectory,&quot;RestaurantInspectionsML&quot;,&quot;model.zip&quot;);
mlContext.Model.Save(bestModel, data.Schema, modelSavePath);
</code></pre>
<p>A file called <em>model.zip</em> should be created inside the <em>RestaurantInspectionsML</em> project.</p>
<p>Make sure that the trained model file is copied to the output directory by adding the following contents to the <em>RestaurantInspectionsML.csproj</em> file in the <em>RestaurantInspectionsML</em> directory.</p>
<pre><code class="language-xml">&lt;ItemGroup&gt;
  &lt;None Include=&quot;model.zip&quot;&gt;
    &lt;CopyToOutputDirectory&gt;PreserveNewest&lt;/CopyToOutputDirectory&gt;
  &lt;/None&gt;
&lt;/ItemGroup&gt;
</code></pre>
<p>Copying it to the output directory of the <em>RestaurantInspectionsML</em> makes it easier to reference from the <em>RestaurantInspectionsEnrichment</em> project since that project already contains a reference to the <em>RestaurantInspectionsML</em> class library.</p>
<h2>Train the model</h2>
<p>The final <em>Program.cs</em> file should look as follows:</p>
<pre><code class="language-csharp">using System;
using System.IO;
using System.Linq;
using Microsoft.ML;
using static Microsoft.ML.DataOperationsCatalog;
using Microsoft.ML.AutoML;
using RestaurantInspectionsML;

namespace RestaurantInspectionsTraining
{
    class Program
    {
        static void Main(string[] args)
        {
            // Define source data directory paths
            string solutionDirectory = &quot;/home/lqdev/Development/RestaurantInspectionsSparkMLNET&quot;;
            string dataLocation = Path.Combine(solutionDirectory,&quot;RestaurantInspectionsETL&quot;,&quot;Output&quot;);

            // Initialize MLContext
            MLContext mlContext = new MLContext();

            // Get directory name of most recent ETL output
            var latestOutput =
                Directory
                    .GetDirectories(dataLocation)
                    .Select(directory =&gt; new DirectoryInfo(directory))
                    .OrderBy(directoryInfo =&gt; directoryInfo.Name)
                    .Select(directory =&gt; Path.Join(directory.FullName,&quot;Graded&quot;))
                    .First();

            var dataFilePaths =
                Directory
                    .GetFiles(latestOutput)
                    .Where(file =&gt; file.EndsWith(&quot;csv&quot;))
                    .ToArray();

            // Load the data
            var dataLoader = mlContext.Data.CreateTextLoader&lt;ModelInput&gt;(separatorChar:',', hasHeader:false, allowQuoting:true, trimWhitespace:true);
            IDataView data = dataLoader.Load(dataFilePaths);

            // Split the data
            TrainTestData dataSplit = mlContext.Data.TrainTestSplit(data,testFraction:0.2);
            IDataView trainData = dataSplit.TrainSet;
            IDataView testData = dataSplit.TestSet;

            // Define experiment settings
            var experimentSettings = new MulticlassExperimentSettings();
            experimentSettings.MaxExperimentTimeInSeconds = 600;
            experimentSettings.OptimizingMetric = MulticlassClassificationMetric.LogLoss;

            // Create experiment
            var experiment = mlContext.Auto().CreateMulticlassClassificationExperiment(experimentSettings);

            // Run experiment
            var experimentResults = experiment.Execute(data, progressHandler: new ProgressHandler());

            // Best Run Results
            var bestModel = experimentResults.BestRun.Model;

            // Evaluate Model
            IDataView scoredTestData = bestModel.Transform(testData);  
            var metrics = mlContext.MulticlassClassification.Evaluate(scoredTestData);
            Console.WriteLine($&quot;MicroAccuracy: {metrics.MicroAccuracy}&quot;);

            // Save Model
            string modelSavePath = Path.Join(solutionDirectory,&quot;RestaurantInspectionsML&quot;,&quot;model.zip&quot;);
            mlContext.Model.Save(bestModel, data.Schema, modelSavePath);
        }
    }
}
</code></pre>
<p>Once all the code and configurations are complete, from the <em>RestaurantInspectionsTraining</em> directory, run the application using the <code>dotnet cli</code>. Remember this will take 10 minutes to run.</p>
<pre><code class="language-bash">dotnet run
</code></pre>
<p>The console output should look similar to the output below:</p>
<pre><code class="language-text">Trained LightGbmMulti with Log Loss 0.1547 in 1.55 seconds
Trained FastTreeOva with Log Loss 0.0405 in 65.58 seconds
Trained FastForestOva with Log Loss 0.0012 in 53.37 seconds
Trained LightGbmMulti with Log Loss 0.0021 in 4.55 seconds
Trained FastTreeOva with Log Loss 0.8315 in 5.22 seconds
MicroAccuracy: 0.999389615839469
</code></pre>
<h2>Build the data enrichment application</h2>
<p>Now that the model is trained, it can be used to enrich the ungraded data.</p>
<h3>Initialize the PredictionEngine</h3>
<p>Navigate to the <em>RestaurantInspectionsEnrichment</em> project directory and add the following using statements to the <em>Program.cs</em> class.</p>
<pre><code class="language-csharp">using System.IO;
using System.Linq;
using Microsoft.ML;
using Microsoft.Spark.Sql;
using static Microsoft.Spark.Sql.Functions;
using RestaurantInspectionsML;
</code></pre>
<p>To make predictions, the model has to be loaded into the applicaton and because predictions are made one row at a time, a <code>PredictionEngine</code> has be created as well.</p>
<p>Inside the <code>Program</code> class, define the <code>PredictionEngine</code>.</p>
<pre><code class="language-csharp">private static readonly PredictionEngine&lt;ModelInput,ModelOutput&gt; _predictionEngine;
</code></pre>
<p>Then, create a constructor to load the model and initialize it.</p>
<pre><code class="language-csharp">static Program()
{
    MLContext mlContext = new MLContext();
    ITransformer model = mlContext.Model.Load(&quot;model.zip&quot;,out DataViewSchema schema);
    _predictionEngine = mlContext.Model.CreatePredictionEngine&lt;ModelInput,ModelOutput&gt;(model);
}
</code></pre>
<h3>Load the ungraded data</h3>
<p>In the <code>Main</code> method of the <code>Program</code> class, define the location of the data files.</p>
<pre><code class="language-csharp">string solutionDirectory = &quot;/home/lqdev/Development/RestaurantInspectionsSparkMLNET&quot;;
string dataLocation = Path.Combine(solutionDirectory,&quot;RestaurantInspectionsETL&quot;,&quot;Output&quot;);
</code></pre>
<p>Then, get the path of the most recent ungraded data generated by the <em>RestaurantInspectionsETL</em> application.</p>
<pre><code class="language-csharp">var latestOutput =
    Directory
        .GetDirectories(dataLocation)
        .Select(directory =&gt; new DirectoryInfo(directory))
        .OrderBy(directoryInfo =&gt; directoryInfo.Name)
        .Select(directory =&gt; directory.FullName)
        .First();
</code></pre>
<p>Initialize a <code>SparkSession</code> for your enrichment application.</p>
<pre><code class="language-csharp">var sc =
    SparkSession
        .Builder()
        .AppName(&quot;Restaurant_Inspections_Enrichment&quot;)
        .GetOrCreate();
</code></pre>
<p>The data generated by the <em>RestaurantInspectionsETL</em> does not have headers. However, the schema can be defined and set when the data is loaded.</p>
<pre><code class="language-csharp">var schema = @&quot;
    INSPECTIONTYPE string,
    CODES string,
    CRITICALFLAG int,
    INSPECTIONSCORE int,
    GRADE string&quot;;

DataFrame df = 
    sc
    .Read()
    .Schema(schema)
    .Csv(Path.Join(latestOutput,&quot;Ungraded&quot;));
</code></pre>
<h3>Define the UDF</h3>
<p>There is no built-in function in Spark that allows you to use a <code>PredictionEngine</code>. However, Spark can be extended through UDFs. Keep in mind that UDFs are not optimized like the built-in functions. Therefore, whenever possible, try to use the built-in functions as much as possible.</p>
<p>In the <code>Program</code> class, create a new method called <code>PredictGrade</code> which takes in the set of features that make up the <code>ModelInput</code> expected by the trained model.</p>
<pre><code class="language-csharp">public static string PredictGrade(
    string inspectionType,
    string violationCodes,
    int criticalFlag,
    int inspectionScore)
{
    ModelInput input = new ModelInput
    {
        InspectionType=inspectionType,
        Codes=violationCodes,
        CriticalFlag=(float)criticalFlag,
        InspectionScore=(float)inspectionScore
    };

    ModelOutput prediction = _predictionEngine.Predict(input);

    return prediction.PredictedLabel;
}
</code></pre>
<p>Then, inside the <code>Main</code> method, register the <code>PredictGrade</code> method as a UDF in your <code>SparkSession</code>.</p>
<pre><code class="language-csharp">sc.Udf().Register&lt;string,string,int,int,string&gt;(&quot;PredictGrade&quot;,PredictGrade);
</code></pre>
<h3>Enrich the data</h3>
<p>Once the UDF is registered, use it inside of a <code>Select</code> statement which creates a new <code>DataFrame</code> that includes the input features as well as the predicted grade output by the trained mdoel.</p>
<pre><code class="language-csharp">var enrichedDf =
    df
    .Select(
        Col(&quot;INSPECTIONTYPE&quot;),
        Col(&quot;CODES&quot;),
        Col(&quot;CRITICALFLAG&quot;),
        Col(&quot;INSPECTIONSCORE&quot;),
        CallUDF(&quot;PredictGrade&quot;,
            Col(&quot;INSPECTIONTYPE&quot;),
            Col(&quot;CODES&quot;),
            Col(&quot;CRITICALFLAG&quot;),
            Col(&quot;INSPECTIONSCORE&quot;)
        ).Alias(&quot;PREDICTEDGRADE&quot;)
    );
</code></pre>
<p>Finally, save the enriched <code>DataFrame</code></p>
<pre><code class="language-csharp">string outputId = new DirectoryInfo(latestOutput).Name;
string enrichedOutputPath = Path.Join(solutionDirectory,&quot;RestaurantInspectionsEnrichment&quot;,&quot;Output&quot;);
string savePath = Path.Join(enrichedOutputPath,outputId);

if(!Directory.Exists(savePath))
{
    Directory.CreateDirectory(enrichedOutputPath);
}

enrichedDf.Write().Csv(savePath);
</code></pre>
<h3>Publish and run the enrichment application</h3>
<p>The final <em>Program.cs</em> file should look as follows.</p>
<pre><code class="language-csharp">using System.IO;
using System.Linq;
using Microsoft.ML;
using Microsoft.Spark.Sql;
using static Microsoft.Spark.Sql.Functions;
using RestaurantInspectionsML;

namespace RestaurantInspectionsEnrichment
{
    class Program
    {
        private static readonly PredictionEngine&lt;ModelInput,ModelOutput&gt; _predictionEngine;

        static Program()
        {
            MLContext mlContext = new MLContext();
            ITransformer model = mlContext.Model.Load(&quot;model.zip&quot;,out DataViewSchema schema);
            _predictionEngine = mlContext.Model.CreatePredictionEngine&lt;ModelInput,ModelOutput&gt;(model);
        }

        static void Main(string[] args)
        {
            // Define source data directory paths
            string solutionDirectory = &quot;/home/lqdev/Development/RestaurantInspectionsSparkMLNET&quot;;
            string dataLocation = Path.Combine(solutionDirectory,&quot;RestaurantInspectionsETL&quot;,&quot;Output&quot;);

            var latestOutput = 
                Directory
                    .GetDirectories(dataLocation)
                    .Select(directory =&gt; new DirectoryInfo(directory))
                    .OrderBy(directoryInfo =&gt; directoryInfo.Name)
                    .Select(directory =&gt; directory.FullName)
                    .First();

            var sc = 
                SparkSession
                    .Builder()
                    .AppName(&quot;Restaurant_Inspections_Enrichment&quot;)
                    .GetOrCreate();

            var schema = @&quot;
                INSPECTIONTYPE string,
                CODES string,
                CRITICALFLAG int,
                INSPECTIONSCORE int,
                GRADE string&quot;;

            DataFrame df = 
                sc
                .Read()
                .Schema(schema)
                .Csv(Path.Join(latestOutput,&quot;Ungraded&quot;));

            sc.Udf().Register&lt;string,string,int,int,string&gt;(&quot;PredictGrade&quot;,PredictGrade);

            var enrichedDf = 
                df
                .Select(
                    Col(&quot;INSPECTIONTYPE&quot;),
                    Col(&quot;CODES&quot;),
                    Col(&quot;CRITICALFLAG&quot;),
                    Col(&quot;INSPECTIONSCORE&quot;),
                    CallUDF(&quot;PredictGrade&quot;,
                        Col(&quot;INSPECTIONTYPE&quot;),
                        Col(&quot;CODES&quot;),
                        Col(&quot;CRITICALFLAG&quot;),
                        Col(&quot;INSPECTIONSCORE&quot;)
                    ).Alias(&quot;PREDICTEDGRADE&quot;)
                );

            string outputId = new DirectoryInfo(latestOutput).Name;
            string enrichedOutputPath = Path.Join(solutionDirectory,&quot;RestaurantInspectionsEnrichment&quot;,&quot;Output&quot;);
            string savePath = Path.Join(enrichedOutputPath,outputId);

            if(!Directory.Exists(savePath))
            {
                Directory.CreateDirectory(enrichedOutputPath);
            }

            enrichedDf.Write().Csv(savePath);

        }

        public static string PredictGrade(
            string inspectionType,
            string violationCodes,
            int criticalFlag,
            int inspectionScore)
        {
            ModelInput input = new ModelInput
            {
                InspectionType=inspectionType,
                Codes=violationCodes,
                CriticalFlag=(float)criticalFlag,
                InspectionScore=(float)inspectionScore
            };

            ModelOutput prediction = _predictionEngine.Predict(input);

            return prediction.PredictedLabel;
        }
    }
}
</code></pre>
<p>From the <em>RestaurantInspectionsEnrichment</em> project publish the application with the following command.</p>
<pre><code class="language-bash">dotnet publish -f netcoreapp2.1 -r ubuntu.18.04-x64
</code></pre>
<p>Navigate to the <em>publish</em> directory. In this case, it's <em>bin/Debug/netcoreapp2.1/ubuntu.18.04-x64/publish</em>.</p>
<p>From the <em>publish</em> directory, run the application with <code>spark-submit</code>.</p>
<pre><code class="language-bash">spark-submit --class org.apache.spark.deploy.dotnet.DotnetRunner --master local microsoft-spark-2.4.x-0.4.0.jar dotnet RestaurantInspectionsEnrichment.dll
</code></pre>
<p>The file output should look similar to the contents below:</p>
<pre><code class="language-text">Cycle Inspection / Initial Inspection,04N,1,13,A
Cycle Inspection / Re-inspection,08A,0,9,A
Cycle Inspection / Initial Inspection,&quot;10B,10H&quot;,0,10,A
Cycle Inspection / Initial Inspection,10F,0,10,A
Cycle Inspection / Reopening Inspection,10F,0,3,C
</code></pre>
<h2>Conclusion</h2>
<p>This solution showcased how Spark can be used within .NET applications with Spark.NET. Because it's part of the .NET ecosystem, other components and frameworks such as ML.NET can be leveraged to extend the system's capabilities. Although this sample was developed and run on a local, single-node cluster, Spark was made to run at scale. As such, this application can be further improved by setting up a cluster and running the ETL and enrichment workloads on there.</p>
<h6>Resources</h6>
<p><a href="https://spark.apache.org/">Apache Spark</a>
<a href="https://dotnet.microsoft.com/apps/data/spark">Spark.NET</a>
<a href="https://github.com/dotnet/spark">Spark.NET GitHub</a>
<a href="https://github.com/Microsoft/Mobius">Mobius</a>
<a href="https://opendata.cityofnewyork.us/">NYC OpenData</a></p>
<hr /><div><script type="application/javascript">window.onload = function() { document.getElementById('webmention-target').value = window.location.href }</script><form action="https://webmentions.lqdev.tech/api/inbox" method="POST" enctype="application/x-www-form-urlencoded"><h5 class="text-center">Send me a <a href="/contact">message</a> or <a href="https://indieweb.org/webmentions">webmention</a></h5><div class="form-row justify-content-center"><div class="w-75"><input type="text" name="source" class="form-control" placeholder="Your URL (source)" /></div><div class="col-auto"><input type="submit" class="btn btn-primary" value="Send" /></div><input readonly class="form-control-plaintext" style="visibility:hidden" type="text" id="webmention-target" name="target" /></div></form></div></div></main><script src="/lib/jquery/jquery.slim.min.js"></script><script src="/lib/boostrap/bootstrap.min.js"></script><script src="/lib/highlight/highlight.min.js"></script><script src="/lib/highlight/highlight.fsharp.min.js"></script><script src="/lib/highlight/highlight.nix.min.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script><script type="application/javascript">mermaid.initialize({startOnLoad:true});</script><script type="application/javascript">hljs.initHighlightingOnLoad();</script></body><footer><a rel="me" href="https://toot.lqdev.tech/@lqdev"></a><a rel="me" href="https://github.com/lqdev"></a><a rel="me" href="https://twitter.com/ljquintanilla"></a><a rel="me" href="https://www.linkedin.com/in/lquintanilla01/"></a><a rel="me" href="mailto:lqdev@outlook.com"></a></footer></html>